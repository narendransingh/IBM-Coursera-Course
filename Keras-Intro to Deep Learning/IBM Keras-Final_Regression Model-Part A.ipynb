{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM Keras - FInal Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('concrete_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks clean, with no null values. We have to predict data of concrete strength\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[df.columns != 'Strength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Strength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A - Build Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Neural Network\n",
    "\n",
    "def regression_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss ='mean_squared_error')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "Since the data is clean we can go ahead and split the data in train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = X_train.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (721, 8)\n",
      "y_train: (721,)\n",
      "X_test: (309, 8)\n",
      "y_test: (309,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 30879.2972 - val_loss: 19858.0317\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 13139.6482 - val_loss: 8294.0097\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 5699.5101 - val_loss: 4145.7313\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 3383.6093 - val_loss: 3113.4729\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 2899.6730 - val_loss: 2916.6057\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 2753.7333 - val_loss: 2808.1071\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 2639.1568 - val_loss: 2696.7693\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 2524.3170 - val_loss: 2591.5136\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 2414.1969 - val_loss: 2488.8301\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 2307.8702 - val_loss: 2390.1111\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 2205.1194 - val_loss: 2292.6129\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 2107.0293 - val_loss: 2195.2292\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 2016.0367 - val_loss: 2102.0095\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 1920.8134 - val_loss: 2014.4406\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 1838.3156 - val_loss: 1926.4405\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 1755.3923 - val_loss: 1847.6916\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 1680.0113 - val_loss: 1771.3099\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 1610.3270 - val_loss: 1697.4103\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 1541.6798 - val_loss: 1630.0332\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 1481.1979 - val_loss: 1564.2338\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 215us/step - loss: 1417.2568 - val_loss: 1504.7089\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 278us/step - loss: 1361.5958 - val_loss: 1448.4777\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 342us/step - loss: 1310.6024 - val_loss: 1394.3526\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 189us/step - loss: 1261.1766 - val_loss: 1343.4376\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 302us/step - loss: 1214.1970 - val_loss: 1294.6927\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 193us/step - loss: 1171.7771 - val_loss: 1247.1240\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 214us/step - loss: 1129.0600 - val_loss: 1203.3651\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 317us/step - loss: 1092.7306 - val_loss: 1164.8627\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 1051.3014 - val_loss: 1124.9432\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 1017.3229 - val_loss: 1087.1179\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 984.6568 - val_loss: 1052.6404\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 951.8991 - val_loss: 1018.8267\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 922.2040 - val_loss: 987.3717\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 892.8734 - val_loss: 957.9441\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 866.3228 - val_loss: 929.5319\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 840.6234 - val_loss: 901.3337\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 814.9495 - val_loss: 876.2011\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 792.6706 - val_loss: 852.1356\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 124us/step - loss: 770.6471 - val_loss: 827.3773\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 176us/step - loss: 749.5554 - val_loss: 804.3401\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 728.8661 - val_loss: 783.0352\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 709.1759 - val_loss: 763.0880\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 691.1997 - val_loss: 744.4182\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 673.1978 - val_loss: 725.4341\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 656.7862 - val_loss: 707.0056\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 640.6189 - val_loss: 690.3713\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 624.7874 - val_loss: 674.3563\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 610.0714 - val_loss: 658.3460\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 595.4816 - val_loss: 644.1254\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 582.0238 - val_loss: 629.1897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f949cc00940>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "\n",
    "predict_yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.17703075133716"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predict_yhat)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 140us/step - loss: 34.9440 - val_loss: 52.2688\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 36.7880 - val_loss: 55.2456\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.4360 - val_loss: 55.9196\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 36.4103 - val_loss: 52.9106\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 36.1782 - val_loss: 52.7653\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.0930 - val_loss: 54.7055\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.4063 - val_loss: 52.3903\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 34.8063 - val_loss: 52.4959\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 35.4520 - val_loss: 54.9354\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.2981 - val_loss: 55.9545\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.4153 - val_loss: 53.1601\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.6170 - val_loss: 53.8937\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.2418 - val_loss: 53.5956\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.4367 - val_loss: 53.5525\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.4526 - val_loss: 53.5410\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.7950 - val_loss: 52.6630\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.6916 - val_loss: 52.8249\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.8885 - val_loss: 52.4382\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.1037 - val_loss: 55.4415\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.8851 - val_loss: 54.4526\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.1161 - val_loss: 53.4170\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.8935 - val_loss: 52.2493\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.0821 - val_loss: 55.1751\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.5331 - val_loss: 53.9926\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 36.6230 - val_loss: 52.7938\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.5841 - val_loss: 53.9337\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.6765 - val_loss: 52.5416\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 35.7626 - val_loss: 53.7463\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 35.5700 - val_loss: 52.4980\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.8566 - val_loss: 52.6988\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 35.5307 - val_loss: 52.1388\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.7659 - val_loss: 56.0813\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.8305 - val_loss: 52.2879\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.3610 - val_loss: 61.0279\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 36.0544 - val_loss: 52.6466\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 35.0553 - val_loss: 53.0889\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.2535 - val_loss: 54.3006\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.5402 - val_loss: 52.6989\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.7720 - val_loss: 51.8672\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.1737 - val_loss: 53.4944\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.4179 - val_loss: 52.7392\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 35.4237 - val_loss: 52.4828\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 40.6786 - val_loss: 54.6426\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 38.4983 - val_loss: 57.7720\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.9548 - val_loss: 55.4942\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.3420 - val_loss: 53.6966\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.9889 - val_loss: 53.1981\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.0589 - val_loss: 52.3542\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 36.9107 - val_loss: 52.9456\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.6630 - val_loss: 52.4293\n",
      "\n",
      "Mean Squared Error for iteration1: 50.583034016405044\n",
      "\n",
      "Iteration: 2\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 35.3859 - val_loss: 52.5720\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.8506 - val_loss: 54.1851\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.2098 - val_loss: 56.4752\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.7314 - val_loss: 52.2987\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.2765 - val_loss: 52.5838\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 35.1698 - val_loss: 52.4374\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 37.3582 - val_loss: 53.5753\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 35.5536 - val_loss: 53.5865\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.8225 - val_loss: 52.8879\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.8358 - val_loss: 54.7590\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.0869 - val_loss: 52.7725\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 35.0574 - val_loss: 54.1928\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 36.7761 - val_loss: 54.8165\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 115us/step - loss: 37.1191 - val_loss: 52.9647\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 35.2932 - val_loss: 54.7650\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 151us/step - loss: 38.3763 - val_loss: 53.7194\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.4751 - val_loss: 52.7173\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.1058 - val_loss: 53.4738\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.1354 - val_loss: 59.5628\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 36.0449 - val_loss: 53.4286\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.0843 - val_loss: 54.5151\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.0371 - val_loss: 55.1966\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 36.4558 - val_loss: 52.4431\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.9876 - val_loss: 53.3723\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 35.1866 - val_loss: 52.2337\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.2102 - val_loss: 53.6948\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.3651 - val_loss: 53.5022\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 83us/step - loss: 34.9853 - val_loss: 53.0255\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.8256 - val_loss: 52.3153\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.8654 - val_loss: 53.3611\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.9582 - val_loss: 53.6490\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.0945 - val_loss: 54.4150\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.1200 - val_loss: 53.3082\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.5033 - val_loss: 53.6819\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.7587 - val_loss: 52.5547\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 36.5075 - val_loss: 53.3600\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.0965 - val_loss: 52.4989\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.4447 - val_loss: 54.2600\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 36.1791 - val_loss: 52.3810\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 35.3224 - val_loss: 52.5505\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.9077 - val_loss: 52.9489\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.9519 - val_loss: 53.2013\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.2963 - val_loss: 53.0734\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.2545 - val_loss: 53.0060\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0938 - val_loss: 53.6990\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.3910 - val_loss: 51.9726\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.9783 - val_loss: 52.5588\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 34.7457 - val_loss: 52.5726\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 124us/step - loss: 35.3204 - val_loss: 53.8613\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 124us/step - loss: 34.9079 - val_loss: 52.4860\n",
      "\n",
      "Mean Squared Error for iteration2: 51.6006477532816\n",
      "\n",
      "Iteration: 3\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 36.1819 - val_loss: 52.3737\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.6541 - val_loss: 55.3321\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.4464 - val_loss: 52.3247\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 35.1504 - val_loss: 53.4768\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.6635 - val_loss: 53.3317\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.4286 - val_loss: 52.7138\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 38.3453 - val_loss: 53.1352\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.7165 - val_loss: 53.7911\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.5708 - val_loss: 53.3714\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.4884 - val_loss: 52.9695\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.2854 - val_loss: 52.5020\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.6035 - val_loss: 61.9613\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 37.6066 - val_loss: 55.4814\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.9543 - val_loss: 52.9215\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.8547 - val_loss: 54.4131\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 34.7296 - val_loss: 53.5669\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 35.7373 - val_loss: 54.1457\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.9983 - val_loss: 55.2193\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.0941 - val_loss: 53.3958\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.6512 - val_loss: 52.8774\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.5993 - val_loss: 53.5131\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.9234 - val_loss: 54.5214\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.2600 - val_loss: 52.8326\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.2703 - val_loss: 52.2795\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.9219 - val_loss: 54.1953\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.4418 - val_loss: 53.5252\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0991 - val_loss: 52.6240\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.3060 - val_loss: 53.2316\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.8335 - val_loss: 52.8762\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 36.1254 - val_loss: 54.9481\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.3917 - val_loss: 53.1749\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.0570 - val_loss: 52.4744\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.0360 - val_loss: 53.2618\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.7431 - val_loss: 52.3942\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.0649 - val_loss: 57.7053\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.3892 - val_loss: 52.9822\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.3770 - val_loss: 53.3346\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.3088 - val_loss: 53.1681\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 37.9657 - val_loss: 52.1141\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.3812 - val_loss: 54.1716\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 35.7602 - val_loss: 53.2743\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 35.5493 - val_loss: 53.1384\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.6003 - val_loss: 52.8635\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.6200 - val_loss: 56.0721\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.9475 - val_loss: 52.7316\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 35.0284 - val_loss: 52.8449\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.0162 - val_loss: 52.8482\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9480 - val_loss: 53.4570\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9511 - val_loss: 52.5908\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 420us/step - loss: 35.4106 - val_loss: 54.0167\n",
      "\n",
      "Mean Squared Error for iteration3: 50.46734574525872\n",
      "\n",
      "Iteration: 4\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 279us/step - loss: 35.8490 - val_loss: 54.5540\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 159us/step - loss: 34.6852 - val_loss: 52.9950\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.5141 - val_loss: 53.3476\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 92us/step - loss: 36.0112 - val_loss: 54.0747\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 36.3347 - val_loss: 53.6818\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 35.0323 - val_loss: 52.8812\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 542us/step - loss: 34.9450 - val_loss: 53.6334\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 568us/step - loss: 36.9882 - val_loss: 53.4191\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.1070 - val_loss: 53.9309\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.5748 - val_loss: 52.9025\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.6010 - val_loss: 53.6052\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 35.2764 - val_loss: 53.2709\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.2624 - val_loss: 53.0596\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 35.4952 - val_loss: 53.6271\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.4188 - val_loss: 53.6775\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 35.6885 - val_loss: 53.4390\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.6213 - val_loss: 53.4060\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 118us/step - loss: 34.9131 - val_loss: 53.2458\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 34.7823 - val_loss: 56.9204\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 36.6358 - val_loss: 52.8013\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 36.0169 - val_loss: 55.3865\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 36.6779 - val_loss: 53.0757\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 36.0643 - val_loss: 53.3954\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.5832 - val_loss: 55.3190\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.5754 - val_loss: 52.4609\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.1419 - val_loss: 53.2476\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.4928 - val_loss: 54.3584\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.0330 - val_loss: 54.4503\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 35.2926 - val_loss: 54.1005\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.7592 - val_loss: 55.8776\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.6775 - val_loss: 55.9251\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.9399 - val_loss: 54.2495\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 35.1648 - val_loss: 53.9692\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 35.1813 - val_loss: 56.1789\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 36.1972 - val_loss: 53.4810\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 34.7741 - val_loss: 53.4069\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 35.3444 - val_loss: 52.9094\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 35.4473 - val_loss: 53.0349\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 35.8403 - val_loss: 58.0855\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 35.3765 - val_loss: 52.9263\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 35.2407 - val_loss: 54.5713\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.4781 - val_loss: 53.5036\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.0637 - val_loss: 53.4187\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.5085 - val_loss: 55.2061\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6514 - val_loss: 54.4178\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3119 - val_loss: 56.9041\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.0513 - val_loss: 54.1858\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.9050 - val_loss: 56.3615\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.7758 - val_loss: 53.6700\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 34.6674 - val_loss: 53.1776\n",
      "\n",
      "Mean Squared Error for iteration4: 51.469371962201535\n",
      "\n",
      "Iteration: 5\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 35.3045 - val_loss: 54.7573\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - ETA: 0s - loss: 34.36 - 0s 127us/step - loss: 35.0165 - val_loss: 54.7485\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 35.1331 - val_loss: 53.3570\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 34.5936 - val_loss: 54.8205\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 35.0113 - val_loss: 55.1160\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 36.1801 - val_loss: 54.8884\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 35.2732 - val_loss: 61.6759\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 35.1814 - val_loss: 53.4112\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 35.9333 - val_loss: 55.0921\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.0326 - val_loss: 56.3068\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.8962 - val_loss: 54.1052\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 37.4479 - val_loss: 60.1820\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 38.4214 - val_loss: 55.7502\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.7768 - val_loss: 53.1177\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.5815 - val_loss: 53.6505\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 114us/step - loss: 36.3312 - val_loss: 53.9298\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.8695 - val_loss: 55.6592\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.2046 - val_loss: 54.1478\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 37.0174 - val_loss: 53.4325\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 35.2536 - val_loss: 54.0750\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.9351 - val_loss: 53.6886\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.5979 - val_loss: 53.4528\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.4449 - val_loss: 53.8808\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 34.7783 - val_loss: 53.3606\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.9256 - val_loss: 54.1629\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.9044 - val_loss: 53.3300\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.9639 - val_loss: 53.9784\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.2614 - val_loss: 53.6866\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6050 - val_loss: 53.4065\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.0825 - val_loss: 53.8886\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 76us/step - loss: 35.1957 - val_loss: 53.3250\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.7332 - val_loss: 54.2012\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 36.3424 - val_loss: 55.6398\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.8962 - val_loss: 53.1413\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.8867 - val_loss: 53.3242\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.2552 - val_loss: 57.8891\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.7888 - val_loss: 54.0075\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.3011 - val_loss: 54.1318\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.5156 - val_loss: 53.4213\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 34.7446 - val_loss: 53.1924\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 36.1366 - val_loss: 55.7384\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.2303 - val_loss: 55.0468\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 38.4044 - val_loss: 54.8128\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.2923 - val_loss: 53.9561\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0245 - val_loss: 55.1563\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.5319 - val_loss: 57.2373\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.9383 - val_loss: 53.1790\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 37.2641 - val_loss: 54.4002\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 37.0078 - val_loss: 56.8891\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.5113 - val_loss: 54.4113\n",
      "\n",
      "Mean Squared Error for iteration5: 50.87150796596201\n",
      "\n",
      "Iteration: 6\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 34.8187 - val_loss: 53.4593\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 35.4891 - val_loss: 54.3971\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 193us/step - loss: 34.3878 - val_loss: 53.1187\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 235us/step - loss: 35.8099 - val_loss: 54.5408\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.8364 - val_loss: 53.8348\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.8457 - val_loss: 59.9536\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 147us/step - loss: 36.2874 - val_loss: 53.9458\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 36.3458 - val_loss: 56.6821\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 161us/step - loss: 37.5222 - val_loss: 53.2214\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 35.0272 - val_loss: 53.6915\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 114us/step - loss: 35.4404 - val_loss: 53.1838\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 35.2282 - val_loss: 56.6500\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 37.2414 - val_loss: 54.2066\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 36.9887 - val_loss: 54.3408\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 165us/step - loss: 34.6499 - val_loss: 57.2147\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 155us/step - loss: 35.9795 - val_loss: 53.9784\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 36.0342 - val_loss: 53.9002\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 34.8223 - val_loss: 54.7049\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - ETA: 0s - loss: 34.93 - 0s 142us/step - loss: 34.5770 - val_loss: 53.3293\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 234us/step - loss: 34.8682 - val_loss: 54.5985\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 35.2282 - val_loss: 54.6982\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.0430 - val_loss: 56.5517\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.0645 - val_loss: 53.0079\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 169us/step - loss: 35.1916 - val_loss: 55.2988\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 167us/step - loss: 35.4339 - val_loss: 54.2155\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.8751 - val_loss: 54.6683\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.2701 - val_loss: 53.4117\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.9738 - val_loss: 56.2679\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.2833 - val_loss: 54.2282\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.2820 - val_loss: 55.5837\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.2671 - val_loss: 55.8500\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.9317 - val_loss: 54.0031\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.3663 - val_loss: 53.5014\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5451 - val_loss: 53.7706\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.4556 - val_loss: 53.6707\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.9002 - val_loss: 54.0688\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 35.5246 - val_loss: 53.8886\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 36.4286 - val_loss: 54.4194\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.1262 - val_loss: 55.1016\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.3185 - val_loss: 53.9925\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.0239 - val_loss: 53.9564\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 36.5195 - val_loss: 54.6425\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 36.5141 - val_loss: 57.4719\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 37.2297 - val_loss: 56.7250\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.9153 - val_loss: 54.3508\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.4529 - val_loss: 54.7811\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9571 - val_loss: 53.2398\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 36.4929 - val_loss: 54.4292\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.6761 - val_loss: 53.5857\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.6611 - val_loss: 54.4516\n",
      "\n",
      "Mean Squared Error for iteration6: 50.90944136412306\n",
      "\n",
      "Iteration: 7\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.6605 - val_loss: 54.5730\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.9196 - val_loss: 54.7179\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.1582 - val_loss: 54.2972\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.6223 - val_loss: 57.6606\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 36.8903 - val_loss: 53.0731\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.8747 - val_loss: 55.1348\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 107us/step - loss: 35.1178 - val_loss: 53.6477\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.4881 - val_loss: 53.2328\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.9408 - val_loss: 54.6704\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.5535 - val_loss: 53.0495\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.2772 - val_loss: 55.1804\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.3692 - val_loss: 53.2223\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7335 - val_loss: 54.7547\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.6301 - val_loss: 53.3786\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0018 - val_loss: 53.8347\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5966 - val_loss: 53.5628\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 188us/step - loss: 34.5639 - val_loss: 54.2893\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 34.8918 - val_loss: 53.8984\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 146us/step - loss: 34.8985 - val_loss: 54.2534\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 34.4841 - val_loss: 54.1640\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 151us/step - loss: 35.2153 - val_loss: 57.3533\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 170us/step - loss: 34.8588 - val_loss: 54.4892\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 35.1701 - val_loss: 54.0072\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 167us/step - loss: 34.9303 - val_loss: 53.6752\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 160us/step - loss: 35.0957 - val_loss: 53.9044\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 34.7065 - val_loss: 54.9455\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.8638 - val_loss: 53.9067\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.8928 - val_loss: 59.5205\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 36.2352 - val_loss: 53.8079\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 192us/step - loss: 35.6477 - val_loss: 53.3024\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 138us/step - loss: 36.2254 - val_loss: 54.1240\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 35.5444 - val_loss: 55.3590\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 154us/step - loss: 35.8872 - val_loss: 52.9572\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.1727 - val_loss: 55.4046\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 189us/step - loss: 35.9452 - val_loss: 53.9346\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 202us/step - loss: 36.7560 - val_loss: 53.4936\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.0340 - val_loss: 55.0235\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 36.7419 - val_loss: 55.9238\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 36.5667 - val_loss: 54.3147\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.3847 - val_loss: 55.9406\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.8867 - val_loss: 54.2506\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.9975 - val_loss: 54.3807\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8996 - val_loss: 53.9083\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 35.9546 - val_loss: 53.4741\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.0717 - val_loss: 56.9700\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.3530 - val_loss: 53.4065\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 36.0410 - val_loss: 60.4806\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 37.2373 - val_loss: 54.3176\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.0251 - val_loss: 53.4944\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.0716 - val_loss: 55.1086\n",
      "\n",
      "Mean Squared Error for iteration7: 51.93626262451689\n",
      "\n",
      "Iteration: 8\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.8122 - val_loss: 55.8371\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.1234 - val_loss: 53.4253\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.3547 - val_loss: 53.5321\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.4507 - val_loss: 54.1940\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.1356 - val_loss: 58.2801\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.3604 - val_loss: 56.4267\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.4000 - val_loss: 53.4904\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5339 - val_loss: 53.7166\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.9671 - val_loss: 53.5404\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.6861 - val_loss: 54.0424\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.1136 - val_loss: 53.8643\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.9750 - val_loss: 54.5564\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.8312 - val_loss: 54.9319\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.5222 - val_loss: 53.7935\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.8093 - val_loss: 53.6860\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7967 - val_loss: 55.0776\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.8454 - val_loss: 54.0523\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 35.6321 - val_loss: 53.7416\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.6549 - val_loss: 56.4335\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6382 - val_loss: 53.9642\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.0669 - val_loss: 53.6528\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.3279 - val_loss: 56.0104\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.8448 - val_loss: 54.0620\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5401 - val_loss: 54.2427\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.2280 - val_loss: 53.7751\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 36.0026 - val_loss: 57.4622\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 36.0251 - val_loss: 53.8977\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.1498 - val_loss: 54.4505\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 35.0155 - val_loss: 54.2432\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 34.9510 - val_loss: 54.0215\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 35.9820 - val_loss: 54.5486\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 152us/step - loss: 34.8268 - val_loss: 57.6117\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 34.6867 - val_loss: 55.4748\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 163us/step - loss: 35.2034 - val_loss: 55.7856\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.6105 - val_loss: 55.3388\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 37.9375 - val_loss: 53.2684\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.6588 - val_loss: 53.8549\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.4378 - val_loss: 54.2725\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7995 - val_loss: 56.6374\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5135 - val_loss: 55.3540\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 37.1320 - val_loss: 54.4076\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 36.8697 - val_loss: 54.8550\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.8120 - val_loss: 53.3134\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 34.9542 - val_loss: 55.8132\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 36.4676 - val_loss: 57.0551\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 34.7316 - val_loss: 54.1914\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 35.1236 - val_loss: 56.4880\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 34.9499 - val_loss: 55.2489\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.7557 - val_loss: 53.6663\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.6906 - val_loss: 53.6939\n",
      "\n",
      "Mean Squared Error for iteration8: 51.34063564978393\n",
      "\n",
      "Iteration: 9\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.4465 - val_loss: 55.1085\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 35.0080 - val_loss: 54.4635\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 34.7329 - val_loss: 53.7423\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 34.6342 - val_loss: 53.7219\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 202us/step - loss: 35.7037 - val_loss: 57.8184\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 234us/step - loss: 35.3367 - val_loss: 54.6336\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 35.7656 - val_loss: 57.4760\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.6004 - val_loss: 53.7489\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.9031 - val_loss: 53.7686\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.9861 - val_loss: 54.3988\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.2311 - val_loss: 54.9291\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.8137 - val_loss: 53.9878\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.3283 - val_loss: 53.6218\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8756 - val_loss: 54.2596\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.9730 - val_loss: 57.6013\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 37.0711 - val_loss: 57.3947\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 36.3258 - val_loss: 53.6733\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.8204 - val_loss: 53.2582\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 34.5099 - val_loss: 55.0138\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 34.6214 - val_loss: 53.5686\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 34.9024 - val_loss: 54.1786\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.4765 - val_loss: 54.7537\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 35.0015 - val_loss: 53.4310\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.0708 - val_loss: 54.1107\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.4995 - val_loss: 53.7710\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 36.9501 - val_loss: 56.5364\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 35.6526 - val_loss: 53.8327\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 34.9351 - val_loss: 53.6966\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.3662 - val_loss: 58.4045\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 134us/step - loss: 37.2168 - val_loss: 56.1327\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 35.3275 - val_loss: 56.3504\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 34.7553 - val_loss: 53.9052\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 190us/step - loss: 34.2468 - val_loss: 53.5538\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 152us/step - loss: 34.5188 - val_loss: 53.9117\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 118us/step - loss: 34.4800 - val_loss: 54.9254\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 231us/step - loss: 36.1938 - val_loss: 54.6787\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 34.7640 - val_loss: 54.7283\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 36.2821 - val_loss: 56.7489\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 159us/step - loss: 38.6680 - val_loss: 56.5090\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 35.2429 - val_loss: 54.3552\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 162us/step - loss: 35.2689 - val_loss: 54.4449\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 225us/step - loss: 36.1877 - val_loss: 58.9940\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 326us/step - loss: 36.5885 - val_loss: 53.6064\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 715us/step - loss: 34.6068 - val_loss: 54.6257\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 181us/step - loss: 34.7614 - val_loss: 53.6083\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.2867 - val_loss: 54.3637\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.3714 - val_loss: 53.6249\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.5987 - val_loss: 55.3035\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.8611 - val_loss: 54.3787\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 34.4348 - val_loss: 53.6710\n",
      "\n",
      "Mean Squared Error for iteration9: 50.311162268774225\n",
      "\n",
      "Iteration: 10\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.7075 - val_loss: 54.1283\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.0470 - val_loss: 54.3954\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.5477 - val_loss: 54.7242\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.2258 - val_loss: 53.4249\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 35.7330 - val_loss: 54.3576\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 35.5474 - val_loss: 53.5652\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 154us/step - loss: 35.5063 - val_loss: 54.9932\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 34.7485 - val_loss: 53.0088\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 35.2005 - val_loss: 53.5371\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 93us/step - loss: 34.2219 - val_loss: 54.3222\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.9897 - val_loss: 55.8690\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 37.3551 - val_loss: 57.4558\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.6350 - val_loss: 53.4997\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 36.2404 - val_loss: 55.3493\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.9475 - val_loss: 55.3516\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.6222 - val_loss: 55.4461\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.3271 - val_loss: 53.7880\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.5636 - val_loss: 54.3099\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.2054 - val_loss: 54.5526\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.1428 - val_loss: 54.9318\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.6569 - val_loss: 54.6852\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.0110 - val_loss: 53.9999\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.4181 - val_loss: 54.8805\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.9722 - val_loss: 60.2579\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.1481 - val_loss: 54.2569\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5668 - val_loss: 54.4431\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.1188 - val_loss: 54.9694\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.5005 - val_loss: 55.4771\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.9808 - val_loss: 55.4903\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7547 - val_loss: 53.9564\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.2394 - val_loss: 59.8572\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3139 - val_loss: 55.4478\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5723 - val_loss: 56.2232\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.8150 - val_loss: 54.4639\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3031 - val_loss: 54.7599\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.2355 - val_loss: 55.0952\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.9541 - val_loss: 54.7155\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3912 - val_loss: 57.1822\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.8610 - val_loss: 53.9721\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.6759 - val_loss: 53.3310\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.3573 - val_loss: 53.7569\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.2463 - val_loss: 53.7447\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.6741 - val_loss: 55.1751\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 37.1232 - val_loss: 55.3500\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6438 - val_loss: 54.1383\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.9099 - val_loss: 53.6521\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.2073 - val_loss: 54.2719\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.9750 - val_loss: 53.4724\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9347 - val_loss: 56.7088\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 39.0120 - val_loss: 55.1872\n",
      "\n",
      "Mean Squared Error for iteration10: 51.07061842532071\n",
      "\n",
      "Iteration: 11\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 37.6274 - val_loss: 56.5364\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.3060 - val_loss: 53.1942\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.1119 - val_loss: 55.1170\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9892 - val_loss: 54.0922\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.5865 - val_loss: 53.6917\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.7482 - val_loss: 55.2429\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.8097 - val_loss: 53.8144\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8362 - val_loss: 56.3502\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.3248 - val_loss: 54.5647\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 36.0020 - val_loss: 54.6012\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 37.1734 - val_loss: 53.3687\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.8063 - val_loss: 54.5692\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.5401 - val_loss: 54.5655\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8124 - val_loss: 54.3868\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.3453 - val_loss: 54.5379\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.1430 - val_loss: 54.4433\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.2224 - val_loss: 54.3089\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.9464 - val_loss: 53.2608\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5774 - val_loss: 53.9319\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.5497 - val_loss: 59.1151\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.3131 - val_loss: 53.8982\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.8626 - val_loss: 53.3509\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.3550 - val_loss: 55.8902\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.4685 - val_loss: 53.6357\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.0296 - val_loss: 54.4494\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.9678 - val_loss: 54.1361\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5065 - val_loss: 54.9556\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.0847 - val_loss: 57.2126\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.2586 - val_loss: 53.4821\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6328 - val_loss: 54.0153\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.2651 - val_loss: 54.0987\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9670 - val_loss: 55.5225\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8842 - val_loss: 58.2077\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 37.2845 - val_loss: 55.3960\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.2294 - val_loss: 57.0274\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.1600 - val_loss: 56.3803\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.7059 - val_loss: 53.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6756 - val_loss: 54.5479\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.0202 - val_loss: 54.0247\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.3764 - val_loss: 55.0664\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5635 - val_loss: 55.2130\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.4801 - val_loss: 54.1439\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.4257 - val_loss: 56.1953\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 36.3910 - val_loss: 61.7532\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.0104 - val_loss: 55.2144\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 36.2342 - val_loss: 54.5415\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.3158 - val_loss: 57.7909\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9838 - val_loss: 54.8860\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.1968 - val_loss: 54.7441\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.9913 - val_loss: 53.6255\n",
      "\n",
      "Mean Squared Error for iteration11: 50.56330530140972\n",
      "\n",
      "Iteration: 12\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 35.1122 - val_loss: 54.2420\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.8099 - val_loss: 56.8734\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.2898 - val_loss: 53.8274\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.2498 - val_loss: 54.6523\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.2182 - val_loss: 53.0528\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.4577 - val_loss: 53.8938\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.5339 - val_loss: 54.7823\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.7992 - val_loss: 55.3489\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.2844 - val_loss: 54.3866\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.4569 - val_loss: 53.4814\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5227 - val_loss: 54.8751\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.9351 - val_loss: 53.9016\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.3777 - val_loss: 54.1590\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5230 - val_loss: 53.5177\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.0563 - val_loss: 58.0068\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.7543 - val_loss: 53.5861\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.8637 - val_loss: 56.5103\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 36.4486 - val_loss: 55.5976\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6714 - val_loss: 53.9296\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.4840 - val_loss: 54.3448\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.2626 - val_loss: 56.6951\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5183 - val_loss: 53.4185\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.8959 - val_loss: 54.5478\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.4601 - val_loss: 54.0348\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.9290 - val_loss: 57.1542\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.1588 - val_loss: 54.3189\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.8137 - val_loss: 54.8884\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.5662 - val_loss: 54.2386\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 36.4859 - val_loss: 59.9696\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 35.7381 - val_loss: 53.0785\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 35.4022 - val_loss: 54.2351\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.4174 - val_loss: 55.6113\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 35.1452 - val_loss: 56.3021\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 35.2605 - val_loss: 54.2535\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 34.4011 - val_loss: 55.4341\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.8847 - val_loss: 53.9405\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.6579 - val_loss: 54.0848\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.5902 - val_loss: 54.5116\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9990 - val_loss: 54.3285\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 38.1616 - val_loss: 58.0790\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.0123 - val_loss: 55.1385\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1843 - val_loss: 53.5154\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.7095 - val_loss: 58.6688\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.9155 - val_loss: 55.3817\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.1988 - val_loss: 54.1814\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9273 - val_loss: 54.6621\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 37.1021 - val_loss: 58.5831\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.5280 - val_loss: 54.9103\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.3349 - val_loss: 56.4510\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.3672 - val_loss: 53.6210\n",
      "\n",
      "Mean Squared Error for iteration12: 50.52495258833162\n",
      "\n",
      "Iteration: 13\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.8326 - val_loss: 54.3539\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.6787 - val_loss: 54.0572\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.4874 - val_loss: 57.4076\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.2502 - val_loss: 55.2704\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.7424 - val_loss: 53.5278\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.7503 - val_loss: 55.8366\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.7694 - val_loss: 55.6262\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 37.1350 - val_loss: 57.1542\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 37.3338 - val_loss: 56.1043\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.3138 - val_loss: 54.1135\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 38.0374 - val_loss: 60.5406\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.9680 - val_loss: 54.2395\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9304 - val_loss: 59.2056\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 78us/step - loss: 38.3797 - val_loss: 55.9078\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9447 - val_loss: 55.6098\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.1945 - val_loss: 53.5886\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.3157 - val_loss: 54.1487\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.1918 - val_loss: 54.5523\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.0384 - val_loss: 53.8618\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.2489 - val_loss: 53.4274\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.5647 - val_loss: 54.6310\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.1849 - val_loss: 53.9286\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.3214 - val_loss: 55.9806\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.4250 - val_loss: 53.4457\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.4206 - val_loss: 54.2569\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.4665 - val_loss: 54.8005\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.2661 - val_loss: 53.6888\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.7751 - val_loss: 53.9366\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.2785 - val_loss: 54.1154\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.3812 - val_loss: 53.6522\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.5267 - val_loss: 54.4800\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 35.9320 - val_loss: 54.3666\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.6094 - val_loss: 53.8803\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.2236 - val_loss: 53.7953\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.2436 - val_loss: 58.3418\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.7321 - val_loss: 53.4584\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.4154 - val_loss: 53.6378\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.3796 - val_loss: 54.3322\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9828 - val_loss: 55.5674\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.7582 - val_loss: 53.6464\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.2051 - val_loss: 55.3484\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.4380 - val_loss: 53.7788\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.3151 - val_loss: 54.2743\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0828 - val_loss: 54.3206\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 38.3206 - val_loss: 54.6641\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 36.4980 - val_loss: 54.4750\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.1873 - val_loss: 55.8329\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.7772 - val_loss: 54.6357\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7640 - val_loss: 53.2924\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5574 - val_loss: 53.8977\n",
      "\n",
      "Mean Squared Error for iteration13: 50.56153508165196\n",
      "\n",
      "Iteration: 14\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.0547 - val_loss: 54.2961\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.4253 - val_loss: 53.7634\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3301 - val_loss: 53.4510\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.4686 - val_loss: 54.0173\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.7911 - val_loss: 56.3427\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.1313 - val_loss: 56.2356\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5337 - val_loss: 53.5145\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.5148 - val_loss: 54.2965\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.8160 - val_loss: 54.4346\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.9359 - val_loss: 53.7391\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.8295 - val_loss: 57.1503\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.1702 - val_loss: 53.8147\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9083 - val_loss: 54.2225\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.8304 - val_loss: 53.8997\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6222 - val_loss: 53.4312\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6844 - val_loss: 55.3094\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0734 - val_loss: 53.2144\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.6201 - val_loss: 54.5819\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.6718 - val_loss: 53.1442\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.4006 - val_loss: 53.8795\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.5055 - val_loss: 53.3285\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 37.1418 - val_loss: 59.2015\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 37.3898 - val_loss: 57.5810\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.8272 - val_loss: 54.3256\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.2954 - val_loss: 53.4201\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5187 - val_loss: 54.1752\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 35.0778 - val_loss: 55.1937\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.9537 - val_loss: 53.7679\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5067 - val_loss: 53.6378\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.4846 - val_loss: 54.0661\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 36.2155 - val_loss: 55.0092\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.2487 - val_loss: 54.5982\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.7859 - val_loss: 54.3084\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.4854 - val_loss: 55.7534\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.8814 - val_loss: 53.3235\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.4586 - val_loss: 56.9583\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.1239 - val_loss: 53.2408\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.3838 - val_loss: 54.8018\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.2636 - val_loss: 55.0232\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.3815 - val_loss: 53.5543\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.8565 - val_loss: 56.7099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.7871 - val_loss: 55.1986\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.2528 - val_loss: 54.3137\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8105 - val_loss: 53.7180\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.9768 - val_loss: 54.4961\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.6448 - val_loss: 56.0195\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.7752 - val_loss: 54.9334\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.3365 - val_loss: 54.4481\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.4668 - val_loss: 54.5605\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1924 - val_loss: 53.8223\n",
      "\n",
      "Mean Squared Error for iteration14: 50.879939106929115\n",
      "\n",
      "Iteration: 15\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.6782 - val_loss: 54.4423\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.4005 - val_loss: 53.8955\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.0977 - val_loss: 53.5461\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.6598 - val_loss: 54.4784\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.9504 - val_loss: 60.2770\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.2600 - val_loss: 54.7889\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8809 - val_loss: 53.4724\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.5625 - val_loss: 55.2504\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.3347 - val_loss: 58.2852\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.4155 - val_loss: 57.8149\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.8986 - val_loss: 53.8494\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5899 - val_loss: 55.5739\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5871 - val_loss: 53.7101\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0862 - val_loss: 53.5479\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.8699 - val_loss: 56.2901\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.7764 - val_loss: 54.1705\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.5854 - val_loss: 56.0603\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 36.4834 - val_loss: 53.3780\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.5941 - val_loss: 54.1325\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5639 - val_loss: 52.8986\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.2306 - val_loss: 54.4610\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.3723 - val_loss: 53.3466\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.3989 - val_loss: 53.8742\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6497 - val_loss: 55.1164\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.3598 - val_loss: 54.1771\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.8164 - val_loss: 54.3566\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.6916 - val_loss: 53.3535\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.8893 - val_loss: 55.9967\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.8906 - val_loss: 53.1126\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.8338 - val_loss: 55.3929\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.5516 - val_loss: 59.8092\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 36.9144 - val_loss: 56.9322\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.1021 - val_loss: 54.6918\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.3729 - val_loss: 53.6557\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.2638 - val_loss: 54.1731\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.2663 - val_loss: 53.7102\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.3920 - val_loss: 54.7562\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0473 - val_loss: 54.4937\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.7460 - val_loss: 53.5405\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.8131 - val_loss: 57.3362\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.0992 - val_loss: 54.1711\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.1214 - val_loss: 56.5168\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.7956 - val_loss: 53.5904\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 36.0279 - val_loss: 53.6265\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.7335 - val_loss: 54.6563\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.7044 - val_loss: 53.2897\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.9721 - val_loss: 53.7071\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 35.0256 - val_loss: 54.0516\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.5465 - val_loss: 56.1429\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 241us/step - loss: 36.5996 - val_loss: 53.8306\n",
      "\n",
      "Mean Squared Error for iteration15: 50.5911131946049\n",
      "\n",
      "Iteration: 16\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.8959 - val_loss: 53.1980\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.8358 - val_loss: 55.4915\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 34.8665 - val_loss: 54.1230\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 34.4809 - val_loss: 54.0360\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 35.1448 - val_loss: 59.4699\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 36.5192 - val_loss: 53.3834\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.7112 - val_loss: 56.0406\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 34.5202 - val_loss: 53.7296\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 34.9998 - val_loss: 53.1259\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 37.2461 - val_loss: 59.4608\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.4669 - val_loss: 53.3680\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.1775 - val_loss: 54.2492\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.6821 - val_loss: 59.5685\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 34.7695 - val_loss: 53.8816\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.6258 - val_loss: 53.8065\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 182us/step - loss: 37.0691 - val_loss: 54.6551\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 145us/step - loss: 36.1196 - val_loss: 58.1497\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 172us/step - loss: 35.0661 - val_loss: 54.8857\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 34.4639 - val_loss: 55.0862\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.8294 - val_loss: 53.2094\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.4165 - val_loss: 56.5756\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 34.9359 - val_loss: 53.8371\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 163us/step - loss: 34.3482 - val_loss: 54.2804\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 162us/step - loss: 34.9345 - val_loss: 54.4145\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 34.5183 - val_loss: 54.3578\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 35.4030 - val_loss: 56.2603\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 37.0564 - val_loss: 53.4374\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 135us/step - loss: 35.2340 - val_loss: 53.7659\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 35.3295 - val_loss: 53.4909\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.0923 - val_loss: 53.9572\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 34.8909 - val_loss: 53.8036\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 34.3286 - val_loss: 53.5950\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 35.0557 - val_loss: 54.1284\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 36.3538 - val_loss: 54.7599\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.8550 - val_loss: 55.0464\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.5055 - val_loss: 55.7827\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.1808 - val_loss: 54.7107\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.4494 - val_loss: 54.5875\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.2160 - val_loss: 54.8378\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.7099 - val_loss: 54.7688\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 34.8644 - val_loss: 53.3136\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 252us/step - loss: 34.2323 - val_loss: 53.8110\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 206us/step - loss: 34.7694 - val_loss: 56.0219\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 152us/step - loss: 34.5059 - val_loss: 54.6785\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 35.5197 - val_loss: 57.5414\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 36.9139 - val_loss: 59.6647\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 35.7903 - val_loss: 53.4821\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9351 - val_loss: 54.2223\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.7330 - val_loss: 54.5270\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.0930 - val_loss: 55.0174\n",
      "\n",
      "Mean Squared Error for iteration16: 51.18277291180999\n",
      "\n",
      "Iteration: 17\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6483 - val_loss: 53.6151\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 37.1996 - val_loss: 53.5378\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 163us/step - loss: 34.3202 - val_loss: 54.1207\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 167us/step - loss: 34.9068 - val_loss: 54.2145\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 118us/step - loss: 34.6033 - val_loss: 54.9373\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.4308 - val_loss: 53.5602\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.2198 - val_loss: 57.7440\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.5182 - val_loss: 53.4465\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 34.4342 - val_loss: 53.7395\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 35.3850 - val_loss: 54.0789\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 35.0178 - val_loss: 54.0326\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 35.0750 - val_loss: 56.6085\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 34.8599 - val_loss: 56.1890\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.4367 - val_loss: 53.6970\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.6116 - val_loss: 53.4765\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7628 - val_loss: 53.1340\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6058 - val_loss: 53.9671\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6424 - val_loss: 54.0080\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.4027 - val_loss: 53.8567\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.1788 - val_loss: 54.3574\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.1205 - val_loss: 53.6046\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.1460 - val_loss: 53.1947\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.2344 - val_loss: 53.5005\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.4818 - val_loss: 54.0833\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.6559 - val_loss: 53.4596\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.2509 - val_loss: 55.1590\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.6413 - val_loss: 59.2184\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.2496 - val_loss: 54.4846\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.2716 - val_loss: 53.4701\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.6876 - val_loss: 53.5174\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 36.3393 - val_loss: 54.2523\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.9052 - val_loss: 54.5498\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.4443 - val_loss: 53.9100\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 37.5058 - val_loss: 53.8871\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 36.2627 - val_loss: 56.2314\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5633 - val_loss: 55.0826\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.3233 - val_loss: 53.4516\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.3282 - val_loss: 53.3349\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5787 - val_loss: 55.4670\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5672 - val_loss: 53.5398\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.9783 - val_loss: 59.2345\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5745 - val_loss: 63.7866\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 37.0254 - val_loss: 54.8799\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.2926 - val_loss: 53.0569\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 72us/step - loss: 34.6548 - val_loss: 54.0537\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.6142 - val_loss: 55.0358\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.0074 - val_loss: 55.7948\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.6812 - val_loss: 53.7234\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.2499 - val_loss: 54.6402\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8093 - val_loss: 53.5215\n",
      "\n",
      "Mean Squared Error for iteration17: 50.280977848723474\n",
      "\n",
      "Iteration: 18\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.1444 - val_loss: 53.4777\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 35.2664 - val_loss: 60.5783\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.1833 - val_loss: 53.1831\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.3971 - val_loss: 53.6552\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.0846 - val_loss: 54.1318\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.8030 - val_loss: 57.0432\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.6283 - val_loss: 54.3442\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.4280 - val_loss: 54.1403\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5738 - val_loss: 53.7917\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.9986 - val_loss: 54.1796\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.6188 - val_loss: 54.9213\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5243 - val_loss: 54.6118\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.4928 - val_loss: 53.7371\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.4165 - val_loss: 53.7869\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.8869 - val_loss: 54.8216\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 35.7209 - val_loss: 54.6371\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.1360 - val_loss: 55.4013\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.7315 - val_loss: 53.1593\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.9620 - val_loss: 54.1124\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5265 - val_loss: 55.7076\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.6830 - val_loss: 54.3934\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3148 - val_loss: 53.7745\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.4686 - val_loss: 55.9971\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.3825 - val_loss: 53.7950\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.4524 - val_loss: 54.0130\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5550 - val_loss: 55.6410\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.2498 - val_loss: 56.5196\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.9024 - val_loss: 53.8701\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.7970 - val_loss: 56.7874\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.6179 - val_loss: 54.7490\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.4266 - val_loss: 53.5757\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3167 - val_loss: 57.4544\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.4913 - val_loss: 54.1302\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.8656 - val_loss: 53.9907\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6302 - val_loss: 58.9795\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.1264 - val_loss: 53.4854\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.8289 - val_loss: 56.7353\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 37.2812 - val_loss: 57.1878\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 35.5088 - val_loss: 54.0100\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.3905 - val_loss: 54.4242\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.8715 - val_loss: 53.2116\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.7566 - val_loss: 56.6856\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.8968 - val_loss: 55.8531\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.6559 - val_loss: 53.3341\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.8311 - val_loss: 54.1076\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.3504 - val_loss: 54.1552\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.1842 - val_loss: 57.6124\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.8727 - val_loss: 55.2367\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.5003 - val_loss: 53.1741\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.7534 - val_loss: 54.9178\n",
      "\n",
      "Mean Squared Error for iteration18: 50.44471844908444\n",
      "\n",
      "Iteration: 19\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.0667 - val_loss: 54.0079\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.2675 - val_loss: 53.9271\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5227 - val_loss: 54.3128\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.7530 - val_loss: 53.3730\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.4358 - val_loss: 53.5762\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.3322 - val_loss: 53.0900\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.3013 - val_loss: 53.5397\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.5602 - val_loss: 55.4278\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.6166 - val_loss: 55.3366\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.4395 - val_loss: 53.6543\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.7055 - val_loss: 53.6744\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.4674 - val_loss: 54.4142\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.1876 - val_loss: 53.8385\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5477 - val_loss: 54.3775\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.9609 - val_loss: 53.5078\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.0501 - val_loss: 54.5366\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.6941 - val_loss: 53.7801\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.7456 - val_loss: 54.4042\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 37.3196 - val_loss: 56.6696\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 37.9090 - val_loss: 56.0251\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 39.2378 - val_loss: 61.7264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.8905 - val_loss: 54.1319\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.6883 - val_loss: 56.4107\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.4809 - val_loss: 59.7789\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.8362 - val_loss: 55.4593\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5359 - val_loss: 54.0319\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.3741 - val_loss: 53.7846\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 37.3496 - val_loss: 56.3526\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7470 - val_loss: 56.8339\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.3735 - val_loss: 53.8216\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.2605 - val_loss: 53.7767\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 36.5751 - val_loss: 59.6439\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.3303 - val_loss: 62.0192\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.9447 - val_loss: 53.2846\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6510 - val_loss: 58.2537\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.9198 - val_loss: 53.9892\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7776 - val_loss: 53.3563\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5832 - val_loss: 54.0393\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 36.2648 - val_loss: 55.9336\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 37.4388 - val_loss: 54.7535\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.2441 - val_loss: 56.7550\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 39.1413 - val_loss: 53.7728\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.4869 - val_loss: 53.7016\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.3047 - val_loss: 53.5669\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5840 - val_loss: 54.5812\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.5869 - val_loss: 54.1775\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.3953 - val_loss: 54.2373\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.6397 - val_loss: 54.0425\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.0747 - val_loss: 53.7203\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.5935 - val_loss: 55.1499\n",
      "\n",
      "Mean Squared Error for iteration19: 51.49137108835086\n",
      "\n",
      "Iteration: 20\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.3189 - val_loss: 53.3440\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.8953 - val_loss: 53.6909\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.6850 - val_loss: 53.4103\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.5436 - val_loss: 53.4737\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 34.2438 - val_loss: 54.4906\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.2818 - val_loss: 53.2491\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 35.4782 - val_loss: 55.5392\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 134us/step - loss: 35.3553 - val_loss: 53.9654\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 210us/step - loss: 34.0634 - val_loss: 54.0968\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 34.0541 - val_loss: 53.5144\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 36.1066 - val_loss: 55.0858\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 34.8004 - val_loss: 55.6802\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 36.9721 - val_loss: 54.9014\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 36.9196 - val_loss: 53.9376\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.6672 - val_loss: 55.3834\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.2162 - val_loss: 58.5095\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.2111 - val_loss: 53.3520\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 34.5612 - val_loss: 54.8003\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.5144 - val_loss: 53.4974\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.8048 - val_loss: 56.7272\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 34.1726 - val_loss: 53.3692\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.1355 - val_loss: 54.6905\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.2597 - val_loss: 55.1974\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 181us/step - loss: 34.3199 - val_loss: 53.8241\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 172us/step - loss: 34.8457 - val_loss: 57.5632\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 502us/step - loss: 35.3152 - val_loss: 53.0641\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 307us/step - loss: 34.3188 - val_loss: 54.0631\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 35.2571 - val_loss: 57.1539\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 198us/step - loss: 34.2574 - val_loss: 57.2095\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 156us/step - loss: 35.3563 - val_loss: 57.9208\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 213us/step - loss: 34.8766 - val_loss: 59.6936\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 241us/step - loss: 36.0765 - val_loss: 55.1448\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 170us/step - loss: 36.0007 - val_loss: 54.3480\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 266us/step - loss: 34.6454 - val_loss: 54.5159\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 34.5641 - val_loss: 54.8440\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 159us/step - loss: 34.8438 - val_loss: 53.3424\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 34.1196 - val_loss: 53.5679\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 171us/step - loss: 34.5358 - val_loss: 53.2031\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 318us/step - loss: 33.8050 - val_loss: 55.8439\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 124us/step - loss: 36.0038 - val_loss: 53.7667\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 35.6222 - val_loss: 53.0546\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 155us/step - loss: 34.7330 - val_loss: 54.1401\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 36.4724 - val_loss: 56.2404\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 147us/step - loss: 34.8691 - val_loss: 58.1779\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 35.5776 - val_loss: 53.9119\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 34.4612 - val_loss: 53.2059\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 34.6859 - val_loss: 54.0753\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 34.2330 - val_loss: 53.1726\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 153us/step - loss: 34.4441 - val_loss: 53.8974\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 171us/step - loss: 34.0425 - val_loss: 53.9841\n",
      "\n",
      "Mean Squared Error for iteration20: 50.370453351727186\n",
      "\n",
      "Iteration: 21\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 297us/step - loss: 34.3799 - val_loss: 53.1851\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 202us/step - loss: 34.7160 - val_loss: 57.8322\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 35.9470 - val_loss: 53.6871\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 34.9623 - val_loss: 53.9747\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 34.5168 - val_loss: 54.0403\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 35.3554 - val_loss: 55.3114\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 136us/step - loss: 35.3085 - val_loss: 53.9214\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.7834 - val_loss: 53.3214\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.4975 - val_loss: 53.0043\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.0376 - val_loss: 53.6893\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.8965 - val_loss: 53.7534\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.0728 - val_loss: 54.0622\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5265 - val_loss: 54.4145\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.4902 - val_loss: 54.3698\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.2408 - val_loss: 53.9154\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.2319 - val_loss: 53.7176\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 245us/step - loss: 34.2440 - val_loss: 54.3162\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 155us/step - loss: 34.7524 - val_loss: 53.5854\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 33.9186 - val_loss: 54.0991\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.3684 - val_loss: 53.4063\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 34.5236 - val_loss: 53.8658\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.5631 - val_loss: 53.6399\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.2372 - val_loss: 53.1200\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.9745 - val_loss: 53.4097\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 35.0694 - val_loss: 56.4931\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 34.3225 - val_loss: 53.2788\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.8400 - val_loss: 54.0219\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.2011 - val_loss: 53.8897\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5038 - val_loss: 53.1501\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.0579 - val_loss: 54.2456\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.1834 - val_loss: 53.0383\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.3455 - val_loss: 54.7091\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.1695 - val_loss: 58.0015\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.1608 - val_loss: 55.2497\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.3866 - val_loss: 54.0385\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.2182 - val_loss: 54.7375\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.9902 - val_loss: 54.0733\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 34.3274 - val_loss: 55.2035\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.3840 - val_loss: 61.5953\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 37.1879 - val_loss: 53.8454\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 37.3282 - val_loss: 53.5330\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 36.5319 - val_loss: 56.5969\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.6754 - val_loss: 56.4273\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.5768 - val_loss: 54.4614\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5968 - val_loss: 53.1640\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7901 - val_loss: 53.8890\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.4524 - val_loss: 54.7396\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.9845 - val_loss: 61.2132\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 36.8576 - val_loss: 54.8634\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 36.7171 - val_loss: 53.9579\n",
      "\n",
      "Mean Squared Error for iteration21: 50.50158131285122\n",
      "\n",
      "Iteration: 22\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9206 - val_loss: 54.8474\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.3448 - val_loss: 54.2176\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.0694 - val_loss: 53.7406\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.0669 - val_loss: 53.5734\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.3611 - val_loss: 54.3229\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5921 - val_loss: 53.7015\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.2484 - val_loss: 53.2331\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.5926 - val_loss: 55.3580\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.1285 - val_loss: 53.0199\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.2968 - val_loss: 53.8738\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5805 - val_loss: 53.6620\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.3328 - val_loss: 53.3174\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8347 - val_loss: 58.6986\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.1209 - val_loss: 53.6827\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.4389 - val_loss: 54.3554\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.7122 - val_loss: 54.2331\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.1777 - val_loss: 53.3701\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.2446 - val_loss: 53.2627\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.0409 - val_loss: 55.7729\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.6740 - val_loss: 55.7679\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.8328 - val_loss: 55.4080\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.6230 - val_loss: 54.2119\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.6974 - val_loss: 53.4508\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.8795 - val_loss: 53.5173\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 75us/step - loss: 34.1090 - val_loss: 54.6544\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.6843 - val_loss: 54.0051\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.7431 - val_loss: 53.1373\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.3480 - val_loss: 53.9124\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.2158 - val_loss: 53.5972\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 37.8445 - val_loss: 59.3063\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 35.3871 - val_loss: 53.7755\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.1287 - val_loss: 53.9404\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.6895 - val_loss: 52.7597\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.8103 - val_loss: 55.3635\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 35.6874 - val_loss: 54.2422\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.9869 - val_loss: 53.5669\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.9422 - val_loss: 53.5830\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 36.4017 - val_loss: 61.4947\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.7170 - val_loss: 57.0763\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.7850 - val_loss: 53.3451\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.5090 - val_loss: 56.8424\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 262us/step - loss: 36.8234 - val_loss: 54.4702\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 36.8893 - val_loss: 56.8781\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.5475 - val_loss: 54.1934\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.5095 - val_loss: 55.0125\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.4663 - val_loss: 53.4035\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.1908 - val_loss: 54.0696\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.0920 - val_loss: 53.3119\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.8902 - val_loss: 53.8368\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.0373 - val_loss: 54.4099\n",
      "\n",
      "Mean Squared Error for iteration22: 52.06077701410863\n",
      "\n",
      "Iteration: 23\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.9364 - val_loss: 55.3139\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.2747 - val_loss: 52.7258\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 314us/step - loss: 33.9754 - val_loss: 54.7431\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 35.3673 - val_loss: 54.8040\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 34.1993 - val_loss: 53.3245\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.9208 - val_loss: 53.5352\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.4198 - val_loss: 54.9589\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.0247 - val_loss: 53.1098\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.1212 - val_loss: 54.5840\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.6528 - val_loss: 53.3729\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 35.0763 - val_loss: 53.1220\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.9038 - val_loss: 54.8303\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.3125 - val_loss: 53.2236\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.4534 - val_loss: 54.9354\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.7920 - val_loss: 53.9929\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.1063 - val_loss: 54.5905\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5319 - val_loss: 54.1600\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.8705 - val_loss: 53.9652\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.3634 - val_loss: 54.5591\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 308us/step - loss: 34.0459 - val_loss: 54.2410\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 288us/step - loss: 35.6873 - val_loss: 57.6569\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 179us/step - loss: 35.0445 - val_loss: 53.5573\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 171us/step - loss: 35.0515 - val_loss: 53.5545\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.2775 - val_loss: 56.6458\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.5607 - val_loss: 53.4333\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 208us/step - loss: 35.0113 - val_loss: 54.5977\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 37.3622 - val_loss: 61.5370\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 36.8098 - val_loss: 56.3205\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.4387 - val_loss: 55.4799\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.9463 - val_loss: 53.9027\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.2887 - val_loss: 54.0129\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.8852 - val_loss: 53.7782\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 33.8408 - val_loss: 55.3230\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.3590 - val_loss: 53.7069\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 34.4122 - val_loss: 55.0629\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8502 - val_loss: 53.8829\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5210 - val_loss: 53.3611\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.9117 - val_loss: 55.0606\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 38.1050 - val_loss: 53.6152\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5367 - val_loss: 54.4230\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.5979 - val_loss: 53.8069\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5577 - val_loss: 54.3778\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.2632 - val_loss: 55.5856\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5000 - val_loss: 57.1519\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.3379 - val_loss: 53.6632\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 36.2665 - val_loss: 53.9080\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8543 - val_loss: 53.9402\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8753 - val_loss: 57.3734\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.4292 - val_loss: 54.0116\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.9331 - val_loss: 53.2825\n",
      "\n",
      "Mean Squared Error for iteration23: 50.215795219836245\n",
      "\n",
      "Iteration: 24\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 66us/step - loss: 35.2187 - val_loss: 54.1012\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.5096 - val_loss: 53.5657\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.0614 - val_loss: 55.1038\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.3269 - val_loss: 53.4523\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.4622 - val_loss: 53.1250\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.8048 - val_loss: 55.2674\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.3402 - val_loss: 53.4853\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.8127 - val_loss: 53.5944\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.3599 - val_loss: 53.5721\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.4077 - val_loss: 53.9778\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.8772 - val_loss: 55.9553\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.5086 - val_loss: 53.3163\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5789 - val_loss: 53.7934\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.0125 - val_loss: 53.7641\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.9353 - val_loss: 53.8670\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.1038 - val_loss: 57.3386\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.1852 - val_loss: 54.8240\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.3542 - val_loss: 54.1491\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.1044 - val_loss: 54.2467\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.1070 - val_loss: 53.5066\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.9327 - val_loss: 56.3282\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.5069 - val_loss: 55.5263\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.1077 - val_loss: 53.4763\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.4850 - val_loss: 54.6983\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 262us/step - loss: 34.0737 - val_loss: 54.0917\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 36.6418 - val_loss: 56.6668\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 135us/step - loss: 34.4436 - val_loss: 54.0958\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.9550 - val_loss: 56.3451\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.5509 - val_loss: 54.0841\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.0223 - val_loss: 53.3819\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.7323 - val_loss: 52.4743\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.5415 - val_loss: 54.0542\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 292us/step - loss: 35.0672 - val_loss: 55.6360\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 35.0610 - val_loss: 53.6612\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 130us/step - loss: 34.4726 - val_loss: 52.9122\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 34.6414 - val_loss: 54.8741\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.5775 - val_loss: 53.3420\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 127us/step - loss: 36.2640 - val_loss: 54.7811\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 34.4520 - val_loss: 54.2954\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 35.6488 - val_loss: 54.3290\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 35.3109 - val_loss: 53.5905\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 34.0196 - val_loss: 53.5117\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 34.2848 - val_loss: 54.1621\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 34.7953 - val_loss: 54.6155\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 227us/step - loss: 35.5650 - val_loss: 57.3976\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 147us/step - loss: 35.1481 - val_loss: 55.3341\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 198us/step - loss: 35.7896 - val_loss: 53.9364\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 35.7426 - val_loss: 54.1191\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 171us/step - loss: 34.3681 - val_loss: 54.2118\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 35.1103 - val_loss: 53.8227\n",
      "\n",
      "Mean Squared Error for iteration24: 51.28994590671447\n",
      "\n",
      "Iteration: 25\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 201us/step - loss: 33.9988 - val_loss: 53.4219\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 35.6544 - val_loss: 53.4972\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 35.4491 - val_loss: 55.6606\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 34.4221 - val_loss: 54.3824\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 132us/step - loss: 34.0037 - val_loss: 53.2311\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 34.4586 - val_loss: 53.2969\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 34.7623 - val_loss: 54.1290\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 34.5837 - val_loss: 53.2282\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 35.0891 - val_loss: 54.8543\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 261us/step - loss: 34.2024 - val_loss: 54.4173\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 203us/step - loss: 34.1220 - val_loss: 54.0923\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 34.0064 - val_loss: 55.3773\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 34.4087 - val_loss: 53.8481\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 34.6125 - val_loss: 54.2741\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 114us/step - loss: 34.9835 - val_loss: 54.0089\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 34.2125 - val_loss: 58.2748\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 35.5471 - val_loss: 53.5943\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 35.5380 - val_loss: 53.7290\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 120us/step - loss: 34.9256 - val_loss: 53.6212\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.2142 - val_loss: 54.1356\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 33.7432 - val_loss: 54.6784\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.0024 - val_loss: 53.5256\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.3455 - val_loss: 57.3098\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.0368 - val_loss: 54.1039\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.7282 - val_loss: 56.5201\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 192us/step - loss: 35.5324 - val_loss: 53.3289\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 154us/step - loss: 34.1020 - val_loss: 53.6190\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 169us/step - loss: 34.1155 - val_loss: 55.0246\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 129us/step - loss: 33.7397 - val_loss: 53.8069\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 120us/step - loss: 33.6990 - val_loss: 54.2604\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.2246 - val_loss: 56.5888\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 37.7269 - val_loss: 55.5983\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.4083 - val_loss: 52.2949\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.9507 - val_loss: 53.6727\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.9165 - val_loss: 55.2039\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.3456 - val_loss: 56.8445\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 35.1335 - val_loss: 54.9526\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 35.6815 - val_loss: 55.2307\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 185us/step - loss: 35.3793 - val_loss: 54.5118\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 35.6357 - val_loss: 53.8340\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.2884 - val_loss: 54.7986\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.7593 - val_loss: 53.2825\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.5359 - val_loss: 54.9363\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 36.8634 - val_loss: 60.1721\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.0149 - val_loss: 54.1307\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.7625 - val_loss: 53.2459\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.0167 - val_loss: 53.8054\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.2213 - val_loss: 54.8358\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.7489 - val_loss: 53.8462\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.4614 - val_loss: 57.2086\n",
      "\n",
      "Mean Squared Error for iteration25: 52.52041096071995\n",
      "\n",
      "Iteration: 26\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 35.2333 - val_loss: 53.6048\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.0110 - val_loss: 54.3671\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 33.9302 - val_loss: 54.0667\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.3012 - val_loss: 53.0352\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.8197 - val_loss: 56.5262\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.7634 - val_loss: 55.4363\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.7964 - val_loss: 56.7063\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 38.3631 - val_loss: 60.0952\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 37.9807 - val_loss: 54.4921\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.9510 - val_loss: 55.9057\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 200us/step - loss: 34.7375 - val_loss: 53.0440\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 33.6509 - val_loss: 54.6344\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 190us/step - loss: 34.4839 - val_loss: 53.3316\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 34.3918 - val_loss: 53.3139\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 34.3361 - val_loss: 53.5304\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.4122 - val_loss: 53.2438\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 34.8845 - val_loss: 54.7968\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.6246 - val_loss: 55.9957\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.5174 - val_loss: 54.1512\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.9454 - val_loss: 54.6679\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.9458 - val_loss: 54.8301\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.1179 - val_loss: 54.7463\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 35.2733 - val_loss: 53.6381\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 34.5442 - val_loss: 55.2044\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 132us/step - loss: 33.9975 - val_loss: 54.0376\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 127us/step - loss: 34.0305 - val_loss: 54.7366\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.4166 - val_loss: 55.0625\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.0961 - val_loss: 53.6748\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 33.8840 - val_loss: 53.7204\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 34.3488 - val_loss: 53.7535\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.2454 - val_loss: 56.3825\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.1580 - val_loss: 54.1275\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.8707 - val_loss: 54.8228\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.2598 - val_loss: 54.1687\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9489 - val_loss: 53.6240\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.4680 - val_loss: 53.5814\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.7620 - val_loss: 54.8318\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.8719 - val_loss: 53.7703\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.9997 - val_loss: 54.1008\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.6757 - val_loss: 54.2660\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8742 - val_loss: 54.9087\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.3688 - val_loss: 54.2652\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.8369 - val_loss: 54.6507\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.8445 - val_loss: 54.6258\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.4915 - val_loss: 54.7171\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.6373 - val_loss: 54.2900\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.3358 - val_loss: 55.1021\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.0820 - val_loss: 52.7198\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.2398 - val_loss: 53.6451\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.2147 - val_loss: 59.3793\n",
      "\n",
      "Mean Squared Error for iteration26: 53.77838450146721\n",
      "\n",
      "Iteration: 27\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.0375 - val_loss: 56.3569\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.6820 - val_loss: 55.3078\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.8276 - val_loss: 53.5940\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 77us/step - loss: 34.3561 - val_loss: 54.1080\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.3467 - val_loss: 53.4144\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.2407 - val_loss: 53.5995\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.1050 - val_loss: 52.9524\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 184us/step - loss: 34.4180 - val_loss: 54.1956\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.0001 - val_loss: 52.3673\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.0704 - val_loss: 55.5446\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.7326 - val_loss: 54.5083\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.7182 - val_loss: 55.9870\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.3438 - val_loss: 53.3805\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.6909 - val_loss: 52.7792\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.3616 - val_loss: 54.4321\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.8449 - val_loss: 54.8000\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8456 - val_loss: 54.8624\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1590 - val_loss: 58.0214\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.8150 - val_loss: 54.5390\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 34.6395 - val_loss: 54.9269\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 34.0344 - val_loss: 52.8810\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.5757 - val_loss: 53.8360\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.9279 - val_loss: 54.7207\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.0000 - val_loss: 54.0047\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.3647 - val_loss: 54.1808\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 36.5241 - val_loss: 53.0814\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.4088 - val_loss: 58.4591\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.7165 - val_loss: 54.9087\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.4294 - val_loss: 54.0881\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.9092 - val_loss: 54.4050\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.2294 - val_loss: 53.3409\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 34.5881 - val_loss: 53.9384\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.3320 - val_loss: 53.0678\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.3892 - val_loss: 52.7099\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.3074 - val_loss: 53.8391\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 34.3458 - val_loss: 53.5853\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 129us/step - loss: 33.8209 - val_loss: 53.1850\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.8182 - val_loss: 53.0865\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.0805 - val_loss: 55.4950\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.4639 - val_loss: 52.7621\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.5804 - val_loss: 58.8786\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 34.2240 - val_loss: 52.9188\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 36.1839 - val_loss: 54.0971\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 34.9963 - val_loss: 53.3993\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 183us/step - loss: 34.0157 - val_loss: 53.7591\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 33.9667 - val_loss: 54.6116\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 389us/step - loss: 34.4190 - val_loss: 54.1291\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 319us/step - loss: 34.1481 - val_loss: 53.7374\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 156us/step - loss: 34.1212 - val_loss: 53.2809\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 35.7445 - val_loss: 56.9538\n",
      "\n",
      "Mean Squared Error for iteration27: 52.8217641944465\n",
      "\n",
      "Iteration: 28\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 34.4503 - val_loss: 53.6638\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 162us/step - loss: 34.6849 - val_loss: 52.5507\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 233us/step - loss: 34.6544 - val_loss: 54.8299\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 205us/step - loss: 34.4380 - val_loss: 53.5099\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.2064 - val_loss: 53.1351\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.0723 - val_loss: 53.2274\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.3653 - val_loss: 53.2058\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.0165 - val_loss: 60.8890\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.6043 - val_loss: 55.3833\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 34.1078 - val_loss: 53.2004\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 34.0330 - val_loss: 56.5179\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.0307 - val_loss: 52.8401\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.1063 - val_loss: 53.4873\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.9064 - val_loss: 57.4883\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 35.9079 - val_loss: 57.6600\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.2419 - val_loss: 53.3701\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 138us/step - loss: 34.2190 - val_loss: 54.4675\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 181us/step - loss: 35.5214 - val_loss: 54.2604\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 196us/step - loss: 34.0958 - val_loss: 54.7999\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 171us/step - loss: 34.1932 - val_loss: 54.7285\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.3472 - val_loss: 56.2206\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.1804 - val_loss: 53.3733\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 187us/step - loss: 33.9723 - val_loss: 53.7854\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.6361 - val_loss: 53.4168\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.1815 - val_loss: 52.3453\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 36.4120 - val_loss: 60.8389\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 37.5146 - val_loss: 54.4114\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 35.0217 - val_loss: 54.5590\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 176us/step - loss: 34.8393 - val_loss: 52.4530\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 34.5785 - val_loss: 53.5891\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 178us/step - loss: 33.6701 - val_loss: 53.8554\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 247us/step - loss: 34.3770 - val_loss: 53.2247\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5166 - val_loss: 53.5037\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.0109 - val_loss: 55.6939\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.6061 - val_loss: 52.6265\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.7802 - val_loss: 54.4103\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.8895 - val_loss: 53.1620\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.8768 - val_loss: 54.1429\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.6767 - val_loss: 53.6982\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 33.6120 - val_loss: 53.3757\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.0453 - val_loss: 53.4191\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 33.8103 - val_loss: 53.3380\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.9784 - val_loss: 53.3656\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.1206 - val_loss: 52.6333\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 166us/step - loss: 34.3722 - val_loss: 53.0399\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 33.7481 - val_loss: 54.4512\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 34.2958 - val_loss: 55.5377\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 130us/step - loss: 35.6914 - val_loss: 55.4898\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.8253 - val_loss: 53.6692\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.9090 - val_loss: 53.2143\n",
      "\n",
      "Mean Squared Error for iteration28: 50.11049199407344\n",
      "\n",
      "Iteration: 29\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.5396 - val_loss: 54.0545\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 207us/step - loss: 34.0963 - val_loss: 53.4026\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 136us/step - loss: 33.7802 - val_loss: 53.9426\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 34.3368 - val_loss: 58.1717\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.0684 - val_loss: 54.3943\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 198us/step - loss: 34.1144 - val_loss: 53.3156\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 267us/step - loss: 34.1224 - val_loss: 55.2411\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 34.3805 - val_loss: 52.7018\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 337us/step - loss: 35.2126 - val_loss: 53.8360\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 209us/step - loss: 34.9932 - val_loss: 53.2722\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 160us/step - loss: 34.3008 - val_loss: 54.5683\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 227us/step - loss: 35.5453 - val_loss: 54.8728\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 198us/step - loss: 33.8159 - val_loss: 56.1374\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 284us/step - loss: 33.9880 - val_loss: 52.8468\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 182us/step - loss: 34.9540 - val_loss: 56.4360\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 160us/step - loss: 34.5299 - val_loss: 53.9730\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 222us/step - loss: 34.1862 - val_loss: 52.7410\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 35.3545 - val_loss: 57.2986\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 248us/step - loss: 34.2749 - val_loss: 53.5269\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 35.0355 - val_loss: 53.6983\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 174us/step - loss: 33.8026 - val_loss: 54.5993\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 34.5834 - val_loss: 58.5273\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 185us/step - loss: 33.8996 - val_loss: 53.7803\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 34.3339 - val_loss: 56.4658\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 189us/step - loss: 35.0180 - val_loss: 54.2647\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 187us/step - loss: 33.8262 - val_loss: 54.4765\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 140us/step - loss: 33.7198 - val_loss: 55.1695\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 134us/step - loss: 34.1692 - val_loss: 54.7597\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 213us/step - loss: 35.2180 - val_loss: 56.8811\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 34.2495 - val_loss: 53.1221\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 34.3419 - val_loss: 53.8185\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 34.2147 - val_loss: 56.7862\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 35.2423 - val_loss: 53.4912\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 34.1122 - val_loss: 54.3355\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 121us/step - loss: 33.9840 - val_loss: 53.1878\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 127us/step - loss: 34.4841 - val_loss: 56.2682\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 143us/step - loss: 35.4604 - val_loss: 53.6608\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 34.2936 - val_loss: 52.9443\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 34.4695 - val_loss: 55.4634\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 34.2465 - val_loss: 52.8327\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 34.0720 - val_loss: 53.6283\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 34.1015 - val_loss: 54.1491\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.2315 - val_loss: 55.4628\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.5795 - val_loss: 54.2838\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 124us/step - loss: 33.8390 - val_loss: 53.4614\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 34.6585 - val_loss: 55.6823\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 138us/step - loss: 34.0750 - val_loss: 53.8341\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 34.0818 - val_loss: 56.0932\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 135us/step - loss: 34.0534 - val_loss: 54.6137\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 34.9459 - val_loss: 52.9800\n",
      "\n",
      "Mean Squared Error for iteration29: 50.01359869686286\n",
      "\n",
      "Iteration: 30\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 34.5376 - val_loss: 54.1710\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 35.4477 - val_loss: 58.3620\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.2143 - val_loss: 54.2166\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.6864 - val_loss: 54.4221\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.3317 - val_loss: 53.9249\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 34.1069 - val_loss: 53.6511\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 83us/step - loss: 34.0435 - val_loss: 52.6832\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.8360 - val_loss: 53.5691\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.7153 - val_loss: 53.2888\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.5961 - val_loss: 54.0921\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.8308 - val_loss: 54.9248\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.4130 - val_loss: 53.5510\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.2124 - val_loss: 54.0176\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 34.6326 - val_loss: 56.9930\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.9349 - val_loss: 54.5835\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.4738 - val_loss: 53.7614\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.2466 - val_loss: 54.5348\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.6568 - val_loss: 54.0771\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 34.6307 - val_loss: 55.7310\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 35.4721 - val_loss: 54.8108\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 36.5257 - val_loss: 55.6308\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.7643 - val_loss: 53.2948\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.7599 - val_loss: 53.9159\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.5832 - val_loss: 53.7466\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.8455 - val_loss: 57.2694\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 132us/step - loss: 33.8420 - val_loss: 54.3517\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 33.8729 - val_loss: 53.9693\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.5327 - val_loss: 54.2886\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.5822 - val_loss: 56.6707\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.0151 - val_loss: 55.4113\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 33.8794 - val_loss: 52.8569\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.8926 - val_loss: 53.7739\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.1829 - val_loss: 54.7123\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.0867 - val_loss: 55.4449\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 36.8930 - val_loss: 56.8417\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.8122 - val_loss: 55.5904\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.7645 - val_loss: 53.7066\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.5104 - val_loss: 54.7210\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.0822 - val_loss: 54.2568\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 36.2847 - val_loss: 54.5349\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.5110 - val_loss: 53.8342\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.8719 - val_loss: 56.3017\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.6114 - val_loss: 55.5803\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.1581 - val_loss: 53.8353\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 33.7719 - val_loss: 54.8633\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.8922 - val_loss: 56.2291\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.7779 - val_loss: 53.4809\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.6260 - val_loss: 57.5765\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.1523 - val_loss: 53.7152\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.1372 - val_loss: 53.9596\n",
      "\n",
      "Mean Squared Error for iteration30: 49.80111868283159\n",
      "\n",
      "Iteration: 31\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.1409 - val_loss: 54.6310\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.6367 - val_loss: 54.8779\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.1312 - val_loss: 56.1835\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.0776 - val_loss: 54.4876\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.6263 - val_loss: 53.6791\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.1468 - val_loss: 53.9973\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.9706 - val_loss: 55.0532\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.6497 - val_loss: 54.5635\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.5320 - val_loss: 53.6854\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.3644 - val_loss: 54.8910\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.7640 - val_loss: 56.5984\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.9648 - val_loss: 55.7453\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.5519 - val_loss: 54.8778\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.0787 - val_loss: 53.4120\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.8103 - val_loss: 53.2350\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.8553 - val_loss: 54.4025\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.9809 - val_loss: 53.7252\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.8268 - val_loss: 53.3532\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.1742 - val_loss: 53.8887\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.7799 - val_loss: 54.5875\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.5091 - val_loss: 56.8629\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.1359 - val_loss: 54.4413\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.4515 - val_loss: 53.3136\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.0581 - val_loss: 54.8879\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.3888 - val_loss: 57.6770\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.8695 - val_loss: 58.8186\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.2296 - val_loss: 54.7886\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.0151 - val_loss: 53.7828\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 33.5348 - val_loss: 54.7786\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.2304 - val_loss: 53.6147\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.0027 - val_loss: 54.6158\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.9732 - val_loss: 54.5050\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.0772 - val_loss: 55.2569\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.0240 - val_loss: 53.2584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.3677 - val_loss: 54.2223\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.3504 - val_loss: 55.3903\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 33.6932 - val_loss: 54.8905\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 35.0909 - val_loss: 59.0547\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 38.0921 - val_loss: 53.7649\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 36.9009 - val_loss: 55.6982\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 222us/step - loss: 34.2948 - val_loss: 53.0335\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 35.5314 - val_loss: 56.6270\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 35.0418 - val_loss: 54.6048\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.0914 - val_loss: 53.8320\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.8524 - val_loss: 53.8873\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.0784 - val_loss: 54.1429\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.8466 - val_loss: 57.1353\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.4983 - val_loss: 54.4507\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.9665 - val_loss: 56.0506\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 35.6426 - val_loss: 55.3894\n",
      "\n",
      "Mean Squared Error for iteration31: 50.001161267513055\n",
      "\n",
      "Iteration: 32\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.8070 - val_loss: 55.9202\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.2227 - val_loss: 54.2745\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 35.3472 - val_loss: 54.6002\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.9285 - val_loss: 56.9848\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 34.0922 - val_loss: 53.6613\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 35.7075 - val_loss: 60.6044\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.7642 - val_loss: 53.3176\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.9149 - val_loss: 54.2174\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.9211 - val_loss: 56.5160\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 36.5173 - val_loss: 55.1924\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5427 - val_loss: 55.5094\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.2190 - val_loss: 56.2756\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.9460 - val_loss: 52.9209\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.6663 - val_loss: 54.6175\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.2280 - val_loss: 53.3754\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 140us/step - loss: 34.1198 - val_loss: 54.3286\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 33.9579 - val_loss: 56.0937\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.8361 - val_loss: 57.3164\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.5705 - val_loss: 53.7042\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.1915 - val_loss: 54.9595\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 114us/step - loss: 33.3129 - val_loss: 53.4698\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.4747 - val_loss: 54.0027\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 34.0561 - val_loss: 54.1994\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.7351 - val_loss: 56.0750\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.6485 - val_loss: 56.3930\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 36.1139 - val_loss: 55.0730\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.6202 - val_loss: 53.8863\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 34.9124 - val_loss: 54.5681\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 151us/step - loss: 33.5594 - val_loss: 54.1798\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 33.5890 - val_loss: 53.5543\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.4496 - val_loss: 54.8269\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.9169 - val_loss: 55.5956\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.6893 - val_loss: 57.1893\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.6419 - val_loss: 54.5773\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.8564 - val_loss: 54.0130\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.8164 - val_loss: 53.3335\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 33.9615 - val_loss: 55.2428\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 33.6465 - val_loss: 53.5852\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.6637 - val_loss: 53.8377\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 34.5593 - val_loss: 55.1032\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.1530 - val_loss: 53.5271\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.8716 - val_loss: 53.9747\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.2363 - val_loss: 55.7483\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.5017 - val_loss: 53.5858\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 34.0022 - val_loss: 54.0379\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 199us/step - loss: 33.8936 - val_loss: 56.4924\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 198us/step - loss: 33.9601 - val_loss: 54.8703\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 156us/step - loss: 33.8712 - val_loss: 53.5487\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.1273 - val_loss: 56.1197\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.7609 - val_loss: 53.0927\n",
      "\n",
      "Mean Squared Error for iteration32: 49.393956656630714\n",
      "\n",
      "Iteration: 33\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.1858 - val_loss: 53.7890\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.2190 - val_loss: 58.1682\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 36.8793 - val_loss: 53.8602\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.8982 - val_loss: 53.7114\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 33.6025 - val_loss: 55.5533\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 35.3140 - val_loss: 55.5677\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 35.0080 - val_loss: 56.4377\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.5251 - val_loss: 54.8026\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.2704 - val_loss: 54.0951\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 33.9331 - val_loss: 53.6192\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 229us/step - loss: 34.0310 - val_loss: 54.8319\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 34.3267 - val_loss: 53.7691\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 179us/step - loss: 34.6918 - val_loss: 54.1629\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.2234 - val_loss: 54.3937\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 279us/step - loss: 33.8938 - val_loss: 53.8867\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 333us/step - loss: 33.6693 - val_loss: 55.3654\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 35.2150 - val_loss: 54.9017\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 35.1458 - val_loss: 55.0186\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.7931 - val_loss: 54.3302\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 33.6596 - val_loss: 55.6491\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 33.9690 - val_loss: 54.2421\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 33.9979 - val_loss: 54.3293\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 34.3967 - val_loss: 54.4574\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 204us/step - loss: 33.7716 - val_loss: 53.6706\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 216us/step - loss: 33.6920 - val_loss: 53.5569\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 33.8165 - val_loss: 54.7141\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 33.7695 - val_loss: 53.5535\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 33.8391 - val_loss: 53.4029\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 374us/step - loss: 33.5487 - val_loss: 53.9782\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 129us/step - loss: 34.5248 - val_loss: 54.9370\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 34.6013 - val_loss: 53.8160\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 34.1865 - val_loss: 55.3477\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 33.7338 - val_loss: 54.5322\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 36.0509 - val_loss: 57.3888\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 33.8883 - val_loss: 56.9703\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 36.3398 - val_loss: 54.6576\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.8797 - val_loss: 53.5550\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.5960 - val_loss: 55.1513\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.1335 - val_loss: 53.7354\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.5321 - val_loss: 56.5815\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.0576 - val_loss: 59.3188\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 37.0880 - val_loss: 54.0216\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 35.4435 - val_loss: 54.0395\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.6767 - val_loss: 53.9109\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.4572 - val_loss: 55.7094\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.4131 - val_loss: 54.7701\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.8869 - val_loss: 54.1412\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.1110 - val_loss: 54.7693\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.6097 - val_loss: 54.1616\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.4781 - val_loss: 53.6333\n",
      "\n",
      "Mean Squared Error for iteration33: 49.393129656033786\n",
      "\n",
      "Iteration: 34\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.6981 - val_loss: 58.2582\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.9402 - val_loss: 53.9474\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 34.5302 - val_loss: 55.1747\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 280us/step - loss: 34.1468 - val_loss: 54.1628\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 34.3482 - val_loss: 54.4972\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.0208 - val_loss: 57.5406\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.7770 - val_loss: 55.5449\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.1136 - val_loss: 53.1929\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.7257 - val_loss: 55.2059\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1448 - val_loss: 53.2405\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.8614 - val_loss: 53.7185\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.5201 - val_loss: 54.1028\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 33.7701 - val_loss: 54.2637\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.5535 - val_loss: 54.9920\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.2092 - val_loss: 54.0602\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.9640 - val_loss: 55.0785\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 34.4649 - val_loss: 58.4987\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 34.6827 - val_loss: 54.9317\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.8020 - val_loss: 56.3842\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.0434 - val_loss: 53.9860\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.2072 - val_loss: 53.8801\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.4790 - val_loss: 54.5376\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.2628 - val_loss: 55.1463\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.8731 - val_loss: 55.8741\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 34.7220 - val_loss: 54.8713\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.7238 - val_loss: 54.0807\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.8352 - val_loss: 53.8877\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.7076 - val_loss: 55.9794\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.0454 - val_loss: 53.9509\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.3067 - val_loss: 55.0373\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.1064 - val_loss: 54.7668\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.9411 - val_loss: 55.0060\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.5737 - val_loss: 54.0170\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.1669 - val_loss: 53.8566\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.7873 - val_loss: 54.1898\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 35.2724 - val_loss: 63.8664\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 36.3288 - val_loss: 53.8663\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 72us/step - loss: 33.8896 - val_loss: 55.4271\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.6134 - val_loss: 55.4190\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 35.9599 - val_loss: 53.7829\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.0126 - val_loss: 56.7374\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8280 - val_loss: 54.1232\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.9756 - val_loss: 57.0774\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5694 - val_loss: 55.0814\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.9227 - val_loss: 54.1730\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 36.5972 - val_loss: 53.6630\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.7954 - val_loss: 55.3965\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.0664 - val_loss: 55.2410\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.9369 - val_loss: 54.8420\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.5120 - val_loss: 54.6154\n",
      "\n",
      "Mean Squared Error for iteration34: 51.436230267216224\n",
      "\n",
      "Iteration: 35\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.4732 - val_loss: 54.5540\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.6749 - val_loss: 53.5881\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.7913 - val_loss: 54.7393\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.5162 - val_loss: 52.7682\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.0296 - val_loss: 61.7270\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.2537 - val_loss: 53.4000\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 33.9243 - val_loss: 54.3237\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.1846 - val_loss: 54.1815\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.7198 - val_loss: 54.0167\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.5447 - val_loss: 55.5218\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.9531 - val_loss: 53.8444\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.6410 - val_loss: 55.3569\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.5547 - val_loss: 53.7384\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 36.0630 - val_loss: 55.4959\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.7640 - val_loss: 53.8089\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.1120 - val_loss: 54.1848\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.6718 - val_loss: 54.4368\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.0411 - val_loss: 54.3273\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.9078 - val_loss: 54.2741\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.7603 - val_loss: 53.3033\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5975 - val_loss: 53.5070\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.5655 - val_loss: 53.6205\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.9123 - val_loss: 54.2601\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.8126 - val_loss: 53.7305\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.0243 - val_loss: 55.1617\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.7281 - val_loss: 53.0571\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.3039 - val_loss: 54.3872\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.7308 - val_loss: 54.1977\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.9385 - val_loss: 55.6861\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.9290 - val_loss: 54.6190\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.4756 - val_loss: 53.4399\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.0007 - val_loss: 58.0309\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0161 - val_loss: 54.2296\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.8744 - val_loss: 54.2351\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.7825 - val_loss: 54.3347\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.4011 - val_loss: 54.1869\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.6172 - val_loss: 53.8652\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.9912 - val_loss: 53.5427\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.3740 - val_loss: 55.5778\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.0788 - val_loss: 53.3993\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.8434 - val_loss: 54.4773\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.8057 - val_loss: 53.1037\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.8073 - val_loss: 53.5082\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.6835 - val_loss: 53.8686\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.1885 - val_loss: 54.7576\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.9799 - val_loss: 53.4876\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.0279 - val_loss: 55.1305\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.8602 - val_loss: 54.8292\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.8490 - val_loss: 56.0988\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.2994 - val_loss: 55.4640\n",
      "\n",
      "Mean Squared Error for iteration35: 49.27707351986575\n",
      "\n",
      "Iteration: 36\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.9469 - val_loss: 53.7140\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 35.4344 - val_loss: 54.6489\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.3766 - val_loss: 53.4904\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.1406 - val_loss: 55.4151\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1487 - val_loss: 53.7252\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.5730 - val_loss: 54.1005\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.5938 - val_loss: 53.7719\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.1855 - val_loss: 53.8780\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.7720 - val_loss: 55.0536\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.2223 - val_loss: 59.0585\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5803 - val_loss: 56.0584\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.5728 - val_loss: 53.8120\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.2125 - val_loss: 53.8140\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.7008 - val_loss: 54.5541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.4085 - val_loss: 53.9578\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.5895 - val_loss: 53.7045\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.1351 - val_loss: 54.6589\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.7418 - val_loss: 53.2691\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.9864 - val_loss: 59.2732\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.0405 - val_loss: 54.8674\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.6293 - val_loss: 53.7326\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.4921 - val_loss: 54.1838\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.6206 - val_loss: 53.6445\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.6616 - val_loss: 53.6796\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.9966 - val_loss: 53.2107\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.6956 - val_loss: 54.9431\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.7111 - val_loss: 53.6400\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.8406 - val_loss: 53.8007\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.1447 - val_loss: 53.7182\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7323 - val_loss: 55.9493\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.6624 - val_loss: 54.3106\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 35.6271 - val_loss: 58.5695\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5840 - val_loss: 53.9667\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.8071 - val_loss: 53.9108\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.4965 - val_loss: 55.6959\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.8654 - val_loss: 62.4898\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.2463 - val_loss: 57.0882\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.6008 - val_loss: 55.7154\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 37.6959 - val_loss: 53.1794\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 36.0847 - val_loss: 59.8889\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.5069 - val_loss: 54.0392\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.5553 - val_loss: 54.5923\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.6205 - val_loss: 54.0180\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.6112 - val_loss: 54.9285\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.3467 - val_loss: 55.0180\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.0708 - val_loss: 55.6133\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 36.0915 - val_loss: 53.2986\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.8028 - val_loss: 55.7429\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.6492 - val_loss: 53.0423\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.8404 - val_loss: 56.1598\n",
      "\n",
      "Mean Squared Error for iteration36: 51.78871964124778\n",
      "\n",
      "Iteration: 37\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 64us/step - loss: 34.6575 - val_loss: 54.0093\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.2007 - val_loss: 53.9879\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.3689 - val_loss: 54.6905\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.0601 - val_loss: 55.4572\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.4537 - val_loss: 53.6847\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.3956 - val_loss: 57.4643\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.4895 - val_loss: 54.9427\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.6133 - val_loss: 53.9824\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 35.5891 - val_loss: 55.2550\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.0315 - val_loss: 54.4146\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.6180 - val_loss: 57.2901\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.9797 - val_loss: 57.3207\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.6644 - val_loss: 53.9265\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.1724 - val_loss: 54.0272\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 35.1964 - val_loss: 53.8438\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.6619 - val_loss: 55.1491\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.2628 - val_loss: 62.9190\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.0430 - val_loss: 55.6507\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.4267 - val_loss: 53.9949\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.7671 - val_loss: 53.5289\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.8356 - val_loss: 54.6371\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.1470 - val_loss: 56.6569\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.5006 - val_loss: 55.5147\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.2922 - val_loss: 53.8261\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.9286 - val_loss: 54.1044\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.1091 - val_loss: 54.5267\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 36.7168 - val_loss: 58.2338\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 36.5158 - val_loss: 53.8047\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 141us/step - loss: 33.7299 - val_loss: 54.9902\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.1423 - val_loss: 55.7661\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 33.9269 - val_loss: 55.5157\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 34.8188 - val_loss: 53.7532\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.6306 - val_loss: 54.1203\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 33.3471 - val_loss: 55.9992\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 34.2560 - val_loss: 54.6375\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 33.4126 - val_loss: 55.8385\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 33.8659 - val_loss: 55.2526\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 34.1038 - val_loss: 53.7680\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 33.6274 - val_loss: 53.1664\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 33.6178 - val_loss: 54.2078\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 33.8141 - val_loss: 54.3276\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 85us/step - loss: 33.9857 - val_loss: 54.7593\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.1970 - val_loss: 54.0871\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.0192 - val_loss: 53.8231\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.9872 - val_loss: 53.9410\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.8712 - val_loss: 55.1537\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.7294 - val_loss: 57.1020\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.3872 - val_loss: 53.9012\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.0150 - val_loss: 53.5501\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.1841 - val_loss: 53.3480\n",
      "\n",
      "Mean Squared Error for iteration37: 48.877470730360024\n",
      "\n",
      "Iteration: 38\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.8453 - val_loss: 54.1429\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1312 - val_loss: 56.9818\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.2503 - val_loss: 53.1087\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.4223 - val_loss: 55.3048\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.8629 - val_loss: 56.6863\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.6160 - val_loss: 53.9585\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.5883 - val_loss: 53.6034\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.3596 - val_loss: 55.7341\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.3984 - val_loss: 53.6468\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.0244 - val_loss: 54.2060\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.7545 - val_loss: 53.9096\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.0511 - val_loss: 53.7095\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.4092 - val_loss: 53.4079\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.6102 - val_loss: 54.2260\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.7726 - val_loss: 55.2437\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.3851 - val_loss: 56.6351\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.3165 - val_loss: 55.5946\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 33.9745 - val_loss: 54.9597\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.7055 - val_loss: 52.9344\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.5089 - val_loss: 54.1226\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.4610 - val_loss: 54.3015\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 35.2487 - val_loss: 64.9943\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.8073 - val_loss: 54.2856\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.9446 - val_loss: 54.1773\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8313 - val_loss: 54.5036\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.9556 - val_loss: 56.3939\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 35.8090 - val_loss: 53.6598\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 35.0423 - val_loss: 54.0936\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.0201 - val_loss: 54.3223\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.8158 - val_loss: 53.9340\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.2836 - val_loss: 55.1881\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 35.0410 - val_loss: 53.3833\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.0325 - val_loss: 53.5751\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.6672 - val_loss: 57.4955\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.8458 - val_loss: 53.8555\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.9337 - val_loss: 53.4428\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.0346 - val_loss: 57.0625\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.8659 - val_loss: 53.3277\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.6523 - val_loss: 56.5547\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.3738 - val_loss: 53.7021\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.4501 - val_loss: 55.2864\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.6418 - val_loss: 54.6855\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8828 - val_loss: 53.0412\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.6511 - val_loss: 56.2542\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.1815 - val_loss: 59.9136\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 35.3496 - val_loss: 53.2813\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 34.2262 - val_loss: 54.2650\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.3141 - val_loss: 53.5268\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.4534 - val_loss: 54.8647\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 33.6024 - val_loss: 54.4346\n",
      "\n",
      "Mean Squared Error for iteration38: 49.64883326294581\n",
      "\n",
      "Iteration: 39\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.4108 - val_loss: 53.3840\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 35.0950 - val_loss: 53.9848\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.5527 - val_loss: 54.2916\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.5346 - val_loss: 53.6714\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.5799 - val_loss: 53.7416\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.7834 - val_loss: 53.5033\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.7095 - val_loss: 54.8587\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.5688 - val_loss: 55.9260\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 33.8095 - val_loss: 53.9546\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.6185 - val_loss: 56.3732\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.5585 - val_loss: 56.1445\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.2541 - val_loss: 54.2199\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.5508 - val_loss: 53.3661\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 33.6356 - val_loss: 53.5674\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.0563 - val_loss: 54.2514\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.6253 - val_loss: 53.8715\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.0827 - val_loss: 53.7831\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.8661 - val_loss: 53.7082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.8407 - val_loss: 56.8022\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.4470 - val_loss: 53.9531\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.8123 - val_loss: 54.7360\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.3993 - val_loss: 53.6284\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1199 - val_loss: 53.9574\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.3882 - val_loss: 54.2148\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 34.2438 - val_loss: 53.5137\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.7587 - val_loss: 54.6557\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.5307 - val_loss: 53.9650\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.0656 - val_loss: 54.2793\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.2387 - val_loss: 54.0966\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.7586 - val_loss: 54.2723\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.9720 - val_loss: 53.4829\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.8801 - val_loss: 55.5302\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.8222 - val_loss: 58.0657\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5969 - val_loss: 55.3663\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.4495 - val_loss: 54.4106\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.6394 - val_loss: 53.9109\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.7891 - val_loss: 57.0897\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.7170 - val_loss: 53.2017\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.4911 - val_loss: 55.3081\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.6321 - val_loss: 56.1737\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.7708 - val_loss: 54.2624\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.4891 - val_loss: 55.0331\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.4987 - val_loss: 53.8742\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.0047 - val_loss: 54.0291\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.9323 - val_loss: 53.9363\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.7822 - val_loss: 54.6257\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.8986 - val_loss: 53.7737\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.2675 - val_loss: 53.5953\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.3128 - val_loss: 53.1205\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.7311 - val_loss: 56.9120\n",
      "\n",
      "Mean Squared Error for iteration39: 51.42886729138819\n",
      "\n",
      "Iteration: 40\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 37.2370 - val_loss: 53.6009\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 38.5496 - val_loss: 60.4152\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.6596 - val_loss: 54.2797\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.3361 - val_loss: 54.8063\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.3069 - val_loss: 54.3703\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.1208 - val_loss: 57.3524\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.9072 - val_loss: 54.4084\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.8362 - val_loss: 53.8756\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8421 - val_loss: 55.1522\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 35.7200 - val_loss: 54.4845\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 33.7799 - val_loss: 53.7003\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.3569 - val_loss: 54.0675\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.4482 - val_loss: 53.5170\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.3728 - val_loss: 55.4095\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.0474 - val_loss: 54.0847\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.8978 - val_loss: 54.3245\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.1556 - val_loss: 53.1644\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.7394 - val_loss: 53.6948\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.5041 - val_loss: 55.9893\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.7916 - val_loss: 54.3512\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.7475 - val_loss: 53.6489\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.6387 - val_loss: 53.4841\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.3256 - val_loss: 53.3785\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.7469 - val_loss: 56.8649\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 36.8579 - val_loss: 56.3131\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 35.1857 - val_loss: 54.9239\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.4373 - val_loss: 54.6051\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.5083 - val_loss: 53.6489\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.0023 - val_loss: 57.1167\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.1739 - val_loss: 53.1092\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.3647 - val_loss: 54.5194\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.8227 - val_loss: 56.4847\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.7741 - val_loss: 53.9091\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.5760 - val_loss: 53.7886\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.6211 - val_loss: 53.2678\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.6926 - val_loss: 53.5613\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.2458 - val_loss: 53.1977\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.4889 - val_loss: 54.2548\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.7929 - val_loss: 53.9289\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.6841 - val_loss: 54.5570\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.4570 - val_loss: 53.8962\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.4444 - val_loss: 53.1873\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.7774 - val_loss: 57.7045\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.8462 - val_loss: 54.8274\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.8568 - val_loss: 58.9063\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 70us/step - loss: 34.6401 - val_loss: 54.7378\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.3697 - val_loss: 53.8905\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.3853 - val_loss: 54.4447\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 36.0660 - val_loss: 54.9966\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 36.0861 - val_loss: 55.5147\n",
      "\n",
      "Mean Squared Error for iteration40: 50.78687571787493\n",
      "\n",
      "Iteration: 41\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.7032 - val_loss: 54.2168\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.2505 - val_loss: 53.3607\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.9003 - val_loss: 56.2780\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.5604 - val_loss: 54.1289\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.8731 - val_loss: 54.3540\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.3073 - val_loss: 55.4945\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.8582 - val_loss: 53.7618\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.9033 - val_loss: 56.2672\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.0742 - val_loss: 54.3825\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.7925 - val_loss: 54.9091\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.6262 - val_loss: 53.9690\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 33.8562 - val_loss: 53.7773\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.8719 - val_loss: 53.6114\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.6920 - val_loss: 53.1099\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.7751 - val_loss: 57.3337\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.0010 - val_loss: 55.1019\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 33.4327 - val_loss: 53.4265\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.3690 - val_loss: 53.1849\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.3073 - val_loss: 54.7352\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 34.1164 - val_loss: 55.9407\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.1036 - val_loss: 55.4526\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 33.1612 - val_loss: 59.0533\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.5320 - val_loss: 56.6078\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.6140 - val_loss: 54.1898\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 33.2811 - val_loss: 54.3229\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 34.5905 - val_loss: 53.4136\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 33.3169 - val_loss: 55.6126\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.2361 - val_loss: 54.9034\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.7205 - val_loss: 54.0817\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.8368 - val_loss: 53.6839\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.1934 - val_loss: 56.0457\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.6348 - val_loss: 53.2544\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 34.2189 - val_loss: 53.9998\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 32.8781 - val_loss: 54.4422\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 34.9147 - val_loss: 53.7178\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.1843 - val_loss: 54.9742\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 35.6802 - val_loss: 53.3437\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.3404 - val_loss: 54.9640\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 33.1871 - val_loss: 53.4633\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.1694 - val_loss: 57.8056\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.8633 - val_loss: 55.6737\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 33.4602 - val_loss: 53.9919\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.3724 - val_loss: 54.9436\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 33.4636 - val_loss: 54.1454\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.8779 - val_loss: 57.5969\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.8214 - val_loss: 53.8150\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.5010 - val_loss: 53.8180\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.0240 - val_loss: 53.4960\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.3589 - val_loss: 52.6199\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 34.3735 - val_loss: 53.7909\n",
      "\n",
      "Mean Squared Error for iteration41: 49.33289776634927\n",
      "\n",
      "Iteration: 42\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 34.3041 - val_loss: 56.4800\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 34.1573 - val_loss: 53.5369\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.8278 - val_loss: 53.5176\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 38.6454 - val_loss: 56.1591\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 36.2248 - val_loss: 55.0556\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5040 - val_loss: 53.0860\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 33.8106 - val_loss: 54.4003\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.5128 - val_loss: 53.2941\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 33.9745 - val_loss: 54.0345\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.3139 - val_loss: 53.3063\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 35.1789 - val_loss: 53.2586\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 34.5448 - val_loss: 57.9083\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 34.5786 - val_loss: 54.3613\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.0235 - val_loss: 53.8238\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.9386 - val_loss: 53.1052\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.8379 - val_loss: 53.6531\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 33.7476 - val_loss: 56.6032\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 33.1494 - val_loss: 59.4587\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 34.9951 - val_loss: 53.9413\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 35.1609 - val_loss: 59.5172\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.9009 - val_loss: 54.9660\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.4765 - val_loss: 53.5366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 35.8245 - val_loss: 53.3931\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.4913 - val_loss: 53.4688\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.0990 - val_loss: 56.1110\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.0845 - val_loss: 55.0723\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.6030 - val_loss: 53.8004\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 33.7630 - val_loss: 54.2746\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.9777 - val_loss: 53.8773\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 179us/step - loss: 33.6801 - val_loss: 53.2095\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.7960 - val_loss: 54.1304\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.7407 - val_loss: 55.9501\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.9250 - val_loss: 54.2802\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.3944 - val_loss: 54.2770\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.8747 - val_loss: 53.9900\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 304us/step - loss: 33.3356 - val_loss: 53.6451\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 33.7307 - val_loss: 53.6650\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 33.4137 - val_loss: 54.0133\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.6439 - val_loss: 53.3759\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.1392 - val_loss: 53.8220\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 33.4636 - val_loss: 53.3480\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 33.5749 - val_loss: 54.8885\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 35.4957 - val_loss: 52.6655\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 121us/step - loss: 35.0397 - val_loss: 57.6534\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 35.5496 - val_loss: 54.0622\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 33.6192 - val_loss: 54.8568\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 33.8105 - val_loss: 53.7710\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 33.4138 - val_loss: 54.0294\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 33.6545 - val_loss: 54.9877\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 33.9571 - val_loss: 54.2154\n",
      "\n",
      "Mean Squared Error for iteration42: 49.56049552659609\n",
      "\n",
      "Iteration: 43\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 120us/step - loss: 33.6710 - val_loss: 56.0022\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 155us/step - loss: 34.4381 - val_loss: 53.4508\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 33.7060 - val_loss: 57.2412\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 35.2649 - val_loss: 52.9111\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.7880 - val_loss: 53.4463\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 35.5564 - val_loss: 54.5192\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 33.5024 - val_loss: 53.6432\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.8027 - val_loss: 53.9957\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.6261 - val_loss: 54.1736\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.6443 - val_loss: 54.3491\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.9952 - val_loss: 55.0159\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 279us/step - loss: 34.5620 - val_loss: 52.9515\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 247us/step - loss: 33.8447 - val_loss: 53.6424\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.3698 - val_loss: 54.2852\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.6759 - val_loss: 53.6944\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.8297 - val_loss: 54.8398\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.2850 - val_loss: 54.8565\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 33.7714 - val_loss: 53.7149\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.2504 - val_loss: 52.5981\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 33.4485 - val_loss: 53.0643\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 33.7666 - val_loss: 53.4915\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.6930 - val_loss: 55.3501\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 33.6026 - val_loss: 54.1472\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 35.6704 - val_loss: 53.4518\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 33.4236 - val_loss: 53.9597\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 33.8983 - val_loss: 53.4909\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 33.5770 - val_loss: 53.7357\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.9171 - val_loss: 54.0209\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.0531 - val_loss: 54.1635\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.6583 - val_loss: 54.8900\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.0817 - val_loss: 53.0165\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 711us/step - loss: 34.0879 - val_loss: 56.2478\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 378us/step - loss: 34.0269 - val_loss: 54.8481\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.5287 - val_loss: 53.8769\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.4856 - val_loss: 54.3173\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 1s 1ms/step - loss: 33.6590 - val_loss: 53.5718\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 162us/step - loss: 33.4107 - val_loss: 53.6228\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.2330 - val_loss: 55.1915\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.4794 - val_loss: 54.1709\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.7317 - val_loss: 54.3114\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 35.6480 - val_loss: 53.0728\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 33.5047 - val_loss: 53.7328\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 33.6549 - val_loss: 53.4947\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 190us/step - loss: 33.9203 - val_loss: 56.2114\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 36.9829 - val_loss: 54.9658\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.4197 - val_loss: 54.1929\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.4559 - val_loss: 54.0184\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.0371 - val_loss: 54.9562\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.7403 - val_loss: 57.2139\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 76us/step - loss: 33.8717 - val_loss: 54.6358\n",
      "\n",
      "Mean Squared Error for iteration43: 49.36746034106665\n",
      "\n",
      "Iteration: 44\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 130us/step - loss: 33.4790 - val_loss: 52.4010\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 160us/step - loss: 33.9786 - val_loss: 58.2431\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 312us/step - loss: 34.7278 - val_loss: 58.4621\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 263us/step - loss: 34.4453 - val_loss: 59.1017\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 36.1885 - val_loss: 53.7948\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 193us/step - loss: 34.1094 - val_loss: 53.2725\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 35.6762 - val_loss: 55.3043\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 167us/step - loss: 34.8430 - val_loss: 55.9411\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 33.5885 - val_loss: 53.7582\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 166us/step - loss: 33.3679 - val_loss: 55.0528\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 170us/step - loss: 33.8290 - val_loss: 60.3610\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 34.6508 - val_loss: 54.4641\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 182us/step - loss: 33.5222 - val_loss: 61.5577\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 35.0698 - val_loss: 54.4514\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 34.8705 - val_loss: 53.8728\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 35.5270 - val_loss: 56.0280\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 138us/step - loss: 33.6045 - val_loss: 55.1282\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 135us/step - loss: 33.3258 - val_loss: 56.4534\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 34.2219 - val_loss: 54.3324\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 34.1372 - val_loss: 54.1392\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 196us/step - loss: 34.9632 - val_loss: 57.0604\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 225us/step - loss: 35.1066 - val_loss: 58.1717\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 34.4923 - val_loss: 57.5354\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 171us/step - loss: 34.8454 - val_loss: 53.4024\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 165us/step - loss: 34.4068 - val_loss: 55.2926\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 188us/step - loss: 33.8090 - val_loss: 54.6651\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 183us/step - loss: 33.3164 - val_loss: 55.6471\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 34.2500 - val_loss: 55.4729\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 34.4418 - val_loss: 53.2642\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.7831 - val_loss: 53.6398\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.6716 - val_loss: 53.1897\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.3597 - val_loss: 57.4646\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 33.3713 - val_loss: 53.8145\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 34.8987 - val_loss: 56.9090\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 33.4963 - val_loss: 55.5856\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 33.9194 - val_loss: 54.0540\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.3214 - val_loss: 56.4019\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.2313 - val_loss: 57.5624\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.6686 - val_loss: 53.9832\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 33.5190 - val_loss: 53.7234\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 215us/step - loss: 33.6423 - val_loss: 55.2972\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 34.0729 - val_loss: 53.7373\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 33.6422 - val_loss: 53.4984\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 33.7421 - val_loss: 54.5286\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 322us/step - loss: 33.3419 - val_loss: 56.8563\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 34.2304 - val_loss: 58.2383\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.9654 - val_loss: 53.4094\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.2689 - val_loss: 53.3892\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.3456 - val_loss: 55.9286\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 35.0256 - val_loss: 53.5482\n",
      "\n",
      "Mean Squared Error for iteration44: 49.16457100746113\n",
      "\n",
      "Iteration: 45\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.6809 - val_loss: 55.0695\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.8367 - val_loss: 53.0001\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.4735 - val_loss: 56.3830\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.4465 - val_loss: 54.2962\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.7324 - val_loss: 53.5151\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.6614 - val_loss: 54.3897\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.4734 - val_loss: 52.9094\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.4276 - val_loss: 54.7591\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.1108 - val_loss: 54.3847\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.8872 - val_loss: 55.2751\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.2388 - val_loss: 55.6228\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 33.9858 - val_loss: 53.2440\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 199us/step - loss: 33.7783 - val_loss: 54.9349\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 34.4878 - val_loss: 55.6082\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 33.6224 - val_loss: 61.2744\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 197us/step - loss: 36.0578 - val_loss: 56.0027\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 166us/step - loss: 33.8296 - val_loss: 54.2143\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 34.0831 - val_loss: 53.9500\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 176us/step - loss: 33.9160 - val_loss: 59.2239\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 37.6886 - val_loss: 53.9939\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 36.5601 - val_loss: 54.3268\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.6511 - val_loss: 54.2492\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.7961 - val_loss: 54.3308\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.8249 - val_loss: 54.9275\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 33.6828 - val_loss: 53.2299\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 346us/step - loss: 33.9212 - val_loss: 54.7766\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 201us/step - loss: 33.7210 - val_loss: 54.4847\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 33.4173 - val_loss: 53.9347\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 33.8344 - val_loss: 54.1787\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.8806 - val_loss: 54.1088\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.5789 - val_loss: 53.5209\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.5928 - val_loss: 54.9008\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.3629 - val_loss: 54.8703\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.0966 - val_loss: 56.9057\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.1369 - val_loss: 57.8179\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.2031 - val_loss: 53.7560\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.6491 - val_loss: 54.2879\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 33.6717 - val_loss: 54.7215\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 33.7786 - val_loss: 53.4429\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.5152 - val_loss: 54.0798\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.1683 - val_loss: 54.2733\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.3314 - val_loss: 53.7610\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.4663 - val_loss: 55.6525\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.3739 - val_loss: 53.6103\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.1421 - val_loss: 54.8923\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.8196 - val_loss: 59.1785\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 35.2984 - val_loss: 54.8685\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 35.5183 - val_loss: 56.9698\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 35.5120 - val_loss: 54.4534\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 33.7293 - val_loss: 53.4014\n",
      "\n",
      "Mean Squared Error for iteration45: 49.6136898532689\n",
      "\n",
      "Iteration: 46\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 33.1300 - val_loss: 53.6100\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.3034 - val_loss: 54.5003\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.9163 - val_loss: 56.0599\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 162us/step - loss: 35.6004 - val_loss: 53.9452\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 36.5308 - val_loss: 60.6483\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 290us/step - loss: 35.5637 - val_loss: 54.4406\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 33.9797 - val_loss: 53.6503\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.4339 - val_loss: 54.7632\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.4169 - val_loss: 53.0724\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.2654 - val_loss: 56.6278\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.5839 - val_loss: 53.6638\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.7407 - val_loss: 53.5699\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.1447 - val_loss: 53.8313\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 182us/step - loss: 33.3991 - val_loss: 54.5228\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 193us/step - loss: 35.2396 - val_loss: 53.5281\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 34.3458 - val_loss: 53.9630\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.2533 - val_loss: 55.6693\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.8458 - val_loss: 53.5598\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.8662 - val_loss: 53.4294\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.4823 - val_loss: 55.1930\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.0536 - val_loss: 60.4561\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.9390 - val_loss: 55.4327\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 34.7794 - val_loss: 54.6436\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 32.9697 - val_loss: 53.4438\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.6357 - val_loss: 57.2848\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.9359 - val_loss: 55.0368\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 33.4345 - val_loss: 54.8831\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.2118 - val_loss: 53.4918\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 33.6017 - val_loss: 54.8043\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.8280 - val_loss: 53.5937\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.7407 - val_loss: 53.6275\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.4613 - val_loss: 55.5561\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.0797 - val_loss: 53.5899\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.4308 - val_loss: 56.5112\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.5575 - val_loss: 54.9736\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.2401 - val_loss: 53.8292\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.6523 - val_loss: 55.1793\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.4447 - val_loss: 53.2368\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.2820 - val_loss: 54.1614\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.5658 - val_loss: 53.5763\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.7625 - val_loss: 53.5018\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 33.6664 - val_loss: 53.4706\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.5965 - val_loss: 57.0720\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 34.7210 - val_loss: 54.6630\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 33.6911 - val_loss: 53.5360\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 160us/step - loss: 33.6270 - val_loss: 57.7653\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 34.5819 - val_loss: 53.7886\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 33.6952 - val_loss: 53.8022\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.3057 - val_loss: 54.5410\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.4931 - val_loss: 56.4454\n",
      "\n",
      "Mean Squared Error for iteration46: 51.61035888373445\n",
      "\n",
      "Iteration: 47\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.5318 - val_loss: 55.8893\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 83us/step - loss: 33.5139 - val_loss: 54.8081\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.1536 - val_loss: 54.1504\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 135us/step - loss: 33.6697 - val_loss: 57.9605\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 165us/step - loss: 34.6193 - val_loss: 53.6036\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 33.4910 - val_loss: 54.4112\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.1902 - val_loss: 53.8275\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.7632 - val_loss: 53.5630\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.4286 - val_loss: 55.5276\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.0572 - val_loss: 53.3272\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.3369 - val_loss: 54.1164\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.1228 - val_loss: 56.8432\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.6129 - val_loss: 55.8144\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 134us/step - loss: 35.3000 - val_loss: 53.5759\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 190us/step - loss: 35.0152 - val_loss: 56.8405\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 34.1237 - val_loss: 53.2444\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 154us/step - loss: 33.8071 - val_loss: 59.4535\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.9648 - val_loss: 55.0005\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.6817 - val_loss: 54.3817\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.8921 - val_loss: 53.9201\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.3539 - val_loss: 54.4202\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.2955 - val_loss: 54.2412\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 33.7062 - val_loss: 54.1901\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 33.3002 - val_loss: 54.1498\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 172us/step - loss: 33.9059 - val_loss: 56.0757\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 172us/step - loss: 35.0346 - val_loss: 54.0554\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 166us/step - loss: 33.6416 - val_loss: 53.9909\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.0970 - val_loss: 54.7465\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.0496 - val_loss: 53.8760\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.4928 - val_loss: 53.7483\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.9794 - val_loss: 56.8228\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.1723 - val_loss: 53.2467\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.4438 - val_loss: 53.9617\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.2714 - val_loss: 53.8261\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.6345 - val_loss: 56.7001\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.6229 - val_loss: 54.8162\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 33.1362 - val_loss: 53.7619\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.2267 - val_loss: 53.7857\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 34.2025 - val_loss: 58.9023\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.8020 - val_loss: 54.3028\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.1088 - val_loss: 54.8331\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.3445 - val_loss: 54.0257\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 35.7931 - val_loss: 54.2462\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.1372 - val_loss: 54.1321\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.5596 - val_loss: 54.0258\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.6055 - val_loss: 53.9954\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.7120 - val_loss: 55.2289\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.4228 - val_loss: 57.2022\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 33.8274 - val_loss: 54.2217\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.3883 - val_loss: 53.8041\n",
      "\n",
      "Mean Squared Error for iteration47: 49.2800218772895\n",
      "\n",
      "Iteration: 48\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 194us/step - loss: 34.7973 - val_loss: 54.6902\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 166us/step - loss: 33.5533 - val_loss: 57.3166\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 292us/step - loss: 33.6596 - val_loss: 53.6790\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 184us/step - loss: 33.5947 - val_loss: 54.8552\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 213us/step - loss: 33.7942 - val_loss: 53.6975\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 34.2294 - val_loss: 53.8303\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 146us/step - loss: 33.1614 - val_loss: 58.4475\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 34.5913 - val_loss: 55.8379\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 34.8032 - val_loss: 54.2135\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 34.1947 - val_loss: 54.5847\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 33.5327 - val_loss: 54.6514\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 166us/step - loss: 33.3129 - val_loss: 53.4082\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 371us/step - loss: 33.3444 - val_loss: 56.4047\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 215us/step - loss: 35.3615 - val_loss: 53.3385\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 186us/step - loss: 34.7709 - val_loss: 54.1067\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 34.2230 - val_loss: 54.3716\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 34.7486 - val_loss: 53.1388\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 33.4986 - val_loss: 53.4462\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 33.9954 - val_loss: 54.3583\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 170us/step - loss: 34.3027 - val_loss: 55.7065\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 34.6338 - val_loss: 55.2564\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 154us/step - loss: 34.2145 - val_loss: 53.8361\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 134us/step - loss: 33.1041 - val_loss: 55.5604\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 35.3239 - val_loss: 53.5015\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 127us/step - loss: 34.8543 - val_loss: 54.0541\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 179us/step - loss: 33.1476 - val_loss: 56.2249\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 33.4418 - val_loss: 54.1752\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 143us/step - loss: 34.3252 - val_loss: 55.1454\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 105us/step - loss: 34.2750 - val_loss: 52.9320\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 33.8240 - val_loss: 55.5678\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 33.5280 - val_loss: 53.9615\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 34.4456 - val_loss: 57.2697\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 33.8758 - val_loss: 54.2136\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 34.1996 - val_loss: 54.3497\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 33.5171 - val_loss: 53.3020\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 35.2393 - val_loss: 57.7464\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 34.0173 - val_loss: 54.4361\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 33.8595 - val_loss: 55.7801\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 34.5972 - val_loss: 53.3703\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.3792 - val_loss: 54.7599\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.3796 - val_loss: 53.0622\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 33.2144 - val_loss: 55.6840\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.0703 - val_loss: 57.5691\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.3980 - val_loss: 53.2113\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.0644 - val_loss: 53.6552\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 35.4242 - val_loss: 53.4262\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 34.5800 - val_loss: 54.8841\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 33.4368 - val_loss: 52.1774\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.4977 - val_loss: 54.0814\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.3985 - val_loss: 55.0119\n",
      "\n",
      "Mean Squared Error for iteration48: 49.666756664771285\n",
      "\n",
      "Iteration: 49\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.1348 - val_loss: 53.3532\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.2574 - val_loss: 53.8183\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.5702 - val_loss: 54.5484\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.9739 - val_loss: 54.6932\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.0844 - val_loss: 53.4226\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.2193 - val_loss: 53.4182\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 33.5950 - val_loss: 54.4704\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.3798 - val_loss: 53.5060\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.3591 - val_loss: 57.0505\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 33.4743 - val_loss: 53.1554\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.2382 - val_loss: 53.4365\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.9237 - val_loss: 57.5807\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 35.5109 - val_loss: 52.7206\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - ETA: 0s - loss: 34.61 - 0s 90us/step - loss: 33.3231 - val_loss: 53.5736\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 34.0135 - val_loss: 56.2905\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.8675 - val_loss: 54.5009\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 32.9121 - val_loss: 55.6947\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 34.9016 - val_loss: 54.0535\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.6493 - val_loss: 53.7583\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.7329 - val_loss: 54.9511\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.0518 - val_loss: 56.9086\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.7045 - val_loss: 53.1775\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 32.9772 - val_loss: 53.8502\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 34.6978 - val_loss: 55.8354\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 33.6409 - val_loss: 54.1091\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.9245 - val_loss: 53.4679\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.6364 - val_loss: 54.2768\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.1752 - val_loss: 54.1947\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.2705 - val_loss: 53.6867\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.9798 - val_loss: 54.3464\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.2004 - val_loss: 55.3005\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.6970 - val_loss: 59.0457\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 34.1196 - val_loss: 60.4066\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 34.5566 - val_loss: 54.2692\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 33.2983 - val_loss: 53.5141\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.5305 - val_loss: 56.2237\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 36.8445 - val_loss: 60.4274\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 34.4244 - val_loss: 53.9643\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 33.2985 - val_loss: 54.2151\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 33.9490 - val_loss: 53.1240\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 34.4974 - val_loss: 54.1721\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.2244 - val_loss: 53.2649\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.9300 - val_loss: 53.8458\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.2184 - val_loss: 53.5743\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.9377 - val_loss: 54.8675\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.4826 - val_loss: 53.8654\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.2003 - val_loss: 53.9283\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 124us/step - loss: 33.8866 - val_loss: 53.9920\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 33.3716 - val_loss: 54.0489\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 36.3582 - val_loss: 52.7430\n",
      "\n",
      "Mean Squared Error for iteration49: 49.498843849894136\n",
      "\n",
      "Iteration: 50\n",
      "\n",
      "\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 33.4312 - val_loss: 53.2972\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 33.6720 - val_loss: 53.0523\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 33.7940 - val_loss: 53.0539\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 33.6987 - val_loss: 53.9906\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 86us/step - loss: 33.3581 - val_loss: 53.8003\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.5526 - val_loss: 53.1009\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.1844 - val_loss: 55.9756\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.6311 - val_loss: 55.3077\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 33.2498 - val_loss: 54.4121\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.3026 - val_loss: 52.9261\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 33.3565 - val_loss: 53.5331\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.5834 - val_loss: 53.2820\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.2367 - val_loss: 54.0919\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.2407 - val_loss: 53.3735\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.3611 - val_loss: 56.2503\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 33.2856 - val_loss: 55.8085\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 33.7201 - val_loss: 57.5915\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 34.1340 - val_loss: 54.5974\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.3277 - val_loss: 52.9176\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.7798 - val_loss: 58.5819\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.6339 - val_loss: 61.7093\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 35.0347 - val_loss: 54.8116\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.6360 - val_loss: 53.6603\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 34.2387 - val_loss: 54.5617\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 33.5280 - val_loss: 56.0624\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.0799 - val_loss: 53.6800\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 32.9963 - val_loss: 53.4526\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 34.4634 - val_loss: 55.2253\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 35.1468 - val_loss: 58.9912\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 34.3539 - val_loss: 53.8957\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.8362 - val_loss: 53.7493\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 33.4522 - val_loss: 54.4959\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.2089 - val_loss: 53.9594\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 33.3833 - val_loss: 52.6700\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.5937 - val_loss: 55.4743\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 34.1498 - val_loss: 54.8252\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 33.5414 - val_loss: 53.2992\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 34.7435 - val_loss: 53.3474\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 34.1032 - val_loss: 57.7024\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 34.1348 - val_loss: 52.2457\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 34.7248 - val_loss: 53.2718\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 33.2121 - val_loss: 53.6305\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 197us/step - loss: 33.4381 - val_loss: 54.0895\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 174us/step - loss: 33.9077 - val_loss: 56.2984\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 33.4321 - val_loss: 54.4611\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 34.3684 - val_loss: 53.9010\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 33.9810 - val_loss: 57.5301\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 35.2279 - val_loss: 53.6827\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 189us/step - loss: 34.0190 - val_loss: 54.4166\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 147us/step - loss: 33.5655 - val_loss: 54.8189\n",
      "\n",
      "Mean Squared Error for iteration50: 50.053049237037065\n"
     ]
    }
   ],
   "source": [
    "mse_total = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    print('\\nIteration:', i+1)\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=50)\n",
    "    predict_yhat = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predict_yhat)\n",
    "    print('\\n''Mean Squared Error for iteration{}: {}'.format(i+1, mse))\n",
    "    mse_total.append(mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50.583034016405044,\n",
       " 51.6006477532816,\n",
       " 50.46734574525872,\n",
       " 51.469371962201535,\n",
       " 50.87150796596201,\n",
       " 50.90944136412306,\n",
       " 51.93626262451689,\n",
       " 51.34063564978393,\n",
       " 50.311162268774225,\n",
       " 51.07061842532071,\n",
       " 50.56330530140972,\n",
       " 50.52495258833162,\n",
       " 50.56153508165196,\n",
       " 50.879939106929115,\n",
       " 50.5911131946049,\n",
       " 51.18277291180999,\n",
       " 50.280977848723474,\n",
       " 50.44471844908444,\n",
       " 51.49137108835086,\n",
       " 50.370453351727186,\n",
       " 50.50158131285122,\n",
       " 52.06077701410863,\n",
       " 50.215795219836245,\n",
       " 51.28994590671447,\n",
       " 52.52041096071995,\n",
       " 53.77838450146721,\n",
       " 52.8217641944465,\n",
       " 50.11049199407344,\n",
       " 50.01359869686286,\n",
       " 49.80111868283159,\n",
       " 50.001161267513055,\n",
       " 49.393956656630714,\n",
       " 49.393129656033786,\n",
       " 51.436230267216224,\n",
       " 49.27707351986575,\n",
       " 51.78871964124778,\n",
       " 48.877470730360024,\n",
       " 49.64883326294581,\n",
       " 51.42886729138819,\n",
       " 50.78687571787493,\n",
       " 49.33289776634927,\n",
       " 49.56049552659609,\n",
       " 49.36746034106665,\n",
       " 49.16457100746113,\n",
       " 49.6136898532689,\n",
       " 51.61035888373445,\n",
       " 49.2800218772895,\n",
       " 49.666756664771285,\n",
       " 49.498843849894136,\n",
       " 50.053049237037065]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_total)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean MSE value is 50.59490996401415 and standard deviation for MSE is 1.0276902495212634\n"
     ]
    }
   ],
   "source": [
    "#Calculating mean and standard deviation of MSE - Part A\n",
    "mean = np.mean(mse_total)\n",
    "std_dev=np.std(mse_total)\n",
    "\n",
    "print('The mean MSE value is {} and standard deviation for MSE is {}'.format(mean, std_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
