{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM Keras - Final Assignment - Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.1-cp36-cp36m-macosx_10_9_x86_64.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 580 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2020.06.20 in /Users/narendransingh/opt/anaconda3/envs/Kera/lib/python3.6/site-packages (from matplotlib) (2020.6.20)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp36-cp36m-macosx_10_9_x86_64.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 685 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-7.2.0-cp36-cp36m-macosx_10_10_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 786 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /Users/narendransingh/opt/anaconda3/envs/Kera/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/narendransingh/opt/anaconda3/envs/Kera/lib/python3.6/site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/narendransingh/opt/anaconda3/envs/Kera/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/narendransingh/opt/anaconda3/envs/Kera/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, pillow, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.1 pillow-7.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('concrete_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks clean, with no null values. We have to predict data of concrete strength\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[df.columns != 'Strength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Strength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A - Build Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Neural Network\n",
    "\n",
    "def regression_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss ='mean_squared_error')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "Since the data is clean we can go ahead and split the data in train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = X_train.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (721, 8)\n",
      "y_train: (721,)\n",
      "X_test: (309, 8)\n",
      "y_test: (309,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B - Normalize the Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = (X_train - X_train.mean()) / X_train.std()\n",
    "#X_train_norm\n",
    "X_test_norm = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 141us/step - loss: 11.1376 - val_loss: 58.1009\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.0012 - val_loss: 58.3837\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.9925 - val_loss: 58.7048\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.1771 - val_loss: 58.8588\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2103 - val_loss: 58.0823\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3605 - val_loss: 59.5544\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2186 - val_loss: 57.8673\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2010 - val_loss: 59.0329\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2556 - val_loss: 57.9456\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 10.9948 - val_loss: 58.3604\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3023 - val_loss: 58.9454\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 10.8436 - val_loss: 58.1813\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 10.9108 - val_loss: 59.2633\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.4124 - val_loss: 58.4984\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.8575 - val_loss: 58.7915\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 12.2877 - val_loss: 58.8454\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.8811 - val_loss: 58.4182\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1238 - val_loss: 58.4063\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1589 - val_loss: 58.1292\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0172 - val_loss: 59.1806\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2185 - val_loss: 58.4481\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 10.9885 - val_loss: 58.3277\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 10.9398 - val_loss: 58.7069\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.1984 - val_loss: 58.0543\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.0636 - val_loss: 59.0521\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3151 - val_loss: 58.5699\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.2624 - val_loss: 58.4974\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.1515 - val_loss: 58.8927\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 324us/step - loss: 10.9454 - val_loss: 58.2746\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 407us/step - loss: 11.2976 - val_loss: 59.0755\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.6009 - val_loss: 59.1286\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2370 - val_loss: 58.0029\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.0229 - val_loss: 58.8611\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.2710 - val_loss: 58.0806\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.1441 - val_loss: 58.4461\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.1380 - val_loss: 57.9170\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.0569 - val_loss: 58.3233\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.0411 - val_loss: 58.8581\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 154us/step - loss: 11.1045 - val_loss: 58.4002\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3002 - val_loss: 58.2188\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 153us/step - loss: 11.1077 - val_loss: 58.4912\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 10.8318 - val_loss: 58.2767\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 212us/step - loss: 10.9557 - val_loss: 58.7389\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 271us/step - loss: 10.9044 - val_loss: 58.2901\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.2836 - val_loss: 59.2307\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.1336 - val_loss: 58.4328\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 10.9545 - val_loss: 58.6603\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 164us/step - loss: 11.1928 - val_loss: 58.4485\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - ETA: 0s - loss: 11.06 - 0s 397us/step - loss: 11.0156 - val_loss: 58.6053\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 258us/step - loss: 11.0300 - val_loss: 58.2617\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 180us/step - loss: 11.1359 - val_loss: 58.5268\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 485us/step - loss: 11.1778 - val_loss: 58.5312\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 184us/step - loss: 11.2825 - val_loss: 58.6557\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.1712 - val_loss: 58.8118\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.2500 - val_loss: 58.2357\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 308us/step - loss: 11.0384 - val_loss: 57.8706\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 391us/step - loss: 10.9554 - val_loss: 58.6557\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.1495 - val_loss: 58.6778\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.4561 - val_loss: 58.8235\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.7720 - val_loss: 58.5864\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.4758 - val_loss: 58.9233\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.2291 - val_loss: 58.7795\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.0199 - val_loss: 58.0696\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 169us/step - loss: 11.0039 - val_loss: 59.1367\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 155us/step - loss: 11.3961 - val_loss: 58.4669\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.3566 - val_loss: 57.8620\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 266us/step - loss: 11.2307 - val_loss: 59.0290\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 467us/step - loss: 11.1101 - val_loss: 57.9233\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 150us/step - loss: 11.0283 - val_loss: 58.8821\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.0859 - val_loss: 58.2798\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.0245 - val_loss: 58.8522\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.2237 - val_loss: 58.2133\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 289us/step - loss: 11.0277 - val_loss: 58.6259\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 266us/step - loss: 11.0460 - val_loss: 58.5094\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 171us/step - loss: 11.0987 - val_loss: 58.3186\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 10.9369 - val_loss: 58.9251\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 146us/step - loss: 11.1388 - val_loss: 58.1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.0588 - val_loss: 58.6816\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.2377 - val_loss: 58.6111\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.2923 - val_loss: 57.8727\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.2673 - val_loss: 59.1130\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 10.9564 - val_loss: 58.5018\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.2670 - val_loss: 58.2366\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 10.9256 - val_loss: 59.0026\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.1179 - val_loss: 59.2412\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.6051 - val_loss: 58.5420\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1683 - val_loss: 58.5928\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0877 - val_loss: 58.9729\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0032 - val_loss: 58.3934\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.1883 - val_loss: 58.2249\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 10.9169 - val_loss: 58.8593\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.1412 - val_loss: 58.5237\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2327 - val_loss: 59.0232\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 10.9308 - val_loss: 57.9907\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1726 - val_loss: 59.0564\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.0229 - val_loss: 57.9459\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3199 - val_loss: 58.2267\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 10.9979 - val_loss: 58.2364\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.0935 - val_loss: 58.4500\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 10.9397 - val_loss: 58.3463\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "\n",
    "history = model.fit(X_train_norm, y_train, validation_split=0.2, epochs=100)\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "\n",
    "predict_yhat = model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.93579077785856"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predict_yhat)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  1\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.5824 - val_loss: 58.3648\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3959 - val_loss: 59.2149\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5984 - val_loss: 59.0843\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5331 - val_loss: 59.2696\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.7786 - val_loss: 60.0420\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5637 - val_loss: 57.5922\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6175 - val_loss: 59.3583\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5419 - val_loss: 59.6041\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3741 - val_loss: 58.8376\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.3219 - val_loss: 58.7725\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.6884 - val_loss: 59.6791\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.6242 - val_loss: 58.7237\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.3698 - val_loss: 59.7927\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.5245 - val_loss: 58.2288\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.4035 - val_loss: 59.1529\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 138us/step - loss: 11.7335 - val_loss: 60.3350\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.8445 - val_loss: 58.4385\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5158 - val_loss: 58.6580\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.3533 - val_loss: 59.1417\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.6193 - val_loss: 59.5145\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.7619 - val_loss: 58.9149\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.7403 - val_loss: 59.3626\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.8433 - val_loss: 58.7941\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.8248 - val_loss: 59.5308\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.7228 - val_loss: 58.3007\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.5117 - val_loss: 60.3554\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.8600 - val_loss: 58.3902\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2017 - val_loss: 58.8472\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4451 - val_loss: 59.4818\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.8087 - val_loss: 59.1867\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5364 - val_loss: 58.6494\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.3773 - val_loss: 58.5033\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.3690 - val_loss: 59.5397\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3688 - val_loss: 58.6827\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3351 - val_loss: 59.5408\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 12.2551 - val_loss: 58.9281\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.7750 - val_loss: 59.4643\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.6260 - val_loss: 58.7104\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.6203 - val_loss: 58.9622\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.6456 - val_loss: 58.8209\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.6251 - val_loss: 58.7277\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.6344 - val_loss: 58.5292\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.5121 - val_loss: 59.4917\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 144us/step - loss: 11.3918 - val_loss: 58.7567\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.3592 - val_loss: 59.2984\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 149us/step - loss: 11.3373 - val_loss: 59.1281\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3652 - val_loss: 58.8493\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4188 - val_loss: 58.6217\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4896 - val_loss: 59.3724\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.5173 - val_loss: 58.4888\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6260 - val_loss: 59.1869\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 146us/step - loss: 11.2900 - val_loss: 58.3005\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 443us/step - loss: 11.3471 - val_loss: 58.5712\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 141us/step - loss: 11.5713 - val_loss: 59.3612\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 347us/step - loss: 11.6879 - val_loss: 58.5494\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 405us/step - loss: 11.4845 - val_loss: 59.2947\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.4365 - val_loss: 58.8989\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5324 - val_loss: 58.7093\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5786 - val_loss: 59.5152\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3898 - val_loss: 58.8897\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.7769 - val_loss: 59.1289\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.6799 - val_loss: 58.6544\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4162 - val_loss: 58.7361\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.4589 - val_loss: 59.1611\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.4109 - val_loss: 58.9137\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.4553 - val_loss: 59.1770\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 152us/step - loss: 11.7459 - val_loss: 59.4786\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3859 - val_loss: 58.9032\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5596 - val_loss: 58.7307\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.8212 - val_loss: 58.7364\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.5341 - val_loss: 58.4271\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3464 - val_loss: 59.0270\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.5557 - val_loss: 58.4148\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 164us/step - loss: 11.5344 - val_loss: 60.0782\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 12.0038 - val_loss: 58.3079\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.7664 - val_loss: 59.4748\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 618us/step - loss: 11.4955 - val_loss: 59.2255\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 100us/step - loss: 11.4643 - val_loss: 58.9429\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.3266 - val_loss: 59.2687\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 12.3177 - val_loss: 59.1571\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4858 - val_loss: 58.6967\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2920 - val_loss: 59.0381\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4085 - val_loss: 58.6231\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4143 - val_loss: 59.0420\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.8076 - val_loss: 59.4749\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.8329 - val_loss: 58.4897\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 12.0049 - val_loss: 59.3414\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.7883 - val_loss: 58.4853\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 12.0172 - val_loss: 59.1538\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.9533 - val_loss: 58.8610\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3410 - val_loss: 59.1428\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3756 - val_loss: 58.5917\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4515 - val_loss: 58.4608\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3945 - val_loss: 59.7226\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3294 - val_loss: 58.0183\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4176 - val_loss: 58.6907\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5960 - val_loss: 58.6163\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4713 - val_loss: 58.7867\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5109 - val_loss: 59.6065\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3399 - val_loss: 58.5322\n",
      "\n",
      "Mean Squared Error for iteration1: 47.536986457942625\n",
      "\n",
      "Iteration:  2\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.5322 - val_loss: 58.7991\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.5072 - val_loss: 58.6433\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.7356 - val_loss: 58.6764\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.4579 - val_loss: 58.7053\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3716 - val_loss: 58.2132\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.8099 - val_loss: 59.1733\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.3017 - val_loss: 58.7856\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.5398 - val_loss: 58.5516\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.2915 - val_loss: 58.7921\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.2387 - val_loss: 59.2136\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.3706 - val_loss: 59.0862\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3741 - val_loss: 58.9407\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3191 - val_loss: 58.8507\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 172us/step - loss: 11.6422 - val_loss: 59.3265\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.5115 - val_loss: 58.3342\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.4317 - val_loss: 59.4219\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.6696 - val_loss: 58.1676\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3849 - val_loss: 58.8854\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 174us/step - loss: 11.2958 - val_loss: 58.4692\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.9373 - val_loss: 58.1121\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.5539 - val_loss: 58.9387\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.4507 - val_loss: 58.4877\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.3200 - val_loss: 59.3010\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 143us/step - loss: 11.6936 - val_loss: 58.6696\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.5793 - val_loss: 59.2502\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.3859 - val_loss: 58.5028\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.5981 - val_loss: 59.9973\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.5823 - val_loss: 58.7456\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.6740 - val_loss: 59.1231\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.8311 - val_loss: 59.5324\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.6911 - val_loss: 58.4732\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.3257 - val_loss: 58.4789\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.2804 - val_loss: 59.2276\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.4050 - val_loss: 58.4884\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.3891 - val_loss: 59.1119\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.2000 - val_loss: 58.9037\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.4645 - val_loss: 59.2620\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.5565 - val_loss: 59.0340\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3486 - val_loss: 59.0339\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 156us/step - loss: 11.2451 - val_loss: 59.2531\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 359us/step - loss: 11.2915 - val_loss: 58.3039\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 188us/step - loss: 11.3751 - val_loss: 59.2987\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.6272 - val_loss: 58.9148\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.4615 - val_loss: 58.8930\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.3690 - val_loss: 58.9636\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 153us/step - loss: 11.2470 - val_loss: 58.8805\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 159us/step - loss: 11.2656 - val_loss: 58.8546\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.4990 - val_loss: 59.1476\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.4927 - val_loss: 59.0623\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.4450 - val_loss: 58.8678\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.5637 - val_loss: 58.9357\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.5666 - val_loss: 59.5569\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 210us/step - loss: 11.5343 - val_loss: 58.3265\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 204us/step - loss: 11.4788 - val_loss: 59.1092\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 292us/step - loss: 11.4749 - val_loss: 58.7131\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.4951 - val_loss: 59.5102\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.4660 - val_loss: 59.2235\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.4267 - val_loss: 59.6208\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2645 - val_loss: 58.8521\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.5231 - val_loss: 58.9409\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.5327 - val_loss: 58.9354\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.4182 - val_loss: 58.6885\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 315us/step - loss: 11.4793 - val_loss: 59.3393\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 250us/step - loss: 11.3414 - val_loss: 59.2976\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 190us/step - loss: 11.6507 - val_loss: 59.3518\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.4529 - val_loss: 59.3365\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 228us/step - loss: 11.2949 - val_loss: 58.5686\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 232us/step - loss: 11.3117 - val_loss: 59.4988\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 216us/step - loss: 11.5271 - val_loss: 58.9637\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.5445 - val_loss: 59.2871\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 12.0679 - val_loss: 59.5243\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 181us/step - loss: 11.4253 - val_loss: 58.5345\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 255us/step - loss: 11.3643 - val_loss: 59.1901\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 283us/step - loss: 11.5352 - val_loss: 59.4681\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 195us/step - loss: 11.7291 - val_loss: 58.4550\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.5155 - val_loss: 59.3542\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.5671 - val_loss: 58.6262\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.3098 - val_loss: 58.6883\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.4402 - val_loss: 58.9917\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.3394 - val_loss: 59.0335\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.4954 - val_loss: 58.5832\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 167us/step - loss: 11.5143 - val_loss: 58.8003\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 143us/step - loss: 11.4944 - val_loss: 58.5493\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.2975 - val_loss: 59.5689\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 384us/step - loss: 11.4743 - val_loss: 59.1348\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 261us/step - loss: 11.2887 - val_loss: 58.2843\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 246us/step - loss: 11.6289 - val_loss: 59.5667\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 175us/step - loss: 11.3295 - val_loss: 58.5041\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 210us/step - loss: 11.4781 - val_loss: 58.8671\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 265us/step - loss: 11.3595 - val_loss: 58.3680\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 182us/step - loss: 11.7365 - val_loss: 59.4185\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.7155 - val_loss: 58.5756\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.3899 - val_loss: 59.1686\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.8683 - val_loss: 59.3008\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.6177 - val_loss: 59.5429\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 211us/step - loss: 11.3174 - val_loss: 59.2040\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 260us/step - loss: 11.4020 - val_loss: 59.0886\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 206us/step - loss: 11.7752 - val_loss: 59.1977\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.3301 - val_loss: 58.4935\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 438us/step - loss: 11.2990 - val_loss: 59.1995\n",
      "\n",
      "Mean Squared Error for iteration2: 47.54262312026416\n",
      "\n",
      "Iteration:  3\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 378us/step - loss: 11.4850 - val_loss: 59.0172\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 402us/step - loss: 11.4452 - val_loss: 58.3959\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 182us/step - loss: 11.2646 - val_loss: 60.1335\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 156us/step - loss: 11.2992 - val_loss: 57.8666\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.4738 - val_loss: 59.7730\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 387us/step - loss: 11.7065 - val_loss: 58.0160\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 365us/step - loss: 11.4911 - val_loss: 58.9697\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 147us/step - loss: 11.4504 - val_loss: 58.5398\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 166us/step - loss: 11.3929 - val_loss: 59.6457\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 157us/step - loss: 11.4389 - val_loss: 58.7628\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.4619 - val_loss: 59.2238\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 156us/step - loss: 11.5475 - val_loss: 59.3117\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 188us/step - loss: 11.2353 - val_loss: 59.0306\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 208us/step - loss: 11.5280 - val_loss: 58.5440\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.6711 - val_loss: 59.4631\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.4723 - val_loss: 58.9630\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 147us/step - loss: 11.5434 - val_loss: 58.4209\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 178us/step - loss: 11.8291 - val_loss: 59.1622\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.7175 - val_loss: 59.6837\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.4071 - val_loss: 58.1030\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.5060 - val_loss: 59.0185\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 11.3821 - val_loss: 58.9907\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.5702 - val_loss: 58.9391\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 146us/step - loss: 11.5711 - val_loss: 58.6967\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.4086 - val_loss: 59.1702\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.2634 - val_loss: 58.2060\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.4391 - val_loss: 59.4473\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.8677 - val_loss: 59.6957\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 173us/step - loss: 11.8350 - val_loss: 58.8890\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 316us/step - loss: 11.5114 - val_loss: 59.5103\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 280us/step - loss: 12.0017 - val_loss: 58.6598\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 244us/step - loss: 11.5805 - val_loss: 58.9120\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 152us/step - loss: 11.6778 - val_loss: 59.3682\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 170us/step - loss: 11.3491 - val_loss: 59.0830\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.4397 - val_loss: 58.5862\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.5731 - val_loss: 58.6982\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.7833 - val_loss: 59.6755\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 170us/step - loss: 11.7622 - val_loss: 59.6042\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.9722 - val_loss: 59.6410\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.7042 - val_loss: 58.5191\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 178us/step - loss: 11.4048 - val_loss: 59.0920\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.6729 - val_loss: 58.5397\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.8231 - val_loss: 59.1208\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.4817 - val_loss: 58.9823\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.7211 - val_loss: 58.8512\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 158us/step - loss: 11.4964 - val_loss: 58.9072\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.2781 - val_loss: 58.9379\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.5042 - val_loss: 58.9595\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.2543 - val_loss: 59.2816\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4026 - val_loss: 58.7195\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 150us/step - loss: 11.3046 - val_loss: 59.0504\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 149us/step - loss: 11.3111 - val_loss: 58.7624\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.3241 - val_loss: 59.3592\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.4516 - val_loss: 59.0837\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 138us/step - loss: 11.3348 - val_loss: 58.5941\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.4713 - val_loss: 58.7197\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.5753 - val_loss: 58.8042\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.3274 - val_loss: 59.1733\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 220us/step - loss: 11.4255 - val_loss: 58.9645\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.2766 - val_loss: 58.9282\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3953 - val_loss: 58.5516\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.4290 - val_loss: 58.7086\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.4985 - val_loss: 58.6984\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.3582 - val_loss: 58.8326\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 194us/step - loss: 11.7435 - val_loss: 59.0012\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 187us/step - loss: 11.6959 - val_loss: 57.8618\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.5649 - val_loss: 59.4407\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.6112 - val_loss: 58.6811\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.4617 - val_loss: 58.9032\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4357 - val_loss: 58.9044\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3933 - val_loss: 58.5970\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3905 - val_loss: 58.7631\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 143us/step - loss: 11.4482 - val_loss: 59.1972\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.3997 - val_loss: 59.2089\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3089 - val_loss: 58.4872\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.4654 - val_loss: 59.2764\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.5694 - val_loss: 58.5155\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3504 - val_loss: 59.9564\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4242 - val_loss: 58.4275\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2709 - val_loss: 58.8242\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5370 - val_loss: 59.0862\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.7884 - val_loss: 59.1387\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1737 - val_loss: 58.4279\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3098 - val_loss: 59.0671\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3688 - val_loss: 58.6332\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.4671 - val_loss: 59.1224\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7091 - val_loss: 58.7919\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4494 - val_loss: 58.8395\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.8517 - val_loss: 59.5510\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.6800 - val_loss: 58.6284\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3469 - val_loss: 59.9865\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5539 - val_loss: 58.6665\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4118 - val_loss: 58.6021\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3872 - val_loss: 58.9710\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5580 - val_loss: 58.7851\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 278us/step - loss: 12.1720 - val_loss: 61.2963\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 311us/step - loss: 12.2815 - val_loss: 58.3201\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.8288 - val_loss: 58.6221\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4885 - val_loss: 58.6300\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7276 - val_loss: 58.7962\n",
      "\n",
      "Mean Squared Error for iteration3: 48.276994484090025\n",
      "\n",
      "Iteration:  4\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4195 - val_loss: 58.5396\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7330 - val_loss: 59.2079\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5784 - val_loss: 58.3690\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.6209 - val_loss: 59.8886\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.9435 - val_loss: 58.8562\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 95us/step - loss: 11.2739 - val_loss: 58.9063\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4565 - val_loss: 58.7023\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.4511 - val_loss: 58.5658\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3623 - val_loss: 58.4864\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3331 - val_loss: 59.0049\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2994 - val_loss: 58.2382\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4296 - val_loss: 59.4284\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3255 - val_loss: 58.8109\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6723 - val_loss: 59.0339\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4404 - val_loss: 58.9850\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4228 - val_loss: 59.1574\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2932 - val_loss: 58.1793\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3837 - val_loss: 58.9738\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2579 - val_loss: 58.7710\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2830 - val_loss: 59.8174\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6226 - val_loss: 59.3460\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.9093 - val_loss: 61.0519\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 12.0488 - val_loss: 58.2631\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4727 - val_loss: 59.2693\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4144 - val_loss: 58.7077\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.4973 - val_loss: 58.7671\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4809 - val_loss: 59.8248\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4958 - val_loss: 58.3767\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4950 - val_loss: 58.2078\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.7280 - val_loss: 59.4818\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.6215 - val_loss: 59.2068\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.2791 - val_loss: 58.2346\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.6171 - val_loss: 58.9128\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.2718 - val_loss: 58.7231\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2941 - val_loss: 59.3901\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4876 - val_loss: 58.5857\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.6559 - val_loss: 59.0657\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3872 - val_loss: 59.1121\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3629 - val_loss: 59.0829\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.9217 - val_loss: 59.1398\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.8950 - val_loss: 58.8476\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.2885 - val_loss: 58.6736\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.4194 - val_loss: 59.1721\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3840 - val_loss: 58.8302\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3727 - val_loss: 58.9825\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2783 - val_loss: 58.9225\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4242 - val_loss: 58.3796\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2617 - val_loss: 58.7509\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4818 - val_loss: 59.5122\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3666 - val_loss: 58.7938\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2888 - val_loss: 58.4523\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5481 - val_loss: 59.2530\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4237 - val_loss: 58.9085\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2779 - val_loss: 59.0152\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5119 - val_loss: 58.7457\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3748 - val_loss: 59.0090\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5494 - val_loss: 59.5497\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6822 - val_loss: 58.4989\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 158us/step - loss: 11.5275 - val_loss: 59.1692\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.3240 - val_loss: 58.8294\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3898 - val_loss: 58.6631\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3324 - val_loss: 59.1001\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3216 - val_loss: 58.1922\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3486 - val_loss: 58.8492\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3457 - val_loss: 58.8657\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2476 - val_loss: 58.6909\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4913 - val_loss: 59.0412\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4022 - val_loss: 58.5281\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2913 - val_loss: 59.0690\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2897 - val_loss: 59.0798\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1931 - val_loss: 58.4607\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3331 - val_loss: 58.8398\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3646 - val_loss: 59.1272\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2463 - val_loss: 59.1637\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4848 - val_loss: 58.4385\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4211 - val_loss: 59.4531\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3592 - val_loss: 58.5560\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4639 - val_loss: 58.9006\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2377 - val_loss: 58.8479\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.6430 - val_loss: 59.4483\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4142 - val_loss: 58.9610\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2846 - val_loss: 58.7034\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3464 - val_loss: 60.0916\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 82us/step - loss: 11.4339 - val_loss: 58.6812\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3793 - val_loss: 59.3422\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3977 - val_loss: 58.6015\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4133 - val_loss: 58.8810\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2518 - val_loss: 59.3207\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - ETA: 0s - loss: 11.76 - 0s 83us/step - loss: 11.4011 - val_loss: 58.6899\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4464 - val_loss: 58.7956\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2469 - val_loss: 59.2251\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3322 - val_loss: 58.6565\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3824 - val_loss: 59.2153\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.7215 - val_loss: 59.9885\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4567 - val_loss: 58.2341\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3394 - val_loss: 59.8123\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.8051 - val_loss: 59.5111\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.4453 - val_loss: 59.1613\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3003 - val_loss: 59.2705\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3126 - val_loss: 58.2329\n",
      "\n",
      "Mean Squared Error for iteration4: 46.78450915051589\n",
      "\n",
      "Iteration:  5\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 78us/step - loss: 11.4179 - val_loss: 59.5312\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4870 - val_loss: 58.8984\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.4110 - val_loss: 58.8688\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5499 - val_loss: 58.8528\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2402 - val_loss: 59.0075\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3739 - val_loss: 59.6114\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4721 - val_loss: 59.0321\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5959 - val_loss: 58.7750\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3028 - val_loss: 58.8414\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2853 - val_loss: 59.6535\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6500 - val_loss: 58.7946\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.6804 - val_loss: 59.5851\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.9479 - val_loss: 59.4121\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5606 - val_loss: 59.3227\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2958 - val_loss: 59.0774\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2954 - val_loss: 59.3344\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.4619 - val_loss: 58.7036\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6088 - val_loss: 59.4502\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3149 - val_loss: 58.7513\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3387 - val_loss: 58.8810\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.4306 - val_loss: 58.5810\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3066 - val_loss: 58.7267\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4747 - val_loss: 58.8975\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3267 - val_loss: 58.2228\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5713 - val_loss: 59.0307\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4639 - val_loss: 58.8711\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4710 - val_loss: 58.4115\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3874 - val_loss: 59.0693\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4109 - val_loss: 58.9382\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4623 - val_loss: 59.3165\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4675 - val_loss: 58.3108\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4822 - val_loss: 59.4988\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4868 - val_loss: 59.4614\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.8900 - val_loss: 59.6211\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.3954 - val_loss: 59.7812\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 12.0368 - val_loss: 59.3617\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5527 - val_loss: 58.1921\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.4361 - val_loss: 59.6192\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5469 - val_loss: 58.5950\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4821 - val_loss: 58.6623\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5647 - val_loss: 59.2961\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.9082 - val_loss: 59.0073\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 12.1455 - val_loss: 59.4567\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.6310 - val_loss: 60.8981\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.8664 - val_loss: 58.9252\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5471 - val_loss: 59.6099\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7204 - val_loss: 59.4764\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3263 - val_loss: 58.5544\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3703 - val_loss: 58.8427\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5502 - val_loss: 59.2104\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3649 - val_loss: 58.6705\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3329 - val_loss: 59.0800\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2917 - val_loss: 58.6478\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2739 - val_loss: 59.5277\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3857 - val_loss: 60.0360\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.9867 - val_loss: 59.1773\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4408 - val_loss: 58.7354\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5154 - val_loss: 59.0007\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4589 - val_loss: 58.7835\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.6201 - val_loss: 59.4406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3135 - val_loss: 58.8733\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4215 - val_loss: 59.1050\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2505 - val_loss: 59.6123\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6574 - val_loss: 59.0298\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4291 - val_loss: 59.2467\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5303 - val_loss: 59.4780\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2320 - val_loss: 58.4975\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3200 - val_loss: 58.6574\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4294 - val_loss: 58.3359\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3539 - val_loss: 60.0018\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4973 - val_loss: 58.6459\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2772 - val_loss: 59.0478\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4238 - val_loss: 59.7291\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4662 - val_loss: 59.1284\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3211 - val_loss: 58.6916\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4878 - val_loss: 59.2243\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.3409 - val_loss: 58.6924\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5461 - val_loss: 58.6645\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4686 - val_loss: 58.8685\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3567 - val_loss: 58.7685\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4578 - val_loss: 58.4771\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4904 - val_loss: 60.0987\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3029 - val_loss: 58.4237\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.7057 - val_loss: 59.2619\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4165 - val_loss: 58.7825\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3519 - val_loss: 58.5308\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6568 - val_loss: 59.5764\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3434 - val_loss: 58.8441\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3645 - val_loss: 58.8560\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3048 - val_loss: 58.7485\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4194 - val_loss: 58.7332\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4594 - val_loss: 59.7039\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2729 - val_loss: 58.3583\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5647 - val_loss: 59.6314\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4758 - val_loss: 58.2595\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3086 - val_loss: 58.6124\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3276 - val_loss: 58.9043\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2652 - val_loss: 58.7557\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2474 - val_loss: 58.7353\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1983 - val_loss: 59.3391\n",
      "\n",
      "Mean Squared Error for iteration5: 47.69979858766106\n",
      "\n",
      "Iteration:  6\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.4387 - val_loss: 58.4759\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.5686 - val_loss: 59.1633\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.4712 - val_loss: 58.5470\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 11.2634 - val_loss: 58.6266\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5427 - val_loss: 58.6683\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.6824 - val_loss: 59.3400\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3533 - val_loss: 58.4148\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.4289 - val_loss: 58.8191\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.4831 - val_loss: 58.9546\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4106 - val_loss: 59.1911\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4526 - val_loss: 59.2207\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4207 - val_loss: 59.1797\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.5302 - val_loss: 58.5444\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 209us/step - loss: 11.3753 - val_loss: 59.3084\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5700 - val_loss: 58.3483\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3164 - val_loss: 59.2952\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5929 - val_loss: 59.0095\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.4467 - val_loss: 59.2585\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.2694 - val_loss: 59.1700\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.5237 - val_loss: 59.6698\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4659 - val_loss: 58.6586\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.2276 - val_loss: 59.4927\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3561 - val_loss: 58.8005\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3761 - val_loss: 58.9931\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.3270 - val_loss: 59.5577\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 169us/step - loss: 11.3391 - val_loss: 59.1768\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 154us/step - loss: 11.2883 - val_loss: 59.1690\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 174us/step - loss: 11.3619 - val_loss: 59.2481\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.6307 - val_loss: 59.7453\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.9878 - val_loss: 58.4993\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.8343 - val_loss: 58.7104\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5955 - val_loss: 59.2549\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4285 - val_loss: 58.6252\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3810 - val_loss: 58.6629\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5634 - val_loss: 59.0265\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5092 - val_loss: 59.8718\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3454 - val_loss: 59.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.5987 - val_loss: 59.4640\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.5032 - val_loss: 58.5753\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.7107 - val_loss: 59.6017\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.3524 - val_loss: 59.1161\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.5692 - val_loss: 58.5693\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3601 - val_loss: 59.3216\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 11.5396 - val_loss: 59.0178\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.4465 - val_loss: 58.2981\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.5380 - val_loss: 59.6259\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7190 - val_loss: 58.6756\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5746 - val_loss: 58.6355\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6381 - val_loss: 59.5638\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 12.1231 - val_loss: 60.5125\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 570us/step - loss: 11.8433 - val_loss: 59.0830\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4349 - val_loss: 59.9108\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3582 - val_loss: 58.2063\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4411 - val_loss: 60.0086\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5562 - val_loss: 58.6716\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5316 - val_loss: 59.2192\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4334 - val_loss: 58.8146\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4701 - val_loss: 59.8862\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.7816 - val_loss: 58.7861\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.5096 - val_loss: 58.8363\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.3145 - val_loss: 58.9777\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 180us/step - loss: 11.5170 - val_loss: 59.4543\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.5495 - val_loss: 58.6746\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.3973 - val_loss: 59.2624\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5875 - val_loss: 58.1373\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3426 - val_loss: 59.2510\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.7066 - val_loss: 58.2919\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4172 - val_loss: 58.7288\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3032 - val_loss: 59.2084\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3544 - val_loss: 59.0634\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2571 - val_loss: 59.0223\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4936 - val_loss: 58.6080\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.9395 - val_loss: 59.0188\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3111 - val_loss: 58.3476\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.4387 - val_loss: 59.7069\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3054 - val_loss: 58.4155\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4959 - val_loss: 59.1931\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4501 - val_loss: 58.8339\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6205 - val_loss: 59.6701\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3543 - val_loss: 58.6818\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3849 - val_loss: 58.1731\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.3286 - val_loss: 58.9348\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.3679 - val_loss: 59.1432\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.9713 - val_loss: 59.0899\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.9999 - val_loss: 58.4340\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6022 - val_loss: 59.8300\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3489 - val_loss: 58.3592\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4319 - val_loss: 58.9489\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4064 - val_loss: 59.5245\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5998 - val_loss: 59.0377\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.6388 - val_loss: 59.4929\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6247 - val_loss: 58.8597\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3290 - val_loss: 59.0142\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4569 - val_loss: 59.5908\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3764 - val_loss: 58.8773\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3757 - val_loss: 59.0642\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4263 - val_loss: 59.2653\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3203 - val_loss: 58.9317\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4279 - val_loss: 58.4205\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4921 - val_loss: 59.4259\n",
      "\n",
      "Mean Squared Error for iteration6: 47.769947751170015\n",
      "\n",
      "Iteration:  7\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3593 - val_loss: 58.7892\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2911 - val_loss: 58.7159\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4418 - val_loss: 59.3704\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5358 - val_loss: 59.0083\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5708 - val_loss: 59.1059\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7517 - val_loss: 59.7093\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 12.3773 - val_loss: 59.3959\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3801 - val_loss: 59.3355\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3292 - val_loss: 59.2318\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3700 - val_loss: 58.6947\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2199 - val_loss: 59.4064\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4310 - val_loss: 58.8824\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4367 - val_loss: 59.0909\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.5563 - val_loss: 58.8205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4480 - val_loss: 59.6119\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4229 - val_loss: 59.2958\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3294 - val_loss: 59.1925\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.9429 - val_loss: 59.1168\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3677 - val_loss: 59.2640\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3160 - val_loss: 58.8307\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4151 - val_loss: 58.5593\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3547 - val_loss: 59.2066\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3222 - val_loss: 58.8932\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2948 - val_loss: 59.1221\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.6791 - val_loss: 59.0487\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4203 - val_loss: 58.9522\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4813 - val_loss: 58.0808\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4724 - val_loss: 59.7424\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3500 - val_loss: 58.5787\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5896 - val_loss: 58.3398\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5015 - val_loss: 58.6997\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5065 - val_loss: 58.4275\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5247 - val_loss: 58.9826\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4541 - val_loss: 58.5630\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3252 - val_loss: 59.9905\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.9768 - val_loss: 59.3732\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.5323 - val_loss: 58.5618\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3060 - val_loss: 58.8068\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4585 - val_loss: 58.7300\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3283 - val_loss: 59.0102\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4887 - val_loss: 59.0577\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4092 - val_loss: 58.6737\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3257 - val_loss: 58.5667\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.4868 - val_loss: 58.6635\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4598 - val_loss: 58.7930\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.4133 - val_loss: 59.0532\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4118 - val_loss: 58.0616\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4166 - val_loss: 59.0567\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2549 - val_loss: 58.6228\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3098 - val_loss: 59.3594\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4969 - val_loss: 59.1459\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3164 - val_loss: 59.2585\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2598 - val_loss: 59.2534\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4296 - val_loss: 59.0523\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3056 - val_loss: 58.8264\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4120 - val_loss: 58.1344\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2513 - val_loss: 59.0844\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3486 - val_loss: 58.7136\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4587 - val_loss: 58.9303\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3693 - val_loss: 58.9102\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.7559 - val_loss: 59.1593\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3849 - val_loss: 59.0753\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.1940 - val_loss: 59.1109\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4856 - val_loss: 58.9700\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3235 - val_loss: 58.4863\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5715 - val_loss: 58.7367\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2129 - val_loss: 58.7347\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4987 - val_loss: 58.6894\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3803 - val_loss: 58.6038\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4181 - val_loss: 58.8232\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4710 - val_loss: 59.7701\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3414 - val_loss: 59.2605\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5364 - val_loss: 58.4567\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4986 - val_loss: 58.7068\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3136 - val_loss: 58.7936\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 12.3275 - val_loss: 58.6952\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2779 - val_loss: 59.4324\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5245 - val_loss: 59.7180\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.8589 - val_loss: 58.7438\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.8502 - val_loss: 59.0548\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4806 - val_loss: 59.0981\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4659 - val_loss: 58.7568\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4682 - val_loss: 58.6623\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3503 - val_loss: 58.9750\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4117 - val_loss: 59.3164\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.7849 - val_loss: 58.7383\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3888 - val_loss: 58.6975\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2661 - val_loss: 58.6831\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3585 - val_loss: 58.7112\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3588 - val_loss: 59.3855\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4838 - val_loss: 58.9480\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4881 - val_loss: 59.2124\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 85us/step - loss: 11.6224 - val_loss: 58.8968\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3668 - val_loss: 59.2295\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3433 - val_loss: 59.2606\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.8316 - val_loss: 60.4066\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.8241 - val_loss: 58.8849\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2631 - val_loss: 59.8907\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4856 - val_loss: 58.9402\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4033 - val_loss: 58.9758\n",
      "\n",
      "Mean Squared Error for iteration7: 47.50060516898658\n",
      "\n",
      "Iteration:  8\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3079 - val_loss: 58.7746\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2784 - val_loss: 58.8680\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2847 - val_loss: 59.0012\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2527 - val_loss: 58.5299\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3023 - val_loss: 59.2452\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3897 - val_loss: 58.7233\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3976 - val_loss: 59.1124\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2878 - val_loss: 58.2013\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4402 - val_loss: 60.2349\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3205 - val_loss: 57.9438\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3401 - val_loss: 59.6137\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5167 - val_loss: 58.6684\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2755 - val_loss: 58.7732\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3921 - val_loss: 58.9231\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4046 - val_loss: 59.1746\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6129 - val_loss: 59.8898\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.6669 - val_loss: 58.9720\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4183 - val_loss: 59.1872\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3006 - val_loss: 58.9634\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4429 - val_loss: 59.5685\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5954 - val_loss: 58.4314\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.6758 - val_loss: 58.8540\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3209 - val_loss: 59.2965\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3662 - val_loss: 58.4723\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5090 - val_loss: 59.0993\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2549 - val_loss: 59.2190\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.8053 - val_loss: 59.5892\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5725 - val_loss: 58.3902\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4550 - val_loss: 58.9471\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2008 - val_loss: 58.8560\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4931 - val_loss: 58.6709\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.7687 - val_loss: 58.8846\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2476 - val_loss: 59.0732\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.1719 - val_loss: 58.8172\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4116 - val_loss: 58.8359\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.4904 - val_loss: 58.6911\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3062 - val_loss: 59.0894\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4595 - val_loss: 58.5503\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2432 - val_loss: 59.3434\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5105 - val_loss: 59.3112\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4934 - val_loss: 58.7218\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2945 - val_loss: 58.4844\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2088 - val_loss: 58.8782\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5749 - val_loss: 58.7406\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4065 - val_loss: 58.9597\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2524 - val_loss: 58.8326\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2626 - val_loss: 58.8384\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3786 - val_loss: 58.6806\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4201 - val_loss: 58.6421\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3029 - val_loss: 58.5155\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3123 - val_loss: 58.8464\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3969 - val_loss: 59.3512\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7421 - val_loss: 58.9716\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2414 - val_loss: 58.4939\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.7449 - val_loss: 58.4949\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4118 - val_loss: 59.7925\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3876 - val_loss: 58.5804\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6953 - val_loss: 59.6529\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5738 - val_loss: 59.1672\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4881 - val_loss: 58.5558\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3299 - val_loss: 58.7744\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4976 - val_loss: 59.1150\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4085 - val_loss: 59.1488\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.7007 - val_loss: 59.1383\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3330 - val_loss: 58.7626\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3171 - val_loss: 58.6821\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2839 - val_loss: 58.5330\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4895 - val_loss: 59.2279\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3735 - val_loss: 58.7673\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 82us/step - loss: 11.5979 - val_loss: 58.9152\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2846 - val_loss: 59.4493\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5272 - val_loss: 58.3642\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3747 - val_loss: 59.0636\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5747 - val_loss: 59.2872\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4084 - val_loss: 59.0937\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4656 - val_loss: 59.0196\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.7534 - val_loss: 59.0597\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2982 - val_loss: 58.7952\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5443 - val_loss: 59.8231\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4646 - val_loss: 59.3603\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2072 - val_loss: 58.6463\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3217 - val_loss: 58.8563\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6554 - val_loss: 59.4194\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6194 - val_loss: 59.2931\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.6093 - val_loss: 59.1608\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.6048 - val_loss: 59.0366\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3062 - val_loss: 58.6759\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.1832 - val_loss: 58.6813\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4238 - val_loss: 58.9518\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4999 - val_loss: 58.7281\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.8604 - val_loss: 58.7801\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4687 - val_loss: 58.7878\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.8104 - val_loss: 58.4690\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3729 - val_loss: 59.1222\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2290 - val_loss: 58.6478\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2814 - val_loss: 58.8430\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 154us/step - loss: 11.4034 - val_loss: 59.0150\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4914 - val_loss: 59.0361\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3810 - val_loss: 58.9859\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2849 - val_loss: 58.9824\n",
      "\n",
      "Mean Squared Error for iteration8: 47.17568581996289\n",
      "\n",
      "Iteration:  9\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.4007 - val_loss: 59.1733\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3633 - val_loss: 58.8721\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5226 - val_loss: 58.2418\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2762 - val_loss: 59.0008\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 12.0842 - val_loss: 58.1922\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4817 - val_loss: 58.9882\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3394 - val_loss: 59.1191\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3127 - val_loss: 59.0321\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3541 - val_loss: 59.0923\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.3620 - val_loss: 58.6213\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.9414 - val_loss: 60.1874\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5843 - val_loss: 57.9227\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3007 - val_loss: 59.6335\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2099 - val_loss: 58.9499\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3535 - val_loss: 58.9020\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.4786 - val_loss: 58.7344\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.7608 - val_loss: 58.6760\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7277 - val_loss: 59.3846\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3743 - val_loss: 59.2627\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3734 - val_loss: 59.2452\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.5634 - val_loss: 58.6241\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4670 - val_loss: 58.9159\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3347 - val_loss: 60.3834\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6274 - val_loss: 58.3691\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3945 - val_loss: 58.7512\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2296 - val_loss: 58.9042\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3992 - val_loss: 60.0620\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4989 - val_loss: 58.6532\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3564 - val_loss: 59.1488\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3695 - val_loss: 59.2184\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4363 - val_loss: 59.5271\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6442 - val_loss: 58.9456\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3434 - val_loss: 58.8033\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3365 - val_loss: 58.8597\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4108 - val_loss: 59.1183\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2706 - val_loss: 58.7656\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2967 - val_loss: 59.2404\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3037 - val_loss: 58.8920\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4024 - val_loss: 59.5188\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4354 - val_loss: 58.7325\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4379 - val_loss: 58.5124\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5854 - val_loss: 59.1871\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.7249 - val_loss: 58.9902\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5423 - val_loss: 58.8797\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6972 - val_loss: 58.4691\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2501 - val_loss: 58.8509\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 83us/step - loss: 11.2861 - val_loss: 58.4820\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3123 - val_loss: 59.2755\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2369 - val_loss: 59.1215\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.7049 - val_loss: 58.7366\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 78us/step - loss: 11.5323 - val_loss: 59.6561\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.8279 - val_loss: 59.6148\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5485 - val_loss: 58.8924\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.1784 - val_loss: 59.1031\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.5617 - val_loss: 58.4962\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1897 - val_loss: 59.1149\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4384 - val_loss: 58.8619\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.7402 - val_loss: 59.4207\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3163 - val_loss: 59.1518\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4938 - val_loss: 59.6805\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.4722 - val_loss: 58.8911\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6870 - val_loss: 58.8655\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3836 - val_loss: 59.3490\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3960 - val_loss: 58.7837\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.6644 - val_loss: 59.0052\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.6253 - val_loss: 58.5160\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.6621 - val_loss: 59.5996\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3402 - val_loss: 58.2953\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1906 - val_loss: 58.7838\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3421 - val_loss: 58.8591\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2126 - val_loss: 59.2350\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.6908 - val_loss: 59.5544\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3837 - val_loss: 59.7677\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3323 - val_loss: 59.0405\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3284 - val_loss: 58.8585\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2807 - val_loss: 58.8876\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3916 - val_loss: 59.3556\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.7860 - val_loss: 59.4420\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3441 - val_loss: 59.0555\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2728 - val_loss: 58.7832\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3166 - val_loss: 59.5850\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5346 - val_loss: 58.6583\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5237 - val_loss: 59.6007\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4475 - val_loss: 58.3572\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.5871 - val_loss: 59.1497\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.5237 - val_loss: 59.1829\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3283 - val_loss: 58.8753\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1433 - val_loss: 58.6260\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4421 - val_loss: 58.8341\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.4955 - val_loss: 59.4016\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6321 - val_loss: 58.8389\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2911 - val_loss: 59.2572\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4867 - val_loss: 58.8375\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 12.0863 - val_loss: 59.3496\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.6222 - val_loss: 59.1944\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3427 - val_loss: 58.5388\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3072 - val_loss: 59.2370\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4563 - val_loss: 58.6242\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3956 - val_loss: 58.9855\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1004 - val_loss: 58.9549\n",
      "\n",
      "Mean Squared Error for iteration9: 47.122843993669576\n",
      "\n",
      "Iteration:  10\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2659 - val_loss: 58.7888\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2237 - val_loss: 58.4460\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3112 - val_loss: 58.3665\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 11.4560 - val_loss: 59.5635\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.2379 - val_loss: 58.7685\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4662 - val_loss: 59.3284\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2288 - val_loss: 58.5936\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4141 - val_loss: 59.7870\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5915 - val_loss: 59.2908\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3810 - val_loss: 58.7751\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1780 - val_loss: 59.3008\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3712 - val_loss: 59.3038\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.8493 - val_loss: 58.4586\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.8332 - val_loss: 59.8394\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5794 - val_loss: 58.7813\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2233 - val_loss: 58.4428\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4278 - val_loss: 59.3959\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5732 - val_loss: 58.8464\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3692 - val_loss: 58.8818\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5737 - val_loss: 58.9207\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3467 - val_loss: 59.3919\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3763 - val_loss: 58.3334\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3108 - val_loss: 58.8548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4508 - val_loss: 59.1236\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2868 - val_loss: 58.2075\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4165 - val_loss: 60.3785\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.5757 - val_loss: 58.8938\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2994 - val_loss: 59.3797\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.4727 - val_loss: 58.5646\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3662 - val_loss: 58.2030\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5628 - val_loss: 59.1553\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2369 - val_loss: 58.6207\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2460 - val_loss: 58.1778\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2392 - val_loss: 59.3708\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4569 - val_loss: 58.0290\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.3663 - val_loss: 59.1445\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.1700 - val_loss: 58.7059\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.8672 - val_loss: 59.3537\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3893 - val_loss: 59.1239\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5716 - val_loss: 58.8252\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4063 - val_loss: 58.2751\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4855 - val_loss: 58.4956\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5615 - val_loss: 59.6186\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.8713 - val_loss: 59.2915\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.3709 - val_loss: 59.3343\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3180 - val_loss: 58.2583\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4254 - val_loss: 58.8327\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4836 - val_loss: 59.3625\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.2864 - val_loss: 58.9367\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2491 - val_loss: 58.7031\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4027 - val_loss: 59.1172\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4684 - val_loss: 59.0681\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5115 - val_loss: 58.9238\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4572 - val_loss: 59.0069\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1650 - val_loss: 58.4953\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2483 - val_loss: 58.6019\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.3953 - val_loss: 59.0715\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6207 - val_loss: 58.2853\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.1559 - val_loss: 58.9116\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2110 - val_loss: 58.5393\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5057 - val_loss: 58.8907\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2574 - val_loss: 58.9278\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 278us/step - loss: 11.3317 - val_loss: 59.3697\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.6443 - val_loss: 58.7430\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 177us/step - loss: 11.5120 - val_loss: 59.4493\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.4429 - val_loss: 59.0750\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4976 - val_loss: 59.0791\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3772 - val_loss: 59.2382\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5119 - val_loss: 59.2657\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3499 - val_loss: 58.6305\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2200 - val_loss: 59.1237\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 372us/step - loss: 11.3707 - val_loss: 58.7487\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 312us/step - loss: 11.4658 - val_loss: 58.3750\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4075 - val_loss: 59.0380\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3359 - val_loss: 59.1400\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4071 - val_loss: 58.9827\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2923 - val_loss: 59.3181\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3991 - val_loss: 59.3672\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7701 - val_loss: 59.0236\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3440 - val_loss: 59.5990\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4477 - val_loss: 58.9319\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5093 - val_loss: 59.0566\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.5763 - val_loss: 58.6714\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.4665 - val_loss: 59.0014\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.2545 - val_loss: 58.7842\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2068 - val_loss: 58.8372\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3584 - val_loss: 58.3304\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3494 - val_loss: 58.5012\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2467 - val_loss: 59.0794\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 153us/step - loss: 11.4914 - val_loss: 59.1498\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.6871 - val_loss: 58.9696\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4333 - val_loss: 59.2895\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5288 - val_loss: 58.9200\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2621 - val_loss: 58.6704\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3274 - val_loss: 58.6042\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.3158 - val_loss: 58.3074\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.8198 - val_loss: 59.8361\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.9074 - val_loss: 58.8713\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.8481 - val_loss: 59.7677\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 12.0044 - val_loss: 59.4159\n",
      "\n",
      "Mean Squared Error for iteration10: 49.781959558908895\n",
      "\n",
      "Iteration:  11\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 94us/step - loss: 11.9544 - val_loss: 59.1704\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2668 - val_loss: 59.4057\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2635 - val_loss: 59.6173\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5215 - val_loss: 59.0127\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5477 - val_loss: 58.8760\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3957 - val_loss: 58.7458\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2573 - val_loss: 58.2656\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2652 - val_loss: 59.0949\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1836 - val_loss: 58.5568\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3978 - val_loss: 58.9447\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3544 - val_loss: 59.4482\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3306 - val_loss: 59.6540\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2621 - val_loss: 58.2142\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3813 - val_loss: 59.0037\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4476 - val_loss: 59.8015\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5049 - val_loss: 59.1070\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1554 - val_loss: 58.7067\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4142 - val_loss: 58.7977\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2997 - val_loss: 58.7155\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2353 - val_loss: 58.6048\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2633 - val_loss: 59.8721\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4630 - val_loss: 58.1180\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2752 - val_loss: 59.2957\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4841 - val_loss: 58.5400\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4738 - val_loss: 59.2614\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2280 - val_loss: 59.1863\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3176 - val_loss: 58.8138\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.6570 - val_loss: 58.9309\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2931 - val_loss: 59.1137\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3830 - val_loss: 58.9405\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7785 - val_loss: 58.8933\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3843 - val_loss: 59.7783\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2553 - val_loss: 58.2500\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3198 - val_loss: 58.5629\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.5108 - val_loss: 59.5828\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7129 - val_loss: 59.1707\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4003 - val_loss: 58.8544\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3714 - val_loss: 58.3307\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2197 - val_loss: 59.4645\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5248 - val_loss: 58.8674\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2771 - val_loss: 58.6313\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2904 - val_loss: 58.8746\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.6163 - val_loss: 58.5882\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 12.0404 - val_loss: 59.0656\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6563 - val_loss: 58.5846\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3148 - val_loss: 58.8844\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3961 - val_loss: 59.1112\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.8508 - val_loss: 59.1689\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.7482 - val_loss: 59.3566\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 12.1726 - val_loss: 59.6130\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7366 - val_loss: 58.7393\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4551 - val_loss: 59.2301\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2931 - val_loss: 58.8288\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3170 - val_loss: 58.7951\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2847 - val_loss: 58.8997\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3651 - val_loss: 58.8336\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6893 - val_loss: 60.7159\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7758 - val_loss: 58.8590\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.3094 - val_loss: 59.3460\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2872 - val_loss: 58.1867\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2955 - val_loss: 59.6855\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2998 - val_loss: 58.5393\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3378 - val_loss: 58.7641\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.6075 - val_loss: 59.1697\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.9033 - val_loss: 58.5721\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.5206 - val_loss: 58.7407\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.1559 - val_loss: 59.5467\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2052 - val_loss: 59.2606\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5657 - val_loss: 58.1682\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.7050 - val_loss: 59.0926\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3648 - val_loss: 58.9714\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3483 - val_loss: 58.6838\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3124 - val_loss: 59.2465\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2426 - val_loss: 58.4336\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3601 - val_loss: 58.8348\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4758 - val_loss: 58.9769\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6969 - val_loss: 58.8297\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2480 - val_loss: 59.7556\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 90us/step - loss: 11.2933 - val_loss: 58.8815\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.5718 - val_loss: 58.7385\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4771 - val_loss: 59.0554\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2744 - val_loss: 58.3881\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2586 - val_loss: 59.1300\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5952 - val_loss: 59.0812\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2997 - val_loss: 58.6743\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3456 - val_loss: 58.9684\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2529 - val_loss: 58.9732\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2755 - val_loss: 58.8868\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2843 - val_loss: 59.0213\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2519 - val_loss: 58.6961\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4017 - val_loss: 58.9230\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.7799 - val_loss: 59.3090\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.6174 - val_loss: 58.3372\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3236 - val_loss: 58.9810\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3632 - val_loss: 59.5007\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.1821 - val_loss: 58.9942\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2623 - val_loss: 59.3999\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2259 - val_loss: 58.5584\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.3992 - val_loss: 58.2336\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2717 - val_loss: 59.4054\n",
      "\n",
      "Mean Squared Error for iteration11: 47.80982134523944\n",
      "\n",
      "Iteration:  12\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2557 - val_loss: 58.8932\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3344 - val_loss: 59.4698\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4118 - val_loss: 60.0986\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3847 - val_loss: 59.2264\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3518 - val_loss: 58.9617\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.4516 - val_loss: 59.2874\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5503 - val_loss: 57.9639\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.7164 - val_loss: 61.1534\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.8877 - val_loss: 58.8416\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.6973 - val_loss: 60.2320\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4472 - val_loss: 58.7722\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4535 - val_loss: 59.4500\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.6228 - val_loss: 58.4095\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3586 - val_loss: 59.3057\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3515 - val_loss: 58.8923\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3777 - val_loss: 58.9827\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.7262 - val_loss: 59.4754\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2987 - val_loss: 59.1551\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5753 - val_loss: 59.2128\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5622 - val_loss: 59.1060\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.8695 - val_loss: 59.3796\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.1875 - val_loss: 58.8299\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4105 - val_loss: 58.8669\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2598 - val_loss: 58.8028\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1750 - val_loss: 59.6303\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7818 - val_loss: 59.0146\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6316 - val_loss: 58.7130\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4552 - val_loss: 58.9475\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4507 - val_loss: 58.6286\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.7048 - val_loss: 58.8425\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3524 - val_loss: 59.0433\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3318 - val_loss: 59.1336\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4547 - val_loss: 58.0020\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4049 - val_loss: 60.2365\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2756 - val_loss: 58.8351\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5240 - val_loss: 59.1141\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3366 - val_loss: 59.0120\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4440 - val_loss: 59.2653\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5977 - val_loss: 59.8336\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5913 - val_loss: 59.0330\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1937 - val_loss: 58.9559\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1997 - val_loss: 59.0033\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2157 - val_loss: 59.0411\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4235 - val_loss: 58.0381\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4031 - val_loss: 59.4431\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2977 - val_loss: 58.9657\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.3184 - val_loss: 59.2100\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5563 - val_loss: 59.6196\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.8632 - val_loss: 59.2277\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4047 - val_loss: 58.6108\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1927 - val_loss: 59.2369\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6209 - val_loss: 59.6880\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2525 - val_loss: 58.0308\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2075 - val_loss: 59.4445\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4754 - val_loss: 59.8270\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 84us/step - loss: 11.6872 - val_loss: 59.4790\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5664 - val_loss: 59.3835\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3491 - val_loss: 58.4536\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2990 - val_loss: 58.6094\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2090 - val_loss: 59.7874\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2184 - val_loss: 58.9006\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3096 - val_loss: 58.6572\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2420 - val_loss: 58.7681\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.4306 - val_loss: 59.3335\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 12.1132 - val_loss: 59.0211\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.9902 - val_loss: 59.5775\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4387 - val_loss: 59.1019\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3830 - val_loss: 58.9964\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4397 - val_loss: 59.1291\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3425 - val_loss: 58.9237\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4044 - val_loss: 58.7308\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3911 - val_loss: 58.6877\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4139 - val_loss: 59.0467\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2475 - val_loss: 58.3364\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2496 - val_loss: 58.9426\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3019 - val_loss: 59.1284\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.1573 - val_loss: 58.7264\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2651 - val_loss: 59.2791\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2036 - val_loss: 58.8439\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1501 - val_loss: 58.8654\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2976 - val_loss: 58.9093\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1757 - val_loss: 58.6735\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1747 - val_loss: 58.5223\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2356 - val_loss: 58.6922\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5002 - val_loss: 59.2152\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.3996 - val_loss: 58.7561\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.3719 - val_loss: 59.0487\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5212 - val_loss: 58.3276\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3800 - val_loss: 59.1823\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2477 - val_loss: 58.7334\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4391 - val_loss: 58.7889\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2270 - val_loss: 58.9870\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.1605 - val_loss: 58.5623\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.5782 - val_loss: 59.6683\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7956 - val_loss: 58.8197\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4357 - val_loss: 59.3268\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2854 - val_loss: 59.0135\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4036 - val_loss: 58.6552\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.5236 - val_loss: 58.7417\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4774 - val_loss: 58.7912\n",
      "\n",
      "Mean Squared Error for iteration12: 46.91001882848166\n",
      "\n",
      "Iteration:  13\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2877 - val_loss: 59.9559\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.8230 - val_loss: 58.8483\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3733 - val_loss: 59.1241\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2799 - val_loss: 58.8123\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2489 - val_loss: 59.2316\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4834 - val_loss: 58.3595\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3459 - val_loss: 59.6468\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3579 - val_loss: 59.1569\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3734 - val_loss: 59.3919\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3725 - val_loss: 58.5407\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2980 - val_loss: 59.1325\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3860 - val_loss: 58.9327\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1244 - val_loss: 58.8050\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2539 - val_loss: 58.8178\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4002 - val_loss: 58.8611\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3605 - val_loss: 58.7950\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4603 - val_loss: 59.0881\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3821 - val_loss: 59.7276\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3898 - val_loss: 59.0626\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4311 - val_loss: 59.9581\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2737 - val_loss: 59.4344\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6090 - val_loss: 60.1237\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3130 - val_loss: 58.6664\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5140 - val_loss: 58.9451\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4291 - val_loss: 58.7872\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3343 - val_loss: 59.7628\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2758 - val_loss: 58.2295\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2238 - val_loss: 59.2520\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3936 - val_loss: 59.0009\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5602 - val_loss: 58.9081\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5972 - val_loss: 59.4242\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2989 - val_loss: 58.4931\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 98us/step - loss: 11.3459 - val_loss: 59.3142\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.3396 - val_loss: 59.2361\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3386 - val_loss: 58.3826\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2625 - val_loss: 58.7476\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4258 - val_loss: 59.0668\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3970 - val_loss: 59.0584\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3114 - val_loss: 58.9622\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2166 - val_loss: 58.4130\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1945 - val_loss: 59.3028\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3472 - val_loss: 60.3030\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.7132 - val_loss: 58.6465\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4433 - val_loss: 58.4337\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2753 - val_loss: 59.0223\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2620 - val_loss: 58.7890\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4169 - val_loss: 58.3662\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3644 - val_loss: 59.1051\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3182 - val_loss: 59.4197\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1896 - val_loss: 59.0962\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.3323 - val_loss: 58.8022\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2161 - val_loss: 59.1471\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2965 - val_loss: 58.7365\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.6099 - val_loss: 59.0853\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.8497 - val_loss: 59.3145\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2417 - val_loss: 58.1884\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3700 - val_loss: 59.4067\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2847 - val_loss: 58.6632\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4038 - val_loss: 59.7462\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5172 - val_loss: 59.1514\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3387 - val_loss: 59.0418\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3011 - val_loss: 59.0637\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.2824 - val_loss: 60.3131\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 12.0360 - val_loss: 58.9695\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.6794 - val_loss: 58.8584\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2917 - val_loss: 58.9158\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3802 - val_loss: 58.9369\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3509 - val_loss: 59.4211\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3570 - val_loss: 59.1816\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.4824 - val_loss: 58.6745\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5916 - val_loss: 59.5803\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3087 - val_loss: 58.7380\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4038 - val_loss: 59.2335\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2838 - val_loss: 58.8345\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3295 - val_loss: 58.9504\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5059 - val_loss: 59.3078\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3273 - val_loss: 58.8655\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 598us/step - loss: 11.4943 - val_loss: 58.7256\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.6808 - val_loss: 58.9620\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.4706 - val_loss: 59.0792\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3169 - val_loss: 58.4463\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.3978 - val_loss: 59.2057\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2591 - val_loss: 58.4820\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0758 - val_loss: 59.1302\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1968 - val_loss: 59.0005\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4449 - val_loss: 58.8376\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2229 - val_loss: 58.6567\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3123 - val_loss: 58.0696\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2814 - val_loss: 59.7454\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3960 - val_loss: 58.8117\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5585 - val_loss: 59.5486\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5386 - val_loss: 58.4001\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4175 - val_loss: 59.1544\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3015 - val_loss: 58.8053\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.6727 - val_loss: 58.3909\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3999 - val_loss: 59.3809\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3498 - val_loss: 59.2044\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5074 - val_loss: 59.2693\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5271 - val_loss: 59.0826\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3561 - val_loss: 58.8596\n",
      "\n",
      "Mean Squared Error for iteration13: 48.01769814403419\n",
      "\n",
      "Iteration:  14\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2391 - val_loss: 59.0565\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4377 - val_loss: 58.0015\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.2549 - val_loss: 58.9914\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2639 - val_loss: 59.5642\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3645 - val_loss: 58.3996\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4857 - val_loss: 59.2696\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3573 - val_loss: 59.9850\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2533 - val_loss: 58.5415\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5188 - val_loss: 59.0889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2236 - val_loss: 59.4223\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2540 - val_loss: 58.8893\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 79us/step - loss: 11.5275 - val_loss: 59.5711\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2859 - val_loss: 58.4464\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4667 - val_loss: 58.8872\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.3748 - val_loss: 60.1858\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4626 - val_loss: 57.9928\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2499 - val_loss: 59.4320\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.6384 - val_loss: 59.2863\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.7365 - val_loss: 57.9627\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4861 - val_loss: 59.2641\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4740 - val_loss: 58.7590\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1934 - val_loss: 59.0002\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2838 - val_loss: 58.6003\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2813 - val_loss: 59.6663\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2333 - val_loss: 59.0236\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2186 - val_loss: 59.0764\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1442 - val_loss: 58.9790\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1989 - val_loss: 58.6981\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3666 - val_loss: 58.3726\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4256 - val_loss: 58.8083\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3713 - val_loss: 59.9138\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.4502 - val_loss: 58.1984\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3337 - val_loss: 58.8167\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3791 - val_loss: 58.8516\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5012 - val_loss: 59.1645\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2987 - val_loss: 58.4126\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5196 - val_loss: 59.5290\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4545 - val_loss: 58.9510\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3145 - val_loss: 59.5547\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4797 - val_loss: 58.8821\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.2539 - val_loss: 58.4980\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2911 - val_loss: 59.2678\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3821 - val_loss: 59.0740\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4980 - val_loss: 58.3071\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4411 - val_loss: 59.7938\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.7694 - val_loss: 59.8764\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5791 - val_loss: 58.8374\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.6623 - val_loss: 58.6842\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3590 - val_loss: 58.9714\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4542 - val_loss: 58.7458\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2540 - val_loss: 59.0440\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1802 - val_loss: 58.5277\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2258 - val_loss: 58.9369\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2819 - val_loss: 58.5298\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2250 - val_loss: 59.1612\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3849 - val_loss: 59.2133\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3481 - val_loss: 58.7944\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.3153 - val_loss: 59.5853\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.2878 - val_loss: 58.4818\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.2394 - val_loss: 58.5073\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3368 - val_loss: 59.4834\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.7186 - val_loss: 59.1484\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3952 - val_loss: 59.8330\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 12.0209 - val_loss: 58.2763\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4417 - val_loss: 59.1560\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.6179 - val_loss: 59.0278\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2874 - val_loss: 58.8968\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5232 - val_loss: 59.1507\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.3155 - val_loss: 59.4230\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6690 - val_loss: 58.9585\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.6268 - val_loss: 59.6210\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4560 - val_loss: 58.7061\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3787 - val_loss: 58.0406\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3734 - val_loss: 59.5897\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6293 - val_loss: 58.7038\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3789 - val_loss: 59.1990\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3747 - val_loss: 58.7112\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.8156 - val_loss: 58.1762\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 161us/step - loss: 11.3893 - val_loss: 59.3885\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3909 - val_loss: 58.9765\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4245 - val_loss: 59.2361\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.2526 - val_loss: 59.1977\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.2674 - val_loss: 59.4468\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.9674 - val_loss: 58.5936\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.5152 - val_loss: 58.7753\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4697 - val_loss: 59.2008\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1249 - val_loss: 58.6045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2219 - val_loss: 58.9440\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2213 - val_loss: 58.5224\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3225 - val_loss: 59.0570\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.4528 - val_loss: 59.7036\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 495us/step - loss: 11.4355 - val_loss: 58.8376\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2218 - val_loss: 59.3201\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3185 - val_loss: 59.1794\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3074 - val_loss: 58.8369\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2867 - val_loss: 59.0739\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3308 - val_loss: 59.6383\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1793 - val_loss: 58.6625\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6077 - val_loss: 59.1831\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.3629 - val_loss: 59.0172\n",
      "\n",
      "Mean Squared Error for iteration14: 48.25282119995537\n",
      "\n",
      "Iteration:  15\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.5632 - val_loss: 59.1422\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.8877 - val_loss: 58.6366\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6584 - val_loss: 58.9688\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2087 - val_loss: 59.0030\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - ETA: 0s - loss: 10.42 - 0s 344us/step - loss: 11.2935 - val_loss: 59.4541\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 344us/step - loss: 11.7621 - val_loss: 59.6653\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 202us/step - loss: 11.5516 - val_loss: 59.1517\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.3142 - val_loss: 58.8350\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.5581 - val_loss: 58.5112\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.3320 - val_loss: 59.0523\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5915 - val_loss: 60.0134\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.7049 - val_loss: 58.7711\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.9990 - val_loss: 59.7565\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7562 - val_loss: 59.5354\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5858 - val_loss: 59.0541\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3915 - val_loss: 58.9170\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2336 - val_loss: 59.0515\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5442 - val_loss: 58.4900\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4642 - val_loss: 59.1241\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2411 - val_loss: 59.0572\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.2638 - val_loss: 59.1546\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3944 - val_loss: 58.8038\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.7487 - val_loss: 58.9562\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2695 - val_loss: 58.5862\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2851 - val_loss: 58.8490\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2466 - val_loss: 59.5431\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2312 - val_loss: 59.0700\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4413 - val_loss: 58.8620\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4963 - val_loss: 58.7758\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3703 - val_loss: 59.1395\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2483 - val_loss: 58.9624\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.7453 - val_loss: 60.0032\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5838 - val_loss: 58.5311\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2220 - val_loss: 58.4614\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.3517 - val_loss: 59.1613\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.7286 - val_loss: 59.3857\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2750 - val_loss: 59.0961\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4756 - val_loss: 58.5174\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2546 - val_loss: 59.1136\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3439 - val_loss: 58.7524\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3802 - val_loss: 59.5378\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3132 - val_loss: 58.7317\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3316 - val_loss: 59.3079\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4889 - val_loss: 58.7505\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2413 - val_loss: 58.9059\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4179 - val_loss: 59.0448\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3901 - val_loss: 59.3463\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2607 - val_loss: 58.4277\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3404 - val_loss: 59.0016\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4534 - val_loss: 59.4193\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7115 - val_loss: 59.0517\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.9954 - val_loss: 59.6001\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4516 - val_loss: 58.3799\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2437 - val_loss: 58.6306\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2670 - val_loss: 58.9450\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1404 - val_loss: 59.0890\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2409 - val_loss: 59.3841\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5320 - val_loss: 58.8194\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5998 - val_loss: 59.6802\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4662 - val_loss: 58.7179\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2771 - val_loss: 58.8707\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2190 - val_loss: 59.1225\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4281 - val_loss: 58.8804\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 85us/step - loss: 11.4303 - val_loss: 58.9691\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2798 - val_loss: 58.8071\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 11.4877 - val_loss: 59.2471\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.6484 - val_loss: 58.2083\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.4067 - val_loss: 59.1093\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.2952 - val_loss: 58.7423\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5316 - val_loss: 58.7245\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4075 - val_loss: 58.4628\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2465 - val_loss: 58.8249\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3998 - val_loss: 59.4015\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4926 - val_loss: 59.2189\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2785 - val_loss: 59.0693\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2832 - val_loss: 58.6922\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2031 - val_loss: 58.5295\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2727 - val_loss: 59.2204\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.2918 - val_loss: 59.5689\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1992 - val_loss: 58.4982\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2391 - val_loss: 59.4769\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1717 - val_loss: 59.1252\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1145 - val_loss: 58.6836\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1821 - val_loss: 58.8895\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2455 - val_loss: 58.9315\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 174us/step - loss: 11.3841 - val_loss: 59.8340\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.6907 - val_loss: 59.7207\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.6407 - val_loss: 58.8999\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.3165 - val_loss: 58.1903\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 138us/step - loss: 11.4423 - val_loss: 59.7824\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.7008 - val_loss: 59.3367\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.3605 - val_loss: 59.0138\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2122 - val_loss: 59.1234\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4721 - val_loss: 58.5796\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 169us/step - loss: 11.8677 - val_loss: 59.0876\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4530 - val_loss: 58.6951\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4502 - val_loss: 59.3097\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4376 - val_loss: 58.3607\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5933 - val_loss: 58.9248\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.8147 - val_loss: 59.0543\n",
      "\n",
      "Mean Squared Error for iteration15: 47.80679584549945\n",
      "\n",
      "Iteration:  16\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.2838 - val_loss: 58.4590\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.3365 - val_loss: 59.3114\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 160us/step - loss: 11.5551 - val_loss: 58.8999\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2507 - val_loss: 59.0041\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5493 - val_loss: 59.2236\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1710 - val_loss: 58.5387\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1626 - val_loss: 58.6312\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3621 - val_loss: 58.8629\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5150 - val_loss: 58.1473\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2754 - val_loss: 59.1635\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3714 - val_loss: 59.0746\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.3901 - val_loss: 59.0138\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4273 - val_loss: 59.0654\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4783 - val_loss: 59.4387\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6020 - val_loss: 58.6162\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1947 - val_loss: 59.4112\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.8444 - val_loss: 59.6324\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.7539 - val_loss: 59.7721\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.6381 - val_loss: 59.3196\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.7046 - val_loss: 60.4502\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 188us/step - loss: 11.8580 - val_loss: 58.9790\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 143us/step - loss: 11.4081 - val_loss: 59.5347\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5559 - val_loss: 59.6491\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 12.2927 - val_loss: 59.1814\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.7261 - val_loss: 58.7511\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4481 - val_loss: 58.8844\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.6872 - val_loss: 59.4516\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.7090 - val_loss: 58.9272\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3347 - val_loss: 59.1494\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.3309 - val_loss: 58.8398\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.3328 - val_loss: 58.9031\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.3512 - val_loss: 59.2958\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.2221 - val_loss: 58.8548\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.4247 - val_loss: 59.6287\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2191 - val_loss: 58.4676\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.1749 - val_loss: 59.3176\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.2599 - val_loss: 59.0266\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.5003 - val_loss: 59.9842\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.8034 - val_loss: 59.6252\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.8566 - val_loss: 59.1463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3884 - val_loss: 58.9323\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5319 - val_loss: 58.9855\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4455 - val_loss: 58.9139\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5955 - val_loss: 58.9515\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4559 - val_loss: 58.6979\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2901 - val_loss: 58.8994\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2513 - val_loss: 58.7836\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2681 - val_loss: 59.0149\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3892 - val_loss: 59.0186\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.3738 - val_loss: 59.1800\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 203us/step - loss: 11.3201 - val_loss: 58.3959\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4531 - val_loss: 58.8137\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2868 - val_loss: 58.5005\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2754 - val_loss: 59.9769\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.6802 - val_loss: 59.8844\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.7109 - val_loss: 59.1230\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 12.0295 - val_loss: 59.6890\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 166us/step - loss: 11.4273 - val_loss: 59.0218\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.2980 - val_loss: 58.5207\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4020 - val_loss: 59.8349\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.6136 - val_loss: 60.3824\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.7283 - val_loss: 58.0867\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3579 - val_loss: 58.9939\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3666 - val_loss: 59.3520\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2362 - val_loss: 59.2987\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.3045 - val_loss: 58.4975\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.3916 - val_loss: 58.6258\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1876 - val_loss: 58.9369\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2653 - val_loss: 59.5629\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.6390 - val_loss: 59.2636\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4615 - val_loss: 59.5315\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.6063 - val_loss: 58.6490\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.3422 - val_loss: 58.6711\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4799 - val_loss: 59.2504\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3579 - val_loss: 59.7301\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4976 - val_loss: 58.8605\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1609 - val_loss: 58.7310\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.3507 - val_loss: 59.6099\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.4890 - val_loss: 59.0199\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.4756 - val_loss: 59.0784\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2723 - val_loss: 58.9806\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3283 - val_loss: 58.7758\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2675 - val_loss: 59.1728\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.6113 - val_loss: 59.0927\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2647 - val_loss: 58.5642\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6747 - val_loss: 59.6461\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 329us/step - loss: 11.4444 - val_loss: 58.4942\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 201us/step - loss: 11.4299 - val_loss: 58.9552\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3663 - val_loss: 58.3466\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1737 - val_loss: 59.4569\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3102 - val_loss: 58.6203\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.2225 - val_loss: 59.1313\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.4362 - val_loss: 59.2375\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 12.1080 - val_loss: 58.4416\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4406 - val_loss: 59.7329\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.9406 - val_loss: 59.6591\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.3781 - val_loss: 58.2747\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2466 - val_loss: 59.2470\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4756 - val_loss: 59.9455\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5190 - val_loss: 58.7169\n",
      "\n",
      "Mean Squared Error for iteration16: 47.94405046720227\n",
      "\n",
      "Iteration:  17\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3671 - val_loss: 58.6089\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 182us/step - loss: 11.3486 - val_loss: 58.7467\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.2835 - val_loss: 58.6799\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2167 - val_loss: 58.4682\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1500 - val_loss: 59.0561\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1432 - val_loss: 58.0690\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3242 - val_loss: 59.1169\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3532 - val_loss: 58.8282\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2254 - val_loss: 58.9658\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3099 - val_loss: 58.9199\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3012 - val_loss: 59.0186\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3365 - val_loss: 59.0025\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5590 - val_loss: 59.2569\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.8423 - val_loss: 60.4569\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4732 - val_loss: 58.7260\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1944 - val_loss: 58.5686\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3923 - val_loss: 59.6681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2870 - val_loss: 58.9414\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3301 - val_loss: 59.3738\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3660 - val_loss: 58.7492\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.3886 - val_loss: 58.4997\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 623us/step - loss: 11.2514 - val_loss: 58.8035\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.3317 - val_loss: 59.0279\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.7249 - val_loss: 59.6890\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.6430 - val_loss: 58.0179\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.2765 - val_loss: 59.0022\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3874 - val_loss: 58.9809\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3658 - val_loss: 58.6310\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3337 - val_loss: 59.2178\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5702 - val_loss: 59.4609\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4334 - val_loss: 58.7227\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.4462 - val_loss: 59.0325\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.2860 - val_loss: 58.9253\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 159us/step - loss: 11.3359 - val_loss: 59.2390\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 204us/step - loss: 11.3926 - val_loss: 58.9228\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 198us/step - loss: 11.3541 - val_loss: 58.9164\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 194us/step - loss: 11.6431 - val_loss: 60.0482\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2598 - val_loss: 59.7265\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.4007 - val_loss: 58.2453\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.3669 - val_loss: 59.7055\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 198us/step - loss: 11.3778 - val_loss: 58.6280\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 235us/step - loss: 11.3691 - val_loss: 58.2762\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.3183 - val_loss: 58.4365\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 172us/step - loss: 11.4095 - val_loss: 59.5089\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 203us/step - loss: 11.2063 - val_loss: 59.1728\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 188us/step - loss: 11.2154 - val_loss: 58.1901\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 190us/step - loss: 11.1214 - val_loss: 59.5213\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 239us/step - loss: 11.4670 - val_loss: 58.8454\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 200us/step - loss: 11.1782 - val_loss: 60.0987\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 207us/step - loss: 11.4156 - val_loss: 58.7193\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.2647 - val_loss: 59.5086\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 153us/step - loss: 11.3238 - val_loss: 58.9352\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 150us/step - loss: 11.2245 - val_loss: 59.3009\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.3013 - val_loss: 57.9633\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.1986 - val_loss: 59.4160\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.3051 - val_loss: 58.3968\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 195us/step - loss: 11.4251 - val_loss: 59.1090\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 238us/step - loss: 11.2741 - val_loss: 58.9848\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 238us/step - loss: 11.2664 - val_loss: 59.1770\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 362us/step - loss: 11.3408 - val_loss: 58.9962\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 319us/step - loss: 11.2709 - val_loss: 59.1947\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.3795 - val_loss: 59.2152\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 157us/step - loss: 11.4024 - val_loss: 58.2989\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.4000 - val_loss: 59.5665\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.6135 - val_loss: 58.1795\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2284 - val_loss: 58.8938\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2671 - val_loss: 59.0333\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 311us/step - loss: 11.2336 - val_loss: 59.1268\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 427us/step - loss: 11.2627 - val_loss: 59.0814\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3677 - val_loss: 59.8677\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.3854 - val_loss: 58.9597\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.3027 - val_loss: 58.9069\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.5958 - val_loss: 59.9911\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.5581 - val_loss: 59.1778\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2069 - val_loss: 58.4943\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.2575 - val_loss: 58.9274\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 228us/step - loss: 11.1495 - val_loss: 59.0581\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 147us/step - loss: 11.2446 - val_loss: 59.1926\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 309us/step - loss: 11.1984 - val_loss: 59.4452\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 469us/step - loss: 11.1868 - val_loss: 58.8111\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5575 - val_loss: 58.8095\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.5961 - val_loss: 58.7578\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2570 - val_loss: 58.9743\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1590 - val_loss: 58.8953\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.2550 - val_loss: 59.2896\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.4118 - val_loss: 59.3404\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2880 - val_loss: 58.0067\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2502 - val_loss: 59.4885\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.3247 - val_loss: 58.4808\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.2147 - val_loss: 58.7356\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4956 - val_loss: 59.5698\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.6129 - val_loss: 59.3353\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2855 - val_loss: 59.5730\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.3799 - val_loss: 58.9175\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 94us/step - loss: 11.4377 - val_loss: 58.9513\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.2871 - val_loss: 58.8975\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2559 - val_loss: 59.5309\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3766 - val_loss: 59.2315\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3712 - val_loss: 59.0009\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2920 - val_loss: 59.0618\n",
      "\n",
      "Mean Squared Error for iteration17: 48.17964872352723\n",
      "\n",
      "Iteration:  18\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3626 - val_loss: 59.1408\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3239 - val_loss: 59.4831\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4907 - val_loss: 59.2991\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1626 - val_loss: 58.9984\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5796 - val_loss: 58.6592\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3289 - val_loss: 59.4042\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4998 - val_loss: 59.4842\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2541 - val_loss: 58.9186\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2190 - val_loss: 59.1310\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3772 - val_loss: 59.5070\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3715 - val_loss: 59.1415\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3348 - val_loss: 58.4931\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1852 - val_loss: 59.1311\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.6405 - val_loss: 59.2966\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5474 - val_loss: 58.6874\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5628 - val_loss: 59.0268\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3498 - val_loss: 58.3629\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3274 - val_loss: 59.3983\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2145 - val_loss: 59.6277\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 12.3359 - val_loss: 61.8537\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.9884 - val_loss: 59.2542\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.4214 - val_loss: 58.7886\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3072 - val_loss: 59.5535\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6454 - val_loss: 58.5543\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1418 - val_loss: 58.8869\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3114 - val_loss: 58.8376\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2839 - val_loss: 58.5501\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3574 - val_loss: 59.0675\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4060 - val_loss: 59.3674\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4474 - val_loss: 59.1595\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5771 - val_loss: 59.5230\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3743 - val_loss: 59.2592\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1469 - val_loss: 58.1573\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2544 - val_loss: 58.7292\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3122 - val_loss: 59.1989\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2102 - val_loss: 58.8116\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2543 - val_loss: 59.4904\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2799 - val_loss: 59.0859\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2337 - val_loss: 58.1548\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 182us/step - loss: 11.3591 - val_loss: 59.3962\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1500 - val_loss: 59.0555\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4057 - val_loss: 58.1603\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1743 - val_loss: 58.9667\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.2482 - val_loss: 59.7730\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4983 - val_loss: 58.5219\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.5899 - val_loss: 59.0646\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4125 - val_loss: 59.0352\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.2884 - val_loss: 59.0007\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.4831 - val_loss: 59.7964\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.6075 - val_loss: 59.2767\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.6587 - val_loss: 59.0171\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3082 - val_loss: 59.1808\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3019 - val_loss: 59.2024\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3599 - val_loss: 58.9748\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.7370 - val_loss: 58.5133\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.4066 - val_loss: 59.3076\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3734 - val_loss: 59.0169\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3126 - val_loss: 59.3488\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3298 - val_loss: 59.0609\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2020 - val_loss: 58.8534\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1396 - val_loss: 59.4451\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1419 - val_loss: 58.8128\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2805 - val_loss: 58.7802\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1838 - val_loss: 59.0160\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1784 - val_loss: 58.8775\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1902 - val_loss: 59.5508\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5540 - val_loss: 59.1795\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3671 - val_loss: 58.5851\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1429 - val_loss: 59.0711\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1906 - val_loss: 58.7233\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2496 - val_loss: 59.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2975 - val_loss: 59.1573\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4418 - val_loss: 58.7403\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3896 - val_loss: 58.3886\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3224 - val_loss: 59.0536\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4589 - val_loss: 58.9764\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.0870 - val_loss: 59.2753\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3670 - val_loss: 58.1218\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1709 - val_loss: 59.9433\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5837 - val_loss: 58.8256\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2904 - val_loss: 59.2383\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2058 - val_loss: 58.3411\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2293 - val_loss: 59.3467\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2368 - val_loss: 58.6964\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5113 - val_loss: 58.8745\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0620 - val_loss: 59.2172\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4068 - val_loss: 59.1480\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3059 - val_loss: 58.7145\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5389 - val_loss: 59.0766\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4741 - val_loss: 59.2645\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1694 - val_loss: 58.4779\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1593 - val_loss: 59.0332\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2520 - val_loss: 58.8072\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.5337 - val_loss: 59.1666\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3990 - val_loss: 59.0358\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2390 - val_loss: 59.8403\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5469 - val_loss: 58.9167\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4258 - val_loss: 58.4377\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3017 - val_loss: 59.2050\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2807 - val_loss: 58.7314\n",
      "\n",
      "Mean Squared Error for iteration18: 47.69559321612682\n",
      "\n",
      "Iteration:  19\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3799 - val_loss: 61.3674\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4887 - val_loss: 58.3730\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3237 - val_loss: 57.9664\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3870 - val_loss: 60.3299\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4424 - val_loss: 58.7846\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2239 - val_loss: 58.4924\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4674 - val_loss: 59.0414\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5339 - val_loss: 58.7800\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4231 - val_loss: 58.4570\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4498 - val_loss: 59.0606\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4612 - val_loss: 58.6527\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.9147 - val_loss: 58.9220\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.8410 - val_loss: 59.2053\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.6587 - val_loss: 58.8370\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2763 - val_loss: 59.0873\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4557 - val_loss: 58.5840\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1957 - val_loss: 58.4424\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4056 - val_loss: 58.6417\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3080 - val_loss: 59.2162\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5005 - val_loss: 59.2945\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1194 - val_loss: 58.8272\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3542 - val_loss: 59.2686\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3115 - val_loss: 58.2203\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4774 - val_loss: 58.7670\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.7030 - val_loss: 58.6619\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5692 - val_loss: 59.1923\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6984 - val_loss: 58.4443\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.8139 - val_loss: 59.6384\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.8446 - val_loss: 58.7478\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4164 - val_loss: 59.1855\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.4552 - val_loss: 58.6805\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3410 - val_loss: 58.8879\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1124 - val_loss: 58.5602\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0803 - val_loss: 58.8452\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3395 - val_loss: 58.7687\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2249 - val_loss: 58.9287\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3095 - val_loss: 59.0196\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4124 - val_loss: 58.9571\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2268 - val_loss: 58.6162\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1971 - val_loss: 58.5020\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4289 - val_loss: 59.9019\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.7369 - val_loss: 59.4241\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.9171 - val_loss: 58.8139\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5609 - val_loss: 59.2322\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5027 - val_loss: 58.6418\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2398 - val_loss: 58.5682\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6036 - val_loss: 58.7684\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2404 - val_loss: 58.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0965 - val_loss: 59.1697\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3016 - val_loss: 58.3556\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3145 - val_loss: 58.7836\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5646 - val_loss: 59.0989\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.9568 - val_loss: 58.6742\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5494 - val_loss: 58.2621\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1866 - val_loss: 58.3194\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2923 - val_loss: 59.3777\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3938 - val_loss: 58.8076\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3268 - val_loss: 58.0688\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5060 - val_loss: 59.4640\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0692 - val_loss: 58.7804\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1807 - val_loss: 58.7133\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5037 - val_loss: 59.5828\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3057 - val_loss: 58.4264\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1906 - val_loss: 58.4424\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4639 - val_loss: 58.5657\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4455 - val_loss: 59.3266\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2579 - val_loss: 59.0054\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4717 - val_loss: 59.0594\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.2560 - val_loss: 58.5826\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3627 - val_loss: 58.6606\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3420 - val_loss: 59.5442\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3403 - val_loss: 58.5997\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1713 - val_loss: 58.4578\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1424 - val_loss: 58.9685\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4470 - val_loss: 59.5699\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1904 - val_loss: 58.1167\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2023 - val_loss: 59.3851\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 229us/step - loss: 11.1451 - val_loss: 58.4313\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.6524 - val_loss: 59.3121\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.7480 - val_loss: 59.2748\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3884 - val_loss: 58.4050\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3134 - val_loss: 58.3942\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2514 - val_loss: 58.6360\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4840 - val_loss: 58.3784\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2158 - val_loss: 59.0130\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 220us/step - loss: 11.2620 - val_loss: 58.4421\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 161us/step - loss: 11.1459 - val_loss: 59.0547\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 166us/step - loss: 11.2496 - val_loss: 58.5809\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.4045 - val_loss: 58.9170\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.2811 - val_loss: 58.6948\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 156us/step - loss: 11.3956 - val_loss: 58.7197\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3339 - val_loss: 59.1225\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4099 - val_loss: 58.4488\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 157us/step - loss: 11.3701 - val_loss: 58.4960\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 170us/step - loss: 11.3819 - val_loss: 59.5011\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 183us/step - loss: 11.2401 - val_loss: 58.8512\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.1796 - val_loss: 58.7944\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1860 - val_loss: 58.9205\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2487 - val_loss: 58.5477\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 141us/step - loss: 11.3297 - val_loss: 58.8991\n",
      "\n",
      "Mean Squared Error for iteration19: 47.815239317895255\n",
      "\n",
      "Iteration:  20\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.3163 - val_loss: 58.6112\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4792 - val_loss: 59.2485\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.8503 - val_loss: 59.2299\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.4491 - val_loss: 59.8443\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 167us/step - loss: 11.1979 - val_loss: 58.2581\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 178us/step - loss: 11.3120 - val_loss: 58.9358\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 155us/step - loss: 11.4615 - val_loss: 59.4317\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.2285 - val_loss: 58.9150\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.3478 - val_loss: 58.6370\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3682 - val_loss: 59.2466\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5924 - val_loss: 59.1546\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3025 - val_loss: 58.9516\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 141us/step - loss: 11.2257 - val_loss: 58.5947\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4358 - val_loss: 60.2546\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3600 - val_loss: 58.5245\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2693 - val_loss: 58.4403\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2678 - val_loss: 59.0774\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2576 - val_loss: 58.7741\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1927 - val_loss: 58.4876\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.7213 - val_loss: 59.2580\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3231 - val_loss: 58.6530\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2019 - val_loss: 58.4420\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3234 - val_loss: 59.3615\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3441 - val_loss: 58.7751\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 86us/step - loss: 11.3308 - val_loss: 59.0515\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4963 - val_loss: 57.9198\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1905 - val_loss: 60.2073\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.5324 - val_loss: 58.4378\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4858 - val_loss: 59.1534\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2233 - val_loss: 58.6338\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3779 - val_loss: 58.7127\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7812 - val_loss: 59.6075\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3739 - val_loss: 58.6982\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3866 - val_loss: 58.8547\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.6134 - val_loss: 59.2914\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5674 - val_loss: 58.3635\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2043 - val_loss: 59.5157\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2302 - val_loss: 59.0953\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1045 - val_loss: 58.7548\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1346 - val_loss: 58.6571\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5467 - val_loss: 58.9544\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5051 - val_loss: 58.1215\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3487 - val_loss: 59.2578\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1768 - val_loss: 58.9708\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5217 - val_loss: 58.8242\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2403 - val_loss: 58.5374\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2740 - val_loss: 58.6094\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5871 - val_loss: 58.9947\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4055 - val_loss: 58.7905\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.7222 - val_loss: 59.1473\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0739 - val_loss: 58.0087\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3895 - val_loss: 59.0425\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2520 - val_loss: 58.7918\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3367 - val_loss: 58.4054\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5292 - val_loss: 59.0019\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5821 - val_loss: 58.3176\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3474 - val_loss: 59.2297\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3734 - val_loss: 58.5682\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4570 - val_loss: 58.8804\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1781 - val_loss: 58.5890\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2158 - val_loss: 59.3529\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3595 - val_loss: 58.7418\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2908 - val_loss: 59.0684\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1101 - val_loss: 58.6692\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1597 - val_loss: 59.2809\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.1551 - val_loss: 59.1197\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4748 - val_loss: 59.1437\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3260 - val_loss: 58.9869\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3327 - val_loss: 58.5236\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2927 - val_loss: 59.7365\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.7878 - val_loss: 58.4666\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6922 - val_loss: 59.1258\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2813 - val_loss: 59.1343\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5405 - val_loss: 58.9014\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5948 - val_loss: 58.4614\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2341 - val_loss: 59.2174\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2441 - val_loss: 58.4475\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1504 - val_loss: 59.0430\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1917 - val_loss: 59.3823\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 12.2504 - val_loss: 59.0270\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6438 - val_loss: 58.9804\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1197 - val_loss: 58.7275\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1860 - val_loss: 58.8124\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4474 - val_loss: 59.0728\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4013 - val_loss: 59.8714\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6705 - val_loss: 58.9639\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1981 - val_loss: 59.0315\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4955 - val_loss: 58.6745\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3785 - val_loss: 58.3885\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2385 - val_loss: 58.8327\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3671 - val_loss: 59.0108\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1260 - val_loss: 59.2768\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5752 - val_loss: 59.3467\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.7808 - val_loss: 58.9621\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2498 - val_loss: 59.0539\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3912 - val_loss: 59.2995\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5148 - val_loss: 58.9223\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.5499 - val_loss: 58.8328\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.7536 - val_loss: 58.4212\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4910 - val_loss: 59.1939\n",
      "\n",
      "Mean Squared Error for iteration20: 48.296189494080764\n",
      "\n",
      "Iteration:  21\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3157 - val_loss: 57.9445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5420 - val_loss: 58.7135\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2720 - val_loss: 58.5697\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.2849 - val_loss: 58.3703\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4124 - val_loss: 59.1780\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3037 - val_loss: 58.6304\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3076 - val_loss: 59.0107\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2892 - val_loss: 59.2184\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6848 - val_loss: 58.3136\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4892 - val_loss: 59.0139\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3615 - val_loss: 58.7829\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1796 - val_loss: 58.2687\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3682 - val_loss: 58.3836\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.8318 - val_loss: 60.0833\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 12.1321 - val_loss: 59.2428\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.9617 - val_loss: 59.3287\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.9296 - val_loss: 58.2383\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5861 - val_loss: 58.8742\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.2451 - val_loss: 58.3903\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 190us/step - loss: 11.1314 - val_loss: 58.5693\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3540 - val_loss: 58.5598\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.6016 - val_loss: 59.5876\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 143us/step - loss: 11.1941 - val_loss: 58.1637\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.3081 - val_loss: 59.8324\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.2007 - val_loss: 57.9940\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2904 - val_loss: 59.1041\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.5400 - val_loss: 59.3053\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.7637 - val_loss: 58.7054\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 488us/step - loss: 11.2506 - val_loss: 58.4221\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 274us/step - loss: 11.0718 - val_loss: 59.1339\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 388us/step - loss: 11.3393 - val_loss: 58.1676\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 205us/step - loss: 11.1977 - val_loss: 58.3492\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.2312 - val_loss: 58.6398\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0916 - val_loss: 59.1082\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.1965 - val_loss: 57.9533\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.3834 - val_loss: 59.0434\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 158us/step - loss: 11.6876 - val_loss: 58.7785\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.3576 - val_loss: 58.4339\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.1769 - val_loss: 59.1581\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2186 - val_loss: 58.6908\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.5785 - val_loss: 58.7427\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3099 - val_loss: 59.1462\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.2647 - val_loss: 59.1175\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3613 - val_loss: 59.0533\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2693 - val_loss: 58.6231\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1523 - val_loss: 58.9511\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3602 - val_loss: 58.1966\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3098 - val_loss: 58.9548\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1951 - val_loss: 58.5810\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1728 - val_loss: 59.2509\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3524 - val_loss: 58.0312\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4775 - val_loss: 59.3933\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.7588 - val_loss: 58.6215\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.6526 - val_loss: 59.3329\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4040 - val_loss: 58.0399\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.2563 - val_loss: 59.2205\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3072 - val_loss: 58.5150\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.2288 - val_loss: 58.8459\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 157us/step - loss: 11.2156 - val_loss: 59.0488\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.2993 - val_loss: 59.0292\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.2877 - val_loss: 59.0722\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3741 - val_loss: 58.6501\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2146 - val_loss: 58.4990\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4797 - val_loss: 59.4008\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.4678 - val_loss: 59.2286\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4764 - val_loss: 58.3477\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.5020 - val_loss: 58.6730\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2496 - val_loss: 58.7740\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6296 - val_loss: 58.5890\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4023 - val_loss: 58.6807\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1954 - val_loss: 59.0576\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1615 - val_loss: 59.0556\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2608 - val_loss: 58.3995\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.7716 - val_loss: 59.1023\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.0937 - val_loss: 58.8856\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5831 - val_loss: 58.6199\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3209 - val_loss: 58.9692\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3892 - val_loss: 59.0871\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1847 - val_loss: 58.8149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3528 - val_loss: 58.4568\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3298 - val_loss: 59.0304\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5649 - val_loss: 59.0169\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.1501 - val_loss: 58.3050\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2614 - val_loss: 58.9900\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5309 - val_loss: 59.4001\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1392 - val_loss: 58.5361\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3375 - val_loss: 58.7262\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.4135 - val_loss: 59.2539\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2284 - val_loss: 58.0384\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1778 - val_loss: 59.9180\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.4719 - val_loss: 58.0269\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1308 - val_loss: 59.4660\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2884 - val_loss: 58.4408\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1583 - val_loss: 58.6559\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2901 - val_loss: 58.6393\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2698 - val_loss: 59.0673\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.2573 - val_loss: 58.1062\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4384 - val_loss: 58.6560\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1544 - val_loss: 58.0199\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1000 - val_loss: 58.8639\n",
      "\n",
      "Mean Squared Error for iteration21: 47.52333813783329\n",
      "\n",
      "Iteration:  22\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3253 - val_loss: 59.6180\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3599 - val_loss: 58.4249\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3430 - val_loss: 58.9077\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.1163 - val_loss: 58.7149\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 80us/step - loss: 11.2924 - val_loss: 59.2984\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 12.1188 - val_loss: 58.8496\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3560 - val_loss: 59.7927\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3576 - val_loss: 58.5126\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3377 - val_loss: 60.1297\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4841 - val_loss: 58.3220\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3219 - val_loss: 59.0152\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1327 - val_loss: 58.4647\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3486 - val_loss: 58.7717\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3493 - val_loss: 58.8991\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7681 - val_loss: 58.6931\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.5911 - val_loss: 58.6102\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6181 - val_loss: 59.5148\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.7912 - val_loss: 59.0750\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.6961 - val_loss: 58.6888\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1697 - val_loss: 58.2239\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.1815 - val_loss: 58.7903\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7942 - val_loss: 58.5516\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2291 - val_loss: 58.0349\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4213 - val_loss: 58.9884\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7657 - val_loss: 58.9358\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3107 - val_loss: 58.5627\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1258 - val_loss: 59.1896\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3222 - val_loss: 58.3584\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2985 - val_loss: 60.2820\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0902 - val_loss: 58.5545\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3492 - val_loss: 57.9601\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0677 - val_loss: 59.0701\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0860 - val_loss: 58.7334\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.4557 - val_loss: 58.4604\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3404 - val_loss: 59.2397\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4406 - val_loss: 58.3880\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3140 - val_loss: 58.7644\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4024 - val_loss: 59.0281\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5578 - val_loss: 59.1964\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2330 - val_loss: 58.3729\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1905 - val_loss: 58.8066\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2906 - val_loss: 59.0197\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1518 - val_loss: 58.6989\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2087 - val_loss: 58.7013\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1773 - val_loss: 59.9151\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.9702 - val_loss: 58.6987\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5370 - val_loss: 59.4293\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4156 - val_loss: 59.1356\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2098 - val_loss: 59.7080\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2327 - val_loss: 58.2505\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2925 - val_loss: 59.0125\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.0937 - val_loss: 58.8940\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3285 - val_loss: 58.7025\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3391 - val_loss: 58.7058\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2123 - val_loss: 58.6792\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2413 - val_loss: 58.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4988 - val_loss: 59.1492\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6695 - val_loss: 59.2631\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3873 - val_loss: 59.4061\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2375 - val_loss: 58.8920\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2104 - val_loss: 58.7618\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2303 - val_loss: 59.4300\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2205 - val_loss: 58.0973\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.6024 - val_loss: 59.2345\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2312 - val_loss: 58.4497\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2389 - val_loss: 58.9168\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.4196 - val_loss: 58.2842\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2317 - val_loss: 58.9580\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2359 - val_loss: 58.3827\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2680 - val_loss: 58.6116\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3443 - val_loss: 58.6414\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.1721 - val_loss: 58.7014\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1013 - val_loss: 59.3706\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5212 - val_loss: 58.4303\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4021 - val_loss: 59.0980\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3226 - val_loss: 58.5363\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5531 - val_loss: 59.0978\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3048 - val_loss: 58.9296\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1426 - val_loss: 59.4007\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5119 - val_loss: 59.1160\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5464 - val_loss: 58.7392\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2941 - val_loss: 58.5975\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3725 - val_loss: 59.2589\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3456 - val_loss: 58.8408\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6456 - val_loss: 59.4528\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2891 - val_loss: 58.9273\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.3558 - val_loss: 58.7418\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2493 - val_loss: 58.5407\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2149 - val_loss: 58.6099\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.3521 - val_loss: 58.6602\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3144 - val_loss: 58.8586\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3799 - val_loss: 58.3897\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4269 - val_loss: 59.1483\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2979 - val_loss: 58.9549\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.9874 - val_loss: 59.5157\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.6745 - val_loss: 59.2982\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3036 - val_loss: 58.1362\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2612 - val_loss: 59.7387\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2806 - val_loss: 57.8820\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2226 - val_loss: 58.8368\n",
      "\n",
      "Mean Squared Error for iteration22: 49.05772947702725\n",
      "\n",
      "Iteration:  23\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2839 - val_loss: 58.8046\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2689 - val_loss: 59.2472\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0171 - val_loss: 58.0955\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.1208 - val_loss: 59.2602\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3503 - val_loss: 58.9192\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.1587 - val_loss: 58.5488\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1860 - val_loss: 58.7581\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1672 - val_loss: 58.8520\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.2080 - val_loss: 57.9709\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3817 - val_loss: 58.7911\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 12.0992 - val_loss: 59.0362\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3724 - val_loss: 58.9267\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2771 - val_loss: 58.7677\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.2718 - val_loss: 58.6170\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2751 - val_loss: 59.2176\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3501 - val_loss: 58.7671\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5177 - val_loss: 58.7451\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5213 - val_loss: 59.7367\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.6876 - val_loss: 58.4240\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1802 - val_loss: 59.3240\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3303 - val_loss: 57.9919\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.4020 - val_loss: 59.3430\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.6733 - val_loss: 59.2071\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3029 - val_loss: 59.2010\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4621 - val_loss: 58.0832\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1382 - val_loss: 58.5155\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.0702 - val_loss: 59.1397\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.2379 - val_loss: 58.4618\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3021 - val_loss: 59.0346\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2569 - val_loss: 58.4615\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.4290 - val_loss: 58.6594\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1216 - val_loss: 58.9952\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1554 - val_loss: 58.8617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3264 - val_loss: 58.6245\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3444 - val_loss: 59.0311\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5330 - val_loss: 58.8501\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2186 - val_loss: 58.7651\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.3444 - val_loss: 58.8795\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2411 - val_loss: 58.7395\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.4777 - val_loss: 58.2785\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2707 - val_loss: 58.4352\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.1398 - val_loss: 58.7934\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4595 - val_loss: 58.0283\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3186 - val_loss: 59.0006\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4125 - val_loss: 59.6345\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.5816 - val_loss: 59.1277\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2613 - val_loss: 58.6915\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1396 - val_loss: 59.0094\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0804 - val_loss: 58.8361\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1178 - val_loss: 59.0663\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3631 - val_loss: 58.7926\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5410 - val_loss: 58.8916\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.3719 - val_loss: 58.4746\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.8003 - val_loss: 58.9999\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 82us/step - loss: 11.1103 - val_loss: 58.7998\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0276 - val_loss: 58.7582\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6799 - val_loss: 59.0884\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2732 - val_loss: 58.5835\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3091 - val_loss: 58.6304\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2238 - val_loss: 59.3153\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2003 - val_loss: 59.1170\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5083 - val_loss: 58.9806\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2001 - val_loss: 58.7023\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0359 - val_loss: 58.8393\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.5679 - val_loss: 59.1667\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.7555 - val_loss: 58.6461\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 81us/step - loss: 12.1256 - val_loss: 58.6891\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4198 - val_loss: 60.0150\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5406 - val_loss: 58.2647\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.2361 - val_loss: 58.3037\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3180 - val_loss: 58.9492\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.1863 - val_loss: 58.2580\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4692 - val_loss: 58.5762\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2944 - val_loss: 58.2471\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2304 - val_loss: 58.3765\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4835 - val_loss: 58.5488\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.0940 - val_loss: 58.5290\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2071 - val_loss: 59.1101\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 169us/step - loss: 11.1803 - val_loss: 58.5168\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 174us/step - loss: 11.1797 - val_loss: 58.8571\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 294us/step - loss: 11.2731 - val_loss: 58.6355\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 168us/step - loss: 11.2485 - val_loss: 58.5539\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.4812 - val_loss: 58.5746\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.2840 - val_loss: 58.9811\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3846 - val_loss: 59.1916\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3392 - val_loss: 59.0594\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.6394 - val_loss: 59.1156\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.3524 - val_loss: 59.1089\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 201us/step - loss: 11.1853 - val_loss: 58.5451\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 285us/step - loss: 11.2679 - val_loss: 58.0903\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 188us/step - loss: 11.2955 - val_loss: 59.1287\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 207us/step - loss: 11.3770 - val_loss: 58.5246\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 190us/step - loss: 11.3341 - val_loss: 58.8631\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 196us/step - loss: 11.1748 - val_loss: 58.4949\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.1581 - val_loss: 59.0389\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 195us/step - loss: 11.1574 - val_loss: 58.1043\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 180us/step - loss: 11.4920 - val_loss: 60.4554\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 149us/step - loss: 11.2238 - val_loss: 58.2108\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.2480 - val_loss: 58.5639\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3471 - val_loss: 58.4513\n",
      "\n",
      "Mean Squared Error for iteration23: 47.95266899545017\n",
      "\n",
      "Iteration:  24\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5150 - val_loss: 58.8542\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 12.1207 - val_loss: 59.2805\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.7463 - val_loss: 59.3465\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.5467 - val_loss: 59.0723\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1919 - val_loss: 58.2361\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2536 - val_loss: 58.8589\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3302 - val_loss: 58.2348\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1300 - val_loss: 59.2461\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3311 - val_loss: 58.4602\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 88us/step - loss: 11.2044 - val_loss: 58.6425\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3432 - val_loss: 59.3576\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1355 - val_loss: 58.3549\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2155 - val_loss: 58.9543\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4249 - val_loss: 58.6109\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5660 - val_loss: 59.1272\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.2250 - val_loss: 58.9535\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 192us/step - loss: 11.6387 - val_loss: 59.0917\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 176us/step - loss: 11.4630 - val_loss: 57.7430\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 194us/step - loss: 11.3820 - val_loss: 59.1830\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.8761 - val_loss: 58.1257\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 156us/step - loss: 11.6243 - val_loss: 58.8985\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.4265 - val_loss: 59.1515\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3092 - val_loss: 58.6544\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1973 - val_loss: 58.5486\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2494 - val_loss: 58.8690\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2874 - val_loss: 59.0956\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4576 - val_loss: 57.9104\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3769 - val_loss: 59.2675\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5576 - val_loss: 58.2162\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3131 - val_loss: 58.3192\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3446 - val_loss: 58.2443\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2558 - val_loss: 58.3851\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3951 - val_loss: 58.6906\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3091 - val_loss: 58.0126\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.1638 - val_loss: 59.0748\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3179 - val_loss: 58.7478\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3954 - val_loss: 58.8895\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4493 - val_loss: 58.8105\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1904 - val_loss: 58.3425\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1696 - val_loss: 58.8839\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4288 - val_loss: 59.0474\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1790 - val_loss: 58.8936\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1105 - val_loss: 58.7949\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.2512 - val_loss: 59.1251\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.2016 - val_loss: 58.7290\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.3559 - val_loss: 59.3256\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.2204 - val_loss: 58.3037\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4280 - val_loss: 58.6996\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1709 - val_loss: 59.3401\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5874 - val_loss: 58.8930\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.4604 - val_loss: 58.9555\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.6641 - val_loss: 58.4097\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2637 - val_loss: 58.4127\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2352 - val_loss: 58.2804\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1634 - val_loss: 58.8978\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2356 - val_loss: 57.8971\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 308us/step - loss: 11.3231 - val_loss: 59.1883\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 167us/step - loss: 11.2605 - val_loss: 58.3665\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.2076 - val_loss: 58.1748\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2069 - val_loss: 58.9919\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2357 - val_loss: 58.9803\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2000 - val_loss: 58.8580\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4842 - val_loss: 58.8540\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2095 - val_loss: 58.7947\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3815 - val_loss: 59.0192\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.3690 - val_loss: 59.7393\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.7471 - val_loss: 58.1219\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3434 - val_loss: 57.7834\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3881 - val_loss: 59.6352\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4352 - val_loss: 58.3236\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4258 - val_loss: 60.0920\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6548 - val_loss: 57.7595\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.1747 - val_loss: 58.6242\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2738 - val_loss: 58.4851\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3555 - val_loss: 58.9457\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2586 - val_loss: 59.4812\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4452 - val_loss: 58.6536\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1445 - val_loss: 58.7869\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1124 - val_loss: 59.5315\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4128 - val_loss: 58.7162\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1424 - val_loss: 58.6793\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1239 - val_loss: 58.5281\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4161 - val_loss: 58.4613\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4850 - val_loss: 58.1206\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1048 - val_loss: 59.2235\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7701 - val_loss: 59.8814\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.6934 - val_loss: 58.8831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6039 - val_loss: 58.3853\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4019 - val_loss: 58.4864\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0824 - val_loss: 58.8143\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1809 - val_loss: 58.8066\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5041 - val_loss: 59.5341\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4908 - val_loss: 58.6700\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2233 - val_loss: 58.1167\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1519 - val_loss: 58.9676\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3861 - val_loss: 58.4402\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3285 - val_loss: 59.5494\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2818 - val_loss: 57.9744\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1993 - val_loss: 58.4735\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2693 - val_loss: 59.1942\n",
      "\n",
      "Mean Squared Error for iteration24: 48.914187341717934\n",
      "\n",
      "Iteration:  25\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3750 - val_loss: 57.7486\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4075 - val_loss: 59.9210\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2084 - val_loss: 58.6096\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2672 - val_loss: 58.5589\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2108 - val_loss: 58.7068\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5396 - val_loss: 59.0994\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.6651 - val_loss: 58.9091\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3465 - val_loss: 58.1118\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0921 - val_loss: 59.0839\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4664 - val_loss: 58.1698\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1126 - val_loss: 58.2060\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1081 - val_loss: 59.1196\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1943 - val_loss: 58.2469\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1110 - val_loss: 59.1387\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.5005 - val_loss: 58.1322\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3630 - val_loss: 59.0620\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3635 - val_loss: 58.5906\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.6043 - val_loss: 59.4428\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3280 - val_loss: 58.5703\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3256 - val_loss: 59.0928\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1342 - val_loss: 58.1375\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3820 - val_loss: 59.6480\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4763 - val_loss: 58.4155\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1773 - val_loss: 58.4950\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1250 - val_loss: 59.2466\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2496 - val_loss: 58.0256\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2951 - val_loss: 59.1675\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2455 - val_loss: 58.5635\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2802 - val_loss: 58.6411\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3588 - val_loss: 58.7215\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6619 - val_loss: 58.2318\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3495 - val_loss: 58.8911\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1710 - val_loss: 58.4362\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3594 - val_loss: 58.8097\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0682 - val_loss: 58.2977\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3141 - val_loss: 58.9768\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1957 - val_loss: 58.4279\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0367 - val_loss: 58.5802\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1456 - val_loss: 59.0926\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3361 - val_loss: 58.6863\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1507 - val_loss: 58.2756\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.1492 - val_loss: 58.7983\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1755 - val_loss: 58.1554\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2163 - val_loss: 58.4408\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2489 - val_loss: 59.0174\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3218 - val_loss: 58.7869\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2669 - val_loss: 59.1041\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2984 - val_loss: 58.0136\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2345 - val_loss: 58.9351\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0955 - val_loss: 58.5591\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2568 - val_loss: 59.2080\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5993 - val_loss: 59.1464\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.4977 - val_loss: 58.7127\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3494 - val_loss: 58.7634\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.1975 - val_loss: 58.4451\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 155us/step - loss: 11.2162 - val_loss: 58.4743\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.2818 - val_loss: 58.1946\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.3452 - val_loss: 59.4092\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3074 - val_loss: 58.4833\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2127 - val_loss: 58.8388\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6829 - val_loss: 58.7672\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3181 - val_loss: 58.6128\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 141us/step - loss: 11.4862 - val_loss: 58.7834\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 288us/step - loss: 11.4603 - val_loss: 58.5816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.1673 - val_loss: 58.5621\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2004 - val_loss: 58.4381\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2943 - val_loss: 59.0497\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2938 - val_loss: 59.1964\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0855 - val_loss: 59.1314\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4822 - val_loss: 58.9002\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 202us/step - loss: 11.2686 - val_loss: 59.0652\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 171us/step - loss: 11.2677 - val_loss: 59.3928\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.3287 - val_loss: 58.0678\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.4002 - val_loss: 58.5073\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2268 - val_loss: 58.7674\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1192 - val_loss: 58.9270\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5471 - val_loss: 58.6267\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.3649 - val_loss: 59.0310\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.3665 - val_loss: 58.0358\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3521 - val_loss: 58.6259\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2316 - val_loss: 58.8309\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2372 - val_loss: 57.9237\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3043 - val_loss: 59.1260\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3856 - val_loss: 58.2713\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1736 - val_loss: 59.5468\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2892 - val_loss: 58.4929\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0983 - val_loss: 58.1575\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1376 - val_loss: 58.5235\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4408 - val_loss: 58.5338\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2914 - val_loss: 60.0537\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2265 - val_loss: 58.0193\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1592 - val_loss: 58.8234\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2117 - val_loss: 59.1673\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1603 - val_loss: 58.6297\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4991 - val_loss: 58.8372\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5302 - val_loss: 58.0114\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2479 - val_loss: 58.5050\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2807 - val_loss: 59.1592\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2617 - val_loss: 58.5442\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1157 - val_loss: 58.9757\n",
      "\n",
      "Mean Squared Error for iteration25: 48.02473085816865\n",
      "\n",
      "Iteration:  26\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.6130 - val_loss: 59.1246\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3902 - val_loss: 57.6979\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0448 - val_loss: 59.6680\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5265 - val_loss: 58.8361\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 164us/step - loss: 11.3771 - val_loss: 58.4123\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1662 - val_loss: 58.3144\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2193 - val_loss: 59.2453\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.8071 - val_loss: 58.3950\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6306 - val_loss: 58.1592\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.8654 - val_loss: 58.4576\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.7403 - val_loss: 58.5271\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2022 - val_loss: 58.8719\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2553 - val_loss: 58.5921\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2699 - val_loss: 58.6635\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3088 - val_loss: 58.3516\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 168us/step - loss: 11.1732 - val_loss: 58.6386\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3236 - val_loss: 59.0128\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.4301 - val_loss: 58.9621\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.3840 - val_loss: 59.0812\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.1927 - val_loss: 58.4296\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.3360 - val_loss: 58.6350\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1879 - val_loss: 58.8954\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4382 - val_loss: 58.5981\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2024 - val_loss: 58.5645\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3296 - val_loss: 57.8849\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.1255 - val_loss: 58.6720\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1564 - val_loss: 58.7335\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4221 - val_loss: 59.1093\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1148 - val_loss: 58.2194\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.1344 - val_loss: 58.5179\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1318 - val_loss: 58.5661\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4463 - val_loss: 59.6465\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2256 - val_loss: 57.8298\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3122 - val_loss: 58.4534\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1089 - val_loss: 58.7739\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2360 - val_loss: 58.8248\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3139 - val_loss: 58.3756\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1180 - val_loss: 58.4947\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4131 - val_loss: 59.5327\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2573 - val_loss: 58.2293\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2898 - val_loss: 59.0669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4205 - val_loss: 59.0333\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4462 - val_loss: 58.6501\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4699 - val_loss: 58.6438\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2416 - val_loss: 58.6488\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4396 - val_loss: 57.7548\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 272us/step - loss: 11.4881 - val_loss: 59.2091\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.1064 - val_loss: 58.5303\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.5257 - val_loss: 58.6358\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.8864 - val_loss: 58.3281\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3063 - val_loss: 58.3589\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1916 - val_loss: 58.7550\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.5595 - val_loss: 58.3839\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5367 - val_loss: 58.3468\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1624 - val_loss: 58.7951\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2983 - val_loss: 58.8625\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1569 - val_loss: 58.0092\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2407 - val_loss: 59.3219\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2762 - val_loss: 58.4883\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 144us/step - loss: 11.1275 - val_loss: 58.8926\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 259us/step - loss: 11.0838 - val_loss: 58.1357\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 185us/step - loss: 11.1068 - val_loss: 58.3516\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.3779 - val_loss: 58.4649\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3957 - val_loss: 58.3958\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1016 - val_loss: 58.8288\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4031 - val_loss: 59.1038\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2859 - val_loss: 57.7070\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2526 - val_loss: 58.8747\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2884 - val_loss: 59.3963\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2157 - val_loss: 58.5588\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 462us/step - loss: 11.2736 - val_loss: 59.3945\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 165us/step - loss: 11.0381 - val_loss: 58.9461\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 221us/step - loss: 11.2653 - val_loss: 58.7481\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 168us/step - loss: 11.6036 - val_loss: 59.4116\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.3302 - val_loss: 58.0923\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 167us/step - loss: 11.4783 - val_loss: 58.8802\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.1794 - val_loss: 58.4404\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.3028 - val_loss: 58.6506\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.3943 - val_loss: 58.3613\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 207us/step - loss: 11.5439 - val_loss: 60.4145\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 167us/step - loss: 11.5311 - val_loss: 58.5544\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 289us/step - loss: 11.1908 - val_loss: 58.8134\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 205us/step - loss: 11.5154 - val_loss: 58.3846\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 179us/step - loss: 11.2656 - val_loss: 58.3328\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 275us/step - loss: 11.4009 - val_loss: 59.2158\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 184us/step - loss: 11.0588 - val_loss: 58.3713\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 178us/step - loss: 11.0653 - val_loss: 58.5064\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 272us/step - loss: 11.2470 - val_loss: 59.0555\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 177us/step - loss: 11.3269 - val_loss: 58.6203\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 200us/step - loss: 11.4746 - val_loss: 58.2920\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 340us/step - loss: 11.1933 - val_loss: 58.4092\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 208us/step - loss: 11.1104 - val_loss: 58.1807\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 186us/step - loss: 11.2466 - val_loss: 58.6716\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 208us/step - loss: 11.0712 - val_loss: 58.0564\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 172us/step - loss: 11.5840 - val_loss: 58.7469\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 295us/step - loss: 11.2856 - val_loss: 58.2576\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.5469 - val_loss: 59.1156\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 219us/step - loss: 11.3381 - val_loss: 60.2296\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 208us/step - loss: 12.0433 - val_loss: 59.3025\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 284us/step - loss: 11.2384 - val_loss: 58.3091\n",
      "\n",
      "Mean Squared Error for iteration26: 48.098022784081635\n",
      "\n",
      "Iteration:  27\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 360us/step - loss: 11.1489 - val_loss: 58.2645\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 230us/step - loss: 11.2138 - val_loss: 58.5480\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 162us/step - loss: 11.2689 - val_loss: 59.0140\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.4315 - val_loss: 58.7791\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.3024 - val_loss: 58.8007\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.8595 - val_loss: 59.7122\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.4537 - val_loss: 58.5541\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.2606 - val_loss: 59.5487\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.6517 - val_loss: 58.5884\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.2761 - val_loss: 58.6743\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.6621 - val_loss: 58.3839\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.3164 - val_loss: 59.0271\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.2735 - val_loss: 58.5383\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 190us/step - loss: 11.1297 - val_loss: 58.2745\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 383us/step - loss: 11.1480 - val_loss: 59.3242\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 165us/step - loss: 11.1215 - val_loss: 59.4186\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 183us/step - loss: 11.2474 - val_loss: 57.9503\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 182us/step - loss: 11.2575 - val_loss: 58.3516\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 194us/step - loss: 11.2881 - val_loss: 59.2907\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.5569 - val_loss: 58.1878\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.5576 - val_loss: 59.0458\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 146us/step - loss: 11.2657 - val_loss: 58.9350\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.1978 - val_loss: 58.7736\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.3179 - val_loss: 58.4735\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.2644 - val_loss: 58.2801\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3455 - val_loss: 59.2666\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2769 - val_loss: 58.3357\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.4323 - val_loss: 59.4522\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1820 - val_loss: 58.8884\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1337 - val_loss: 58.8785\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.4919 - val_loss: 58.3105\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1981 - val_loss: 58.6598\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.1749 - val_loss: 58.5897\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.1425 - val_loss: 58.4510\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2311 - val_loss: 58.6259\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1914 - val_loss: 57.9563\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3352 - val_loss: 58.9231\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4470 - val_loss: 58.3751\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.9282 - val_loss: 58.6450\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 12.4628 - val_loss: 59.4216\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 191us/step - loss: 12.5653 - val_loss: 59.0805\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 194us/step - loss: 11.5536 - val_loss: 59.5784\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 245us/step - loss: 11.7842 - val_loss: 59.3803\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.7058 - val_loss: 58.3281\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4361 - val_loss: 58.9025\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3022 - val_loss: 58.4522\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1720 - val_loss: 58.3460\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3065 - val_loss: 59.0572\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4252 - val_loss: 58.5890\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.0755 - val_loss: 58.5192\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 190us/step - loss: 11.3608 - val_loss: 59.1533\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 252us/step - loss: 11.2973 - val_loss: 58.3638\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.2131 - val_loss: 58.7135\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.9194 - val_loss: 58.1937\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.4568 - val_loss: 59.5729\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3660 - val_loss: 58.1949\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.3627 - val_loss: 58.8477\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2977 - val_loss: 59.0801\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0748 - val_loss: 58.0389\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0696 - val_loss: 59.2242\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1952 - val_loss: 59.3935\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.1616 - val_loss: 58.4761\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 225us/step - loss: 11.1876 - val_loss: 58.7214\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 289us/step - loss: 11.2110 - val_loss: 58.8877\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.4287 - val_loss: 59.3020\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1973 - val_loss: 58.2057\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2349 - val_loss: 58.5580\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3533 - val_loss: 58.3358\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1210 - val_loss: 58.4471\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4839 - val_loss: 58.7697\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.7099 - val_loss: 58.0750\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2639 - val_loss: 59.6118\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3963 - val_loss: 57.3500\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.1572 - val_loss: 58.5656\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 267us/step - loss: 11.4624 - val_loss: 58.7680\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2960 - val_loss: 58.7258\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3509 - val_loss: 58.6024\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2992 - val_loss: 58.2811\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0608 - val_loss: 58.4487\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0558 - val_loss: 58.8898\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.2428 - val_loss: 58.7852\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 199us/step - loss: 11.3997 - val_loss: 58.5838\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 209us/step - loss: 11.1592 - val_loss: 58.4623\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1355 - val_loss: 58.1609\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.4098 - val_loss: 59.2225\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4783 - val_loss: 59.6733\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3301 - val_loss: 58.4240\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1400 - val_loss: 58.3839\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3653 - val_loss: 59.0801\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1355 - val_loss: 58.2536\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0331 - val_loss: 58.5857\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5571 - val_loss: 59.1448\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1428 - val_loss: 58.1604\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4216 - val_loss: 58.0564\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0732 - val_loss: 58.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1243 - val_loss: 58.4158\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3706 - val_loss: 58.2250\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.6259 - val_loss: 58.3394\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2221 - val_loss: 58.8194\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2053 - val_loss: 58.1535\n",
      "\n",
      "Mean Squared Error for iteration27: 47.512136592901115\n",
      "\n",
      "Iteration:  28\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4742 - val_loss: 58.2001\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1711 - val_loss: 57.8599\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 10.9930 - val_loss: 59.3731\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 235us/step - loss: 11.2038 - val_loss: 58.3995\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2340 - val_loss: 58.0059\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2004 - val_loss: 58.6942\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2284 - val_loss: 58.5562\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1390 - val_loss: 58.6582\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2754 - val_loss: 58.7378\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2494 - val_loss: 58.6072\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2335 - val_loss: 58.3208\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0402 - val_loss: 58.7792\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 184us/step - loss: 11.3531 - val_loss: 59.2675\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.6841 - val_loss: 58.4460\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3118 - val_loss: 58.1108\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4505 - val_loss: 58.4426\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.7945 - val_loss: 58.7229\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 12.2601 - val_loss: 58.1413\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3491 - val_loss: 59.2357\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3372 - val_loss: 58.7138\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4537 - val_loss: 58.4956\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 438us/step - loss: 11.0937 - val_loss: 59.1561\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4312 - val_loss: 58.6473\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1556 - val_loss: 58.5778\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2223 - val_loss: 58.3930\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0330 - val_loss: 58.6303\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.1713 - val_loss: 58.5489\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.5799 - val_loss: 60.4928\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 12.2104 - val_loss: 59.1895\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2105 - val_loss: 58.2445\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.0763 - val_loss: 58.8131\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2215 - val_loss: 58.3677\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.6739 - val_loss: 58.5500\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1380 - val_loss: 58.4654\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2447 - val_loss: 58.7848\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4792 - val_loss: 59.1913\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.2016 - val_loss: 58.7893\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1570 - val_loss: 58.3261\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1692 - val_loss: 58.6608\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0218 - val_loss: 58.9538\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1798 - val_loss: 58.2406\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1598 - val_loss: 58.8218\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1324 - val_loss: 58.0752\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0879 - val_loss: 58.4370\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2088 - val_loss: 57.8663\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.5433 - val_loss: 59.8246\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1589 - val_loss: 58.4457\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4797 - val_loss: 59.1939\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 10.9894 - val_loss: 58.5816\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1238 - val_loss: 58.3218\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2949 - val_loss: 58.9304\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3925 - val_loss: 58.2099\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1506 - val_loss: 58.5873\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2396 - val_loss: 58.6547\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0427 - val_loss: 58.2486\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2050 - val_loss: 58.3528\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6000 - val_loss: 58.3885\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.6111 - val_loss: 58.6044\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6512 - val_loss: 58.8419\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2034 - val_loss: 58.0548\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2023 - val_loss: 58.6645\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2698 - val_loss: 59.5885\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2829 - val_loss: 57.7117\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2059 - val_loss: 58.7344\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0453 - val_loss: 58.9210\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1917 - val_loss: 58.3099\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4503 - val_loss: 58.7189\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.5170 - val_loss: 59.1972\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4115 - val_loss: 58.1694\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4738 - val_loss: 60.3526\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1797 - val_loss: 58.4557\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1659 - val_loss: 59.2183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.1047 - val_loss: 58.0051\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1624 - val_loss: 59.0494\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3184 - val_loss: 58.2358\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4432 - val_loss: 58.4763\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3821 - val_loss: 58.6103\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1367 - val_loss: 58.4292\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2383 - val_loss: 58.7008\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0372 - val_loss: 58.4457\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1202 - val_loss: 58.1674\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4809 - val_loss: 59.3741\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.4575 - val_loss: 58.2246\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2819 - val_loss: 58.7369\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1352 - val_loss: 59.2912\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5366 - val_loss: 58.5418\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1929 - val_loss: 58.1206\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2637 - val_loss: 58.9901\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3971 - val_loss: 58.7930\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1552 - val_loss: 58.3763\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.1745 - val_loss: 58.5369\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4419 - val_loss: 58.7801\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3192 - val_loss: 59.7152\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.9166 - val_loss: 58.9783\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6034 - val_loss: 58.7438\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2324 - val_loss: 58.3714\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0215 - val_loss: 58.6386\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2755 - val_loss: 58.7802\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2251 - val_loss: 58.8451\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3018 - val_loss: 58.5585\n",
      "\n",
      "Mean Squared Error for iteration28: 48.07720855248626\n",
      "\n",
      "Iteration:  29\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1370 - val_loss: 58.5264\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.0922 - val_loss: 58.7298\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.0654 - val_loss: 58.3989\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1857 - val_loss: 58.1459\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2302 - val_loss: 59.1130\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2403 - val_loss: 58.3571\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2009 - val_loss: 58.9744\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1952 - val_loss: 58.5190\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3495 - val_loss: 58.2657\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4577 - val_loss: 58.2163\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2637 - val_loss: 58.1085\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2295 - val_loss: 58.5455\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1946 - val_loss: 58.8836\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.1581 - val_loss: 58.0314\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1922 - val_loss: 58.1269\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1201 - val_loss: 59.1340\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5712 - val_loss: 58.7133\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2196 - val_loss: 58.8430\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.2453 - val_loss: 58.9260\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6018 - val_loss: 58.7538\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4519 - val_loss: 58.3480\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0974 - val_loss: 58.4656\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0375 - val_loss: 58.8333\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1812 - val_loss: 58.3881\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1630 - val_loss: 60.3352\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 12.0767 - val_loss: 58.4373\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1843 - val_loss: 58.7788\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3645 - val_loss: 59.3776\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4776 - val_loss: 58.2941\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2933 - val_loss: 58.3285\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3649 - val_loss: 59.3250\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2176 - val_loss: 58.1405\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.1637 - val_loss: 58.5965\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1748 - val_loss: 59.0289\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1631 - val_loss: 58.2662\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1870 - val_loss: 59.4425\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3368 - val_loss: 58.2235\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5430 - val_loss: 58.9222\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1423 - val_loss: 57.9107\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1348 - val_loss: 58.6874\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1343 - val_loss: 58.3053\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2120 - val_loss: 58.5955\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5193 - val_loss: 58.7555\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.0990 - val_loss: 58.3736\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1815 - val_loss: 58.3913\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0490 - val_loss: 58.6738\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1826 - val_loss: 58.4917\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0328 - val_loss: 58.3660\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0107 - val_loss: 59.0971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3658 - val_loss: 58.5145\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4261 - val_loss: 59.9886\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.6569 - val_loss: 58.5279\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1825 - val_loss: 58.5208\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.9689 - val_loss: 59.9741\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5304 - val_loss: 59.0116\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.1841 - val_loss: 58.2881\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.0950 - val_loss: 58.4515\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2292 - val_loss: 58.7969\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4279 - val_loss: 58.7572\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4623 - val_loss: 58.3087\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4481 - val_loss: 58.1412\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1461 - val_loss: 58.7847\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.9203 - val_loss: 58.4893\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1778 - val_loss: 58.1012\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2088 - val_loss: 58.8277\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0810 - val_loss: 57.8526\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3387 - val_loss: 58.3114\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2462 - val_loss: 58.8253\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3735 - val_loss: 58.6310\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1575 - val_loss: 58.3791\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3395 - val_loss: 58.8525\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1559 - val_loss: 58.5156\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5073 - val_loss: 59.1136\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2156 - val_loss: 58.9871\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5738 - val_loss: 58.7960\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3409 - val_loss: 58.0969\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4264 - val_loss: 58.5861\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1208 - val_loss: 58.7196\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1916 - val_loss: 59.3865\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.2378 - val_loss: 58.1512\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 176us/step - loss: 11.1604 - val_loss: 58.2354\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1967 - val_loss: 59.1920\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2225 - val_loss: 58.5570\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1866 - val_loss: 58.4988\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.0462 - val_loss: 58.0608\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3033 - val_loss: 58.5031\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1383 - val_loss: 58.9143\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5175 - val_loss: 58.6945\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3914 - val_loss: 59.3007\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3249 - val_loss: 58.6687\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 12.0530 - val_loss: 59.1507\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.5260 - val_loss: 58.0635\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5366 - val_loss: 59.0793\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4459 - val_loss: 58.9838\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4336 - val_loss: 58.2683\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5721 - val_loss: 59.0338\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1001 - val_loss: 58.5501\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2741 - val_loss: 59.3979\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.2891 - val_loss: 57.7257\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.1259 - val_loss: 58.6600\n",
      "\n",
      "Mean Squared Error for iteration29: 48.14905384273573\n",
      "\n",
      "Iteration:  30\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.2162 - val_loss: 58.9082\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3017 - val_loss: 58.4633\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.1006 - val_loss: 58.5762\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 11.1750 - val_loss: 58.4062\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.0654 - val_loss: 58.6681\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2767 - val_loss: 58.4262\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4148 - val_loss: 59.1407\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.3191 - val_loss: 58.5029\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.9298 - val_loss: 59.1938\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.7894 - val_loss: 58.3704\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.5340 - val_loss: 58.9324\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.3835 - val_loss: 58.4186\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.1822 - val_loss: 58.1652\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.2386 - val_loss: 58.6601\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.4831 - val_loss: 58.9790\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.2511 - val_loss: 58.1530\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2261 - val_loss: 58.7318\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 10.9733 - val_loss: 59.0183\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2455 - val_loss: 58.4602\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1008 - val_loss: 58.5290\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3448 - val_loss: 58.5139\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2657 - val_loss: 59.2744\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5744 - val_loss: 59.0977\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 150us/step - loss: 11.2796 - val_loss: 58.4352\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2043 - val_loss: 58.7179\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2484 - val_loss: 58.1791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1525 - val_loss: 59.3524\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1342 - val_loss: 58.7000\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1559 - val_loss: 59.0501\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1893 - val_loss: 58.5178\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.2792 - val_loss: 57.9477\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2707 - val_loss: 58.3930\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 230us/step - loss: 11.1888 - val_loss: 58.5468\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 350us/step - loss: 11.1608 - val_loss: 58.6848\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 231us/step - loss: 11.1141 - val_loss: 58.2119\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 169us/step - loss: 11.2537 - val_loss: 58.5961\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.1070 - val_loss: 58.0975\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.1846 - val_loss: 59.0252\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4192 - val_loss: 58.5497\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3129 - val_loss: 59.0056\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2740 - val_loss: 58.2602\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0998 - val_loss: 59.0963\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5664 - val_loss: 59.5667\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4224 - val_loss: 58.0488\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.4356 - val_loss: 58.9386\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 154us/step - loss: 11.6287 - val_loss: 58.7029\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2367 - val_loss: 58.5784\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.7167 - val_loss: 58.4417\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1897 - val_loss: 58.5241\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.4044 - val_loss: 59.0677\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2690 - val_loss: 58.8344\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.4030 - val_loss: 58.1780\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5358 - val_loss: 59.3797\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3573 - val_loss: 57.9096\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2514 - val_loss: 59.3046\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3987 - val_loss: 58.5524\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5005 - val_loss: 59.2251\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3336 - val_loss: 57.8324\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.0924 - val_loss: 58.7868\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1356 - val_loss: 58.5963\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2290 - val_loss: 59.5515\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5698 - val_loss: 58.6984\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6461 - val_loss: 59.6266\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6676 - val_loss: 58.3860\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4037 - val_loss: 58.6732\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4573 - val_loss: 58.7226\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5681 - val_loss: 59.1158\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5142 - val_loss: 59.4698\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4130 - val_loss: 58.3363\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3788 - val_loss: 58.6342\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2685 - val_loss: 58.0787\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3428 - val_loss: 58.7691\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1002 - val_loss: 58.5553\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2445 - val_loss: 58.6293\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0218 - val_loss: 58.8375\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1231 - val_loss: 58.5641\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.0531 - val_loss: 58.6701\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1203 - val_loss: 58.6060\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.0314 - val_loss: 57.8871\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 130us/step - loss: 11.2134 - val_loss: 58.9502\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1911 - val_loss: 58.3817\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1674 - val_loss: 58.9750\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1893 - val_loss: 58.7569\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2908 - val_loss: 58.8148\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4138 - val_loss: 58.2054\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5315 - val_loss: 58.3339\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5309 - val_loss: 58.6895\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1312 - val_loss: 58.3010\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.2641 - val_loss: 58.6007\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1556 - val_loss: 59.4127\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.6757 - val_loss: 59.1848\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3985 - val_loss: 59.0261\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1482 - val_loss: 58.4035\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2829 - val_loss: 58.6987\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1511 - val_loss: 58.5704\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.2979 - val_loss: 58.8141\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3350 - val_loss: 58.6845\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2032 - val_loss: 58.4428\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1676 - val_loss: 58.5677\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.2194 - val_loss: 58.4985\n",
      "\n",
      "Mean Squared Error for iteration30: 47.6161359499778\n",
      "\n",
      "Iteration:  31\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2142 - val_loss: 58.9936\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1147 - val_loss: 58.9388\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4811 - val_loss: 59.3510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3134 - val_loss: 58.5826\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5343 - val_loss: 58.6652\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3790 - val_loss: 58.5895\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2728 - val_loss: 58.4527\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2981 - val_loss: 58.6019\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1336 - val_loss: 58.2864\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2121 - val_loss: 58.3386\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 10.9823 - val_loss: 59.1736\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1536 - val_loss: 59.1086\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2573 - val_loss: 58.7248\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2500 - val_loss: 58.4175\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9955 - val_loss: 58.7484\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2522 - val_loss: 58.5389\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5514 - val_loss: 59.3565\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2348 - val_loss: 58.8991\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1982 - val_loss: 58.4391\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3911 - val_loss: 58.9969\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1109 - val_loss: 58.4127\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2562 - val_loss: 58.5775\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1312 - val_loss: 58.8776\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2859 - val_loss: 59.6857\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5817 - val_loss: 58.7145\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.1941 - val_loss: 58.2434\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1316 - val_loss: 58.2472\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2145 - val_loss: 58.5609\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1657 - val_loss: 58.9986\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4595 - val_loss: 58.9507\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.2297 - val_loss: 59.2061\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3244 - val_loss: 58.7125\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.6222 - val_loss: 58.6501\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4102 - val_loss: 58.7406\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1812 - val_loss: 58.0826\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1840 - val_loss: 58.1872\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1814 - val_loss: 58.6401\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.1273 - val_loss: 58.7251\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3299 - val_loss: 58.5147\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2065 - val_loss: 59.0865\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2619 - val_loss: 58.3582\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1168 - val_loss: 58.7684\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0618 - val_loss: 58.5508\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0707 - val_loss: 58.6088\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0416 - val_loss: 59.2291\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.4633 - val_loss: 58.7994\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2534 - val_loss: 58.6081\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5897 - val_loss: 58.4589\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3628 - val_loss: 58.6175\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1356 - val_loss: 59.2284\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2042 - val_loss: 58.5548\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1943 - val_loss: 57.9402\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3245 - val_loss: 58.3346\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3294 - val_loss: 58.3790\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3344 - val_loss: 58.4339\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3052 - val_loss: 58.8012\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3986 - val_loss: 58.4469\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1933 - val_loss: 58.0016\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4936 - val_loss: 58.4499\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3303 - val_loss: 58.7229\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2538 - val_loss: 58.7308\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2616 - val_loss: 58.4313\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.1650 - val_loss: 58.3340\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1749 - val_loss: 58.4540\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 181us/step - loss: 11.2408 - val_loss: 58.4657\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.4547 - val_loss: 59.2272\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3267 - val_loss: 58.1283\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1300 - val_loss: 58.4117\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.1181 - val_loss: 58.7664\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0300 - val_loss: 59.0923\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2480 - val_loss: 58.1287\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.0723 - val_loss: 59.1891\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.1030 - val_loss: 58.5524\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.1863 - val_loss: 58.4078\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.0703 - val_loss: 59.2838\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.1230 - val_loss: 58.4718\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.1508 - val_loss: 58.7313\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.2704 - val_loss: 58.9769\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3794 - val_loss: 58.6221\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3966 - val_loss: 58.9670\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1518 - val_loss: 58.8860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1833 - val_loss: 59.0911\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2764 - val_loss: 58.6438\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.3063 - val_loss: 58.8193\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1269 - val_loss: 58.1822\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1130 - val_loss: 58.5299\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2783 - val_loss: 58.1061\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2726 - val_loss: 59.1177\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.6051 - val_loss: 58.4743\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1547 - val_loss: 59.0571\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1912 - val_loss: 58.8455\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1870 - val_loss: 58.4779\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.1250 - val_loss: 58.8062\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1027 - val_loss: 58.6763\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4816 - val_loss: 60.0998\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 141us/step - loss: 11.3398 - val_loss: 58.6013\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4735 - val_loss: 59.1189\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.5519 - val_loss: 58.5896\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2696 - val_loss: 58.3017\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2400 - val_loss: 59.0942\n",
      "\n",
      "Mean Squared Error for iteration31: 48.848068385595695\n",
      "\n",
      "Iteration:  32\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1235 - val_loss: 57.8347\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3306 - val_loss: 58.3769\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3023 - val_loss: 58.6903\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2395 - val_loss: 58.1602\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2722 - val_loss: 58.7517\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3998 - val_loss: 58.5086\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1537 - val_loss: 58.5143\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9548 - val_loss: 58.7569\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1012 - val_loss: 58.2114\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2392 - val_loss: 58.8045\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2343 - val_loss: 58.4701\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2295 - val_loss: 58.6327\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1847 - val_loss: 57.9806\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1730 - val_loss: 59.0177\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3182 - val_loss: 58.5365\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2999 - val_loss: 57.9309\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1479 - val_loss: 58.9153\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0289 - val_loss: 58.4434\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3215 - val_loss: 59.2352\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3833 - val_loss: 58.8758\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2415 - val_loss: 59.0764\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5351 - val_loss: 58.8361\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2657 - val_loss: 58.3358\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3474 - val_loss: 58.6277\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1523 - val_loss: 58.3397\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1390 - val_loss: 58.6135\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2662 - val_loss: 58.5253\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1420 - val_loss: 58.7867\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3710 - val_loss: 58.4869\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1256 - val_loss: 58.5426\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2836 - val_loss: 57.9212\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5309 - val_loss: 60.3052\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.4774 - val_loss: 58.9617\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.2061 - val_loss: 58.7411\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2316 - val_loss: 58.5047\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.1226 - val_loss: 58.3908\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1137 - val_loss: 58.8695\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.1281 - val_loss: 58.1503\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.0533 - val_loss: 59.2873\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.2032 - val_loss: 58.5735\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.4073 - val_loss: 59.3487\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4547 - val_loss: 58.5379\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1982 - val_loss: 58.2033\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3307 - val_loss: 58.7140\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5474 - val_loss: 58.2573\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4651 - val_loss: 58.9920\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2680 - val_loss: 58.8182\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0749 - val_loss: 58.5672\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 375us/step - loss: 11.0640 - val_loss: 57.9741\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 428us/step - loss: 11.1640 - val_loss: 58.6084\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 149us/step - loss: 11.2603 - val_loss: 58.8615\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 478us/step - loss: 11.1938 - val_loss: 58.2307\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.1310 - val_loss: 58.8618\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2637 - val_loss: 58.1969\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0950 - val_loss: 58.1184\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.0558 - val_loss: 58.6101\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2568 - val_loss: 58.5309\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3508 - val_loss: 58.2711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2525 - val_loss: 58.8608\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1937 - val_loss: 58.3584\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1034 - val_loss: 58.1094\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.1654 - val_loss: 58.4027\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2458 - val_loss: 58.5566\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0594 - val_loss: 58.9910\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2452 - val_loss: 58.9768\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2045 - val_loss: 58.6243\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1704 - val_loss: 58.2884\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1890 - val_loss: 59.0823\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1910 - val_loss: 58.3481\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1667 - val_loss: 58.4676\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2270 - val_loss: 58.3802\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2226 - val_loss: 58.4679\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1341 - val_loss: 58.0247\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1029 - val_loss: 58.9287\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3662 - val_loss: 58.6565\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1993 - val_loss: 58.3840\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2591 - val_loss: 59.0904\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1658 - val_loss: 57.8310\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2779 - val_loss: 58.4585\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2146 - val_loss: 58.6532\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.1187 - val_loss: 58.8252\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2781 - val_loss: 58.4076\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2701 - val_loss: 59.5709\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5580 - val_loss: 59.3961\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4559 - val_loss: 57.9824\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3464 - val_loss: 58.2330\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1479 - val_loss: 58.6271\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1051 - val_loss: 59.5591\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3547 - val_loss: 58.1676\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4955 - val_loss: 58.8624\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2773 - val_loss: 59.4868\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1044 - val_loss: 57.7260\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.1544 - val_loss: 58.9922\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.4555 - val_loss: 58.5137\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1851 - val_loss: 58.8958\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3501 - val_loss: 58.0858\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2452 - val_loss: 59.2695\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.6666 - val_loss: 59.1997\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2142 - val_loss: 58.6015\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.1799 - val_loss: 58.6643\n",
      "\n",
      "Mean Squared Error for iteration32: 48.53899628108316\n",
      "\n",
      "Iteration:  33\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3792 - val_loss: 59.0101\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1834 - val_loss: 57.8736\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3728 - val_loss: 59.2554\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2991 - val_loss: 58.5802\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1734 - val_loss: 58.6971\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1296 - val_loss: 58.5540\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2929 - val_loss: 59.1945\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4328 - val_loss: 60.0245\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6942 - val_loss: 58.0974\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3135 - val_loss: 59.0960\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1606 - val_loss: 58.0887\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3093 - val_loss: 59.2741\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5053 - val_loss: 58.8763\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3650 - val_loss: 58.3430\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2969 - val_loss: 58.1178\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2528 - val_loss: 58.8927\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1567 - val_loss: 58.0552\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.2537 - val_loss: 58.4065\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1745 - val_loss: 59.2961\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4639 - val_loss: 58.4743\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2272 - val_loss: 59.1243\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2256 - val_loss: 58.7763\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2410 - val_loss: 58.7274\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4173 - val_loss: 58.6696\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2729 - val_loss: 57.9422\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2983 - val_loss: 58.1241\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3048 - val_loss: 59.6492\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2198 - val_loss: 59.1704\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3326 - val_loss: 58.7524\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.1957 - val_loss: 58.3378\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3053 - val_loss: 58.6559\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1289 - val_loss: 58.1766\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2796 - val_loss: 58.9856\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4672 - val_loss: 59.1010\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4419 - val_loss: 57.6350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.1539 - val_loss: 59.6255\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0584 - val_loss: 58.2406\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0092 - val_loss: 58.6461\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1026 - val_loss: 58.7480\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1538 - val_loss: 58.1930\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1594 - val_loss: 58.0107\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3956 - val_loss: 58.3230\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0558 - val_loss: 58.6066\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2498 - val_loss: 58.3225\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1794 - val_loss: 58.6473\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0972 - val_loss: 59.3657\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2735 - val_loss: 58.1001\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2333 - val_loss: 58.2528\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4527 - val_loss: 59.0081\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5996 - val_loss: 58.9683\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4309 - val_loss: 58.1870\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4410 - val_loss: 58.0654\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2763 - val_loss: 58.8892\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0337 - val_loss: 58.4937\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1263 - val_loss: 58.7968\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3368 - val_loss: 58.6735\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3659 - val_loss: 58.5058\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1406 - val_loss: 58.4844\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1383 - val_loss: 58.4765\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4676 - val_loss: 58.6580\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6453 - val_loss: 58.8648\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2382 - val_loss: 57.9437\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1814 - val_loss: 58.7310\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1700 - val_loss: 58.2186\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.7762 - val_loss: 59.2396\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2822 - val_loss: 58.4062\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2890 - val_loss: 58.6155\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.1151 - val_loss: 58.6202\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2698 - val_loss: 58.2777\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.1402 - val_loss: 59.2740\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3415 - val_loss: 58.4860\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3885 - val_loss: 58.9304\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1256 - val_loss: 57.9909\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3550 - val_loss: 59.1366\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0827 - val_loss: 58.7961\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0147 - val_loss: 58.0933\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3849 - val_loss: 58.9578\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2791 - val_loss: 58.3984\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4485 - val_loss: 59.6081\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0951 - val_loss: 58.3079\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1001 - val_loss: 58.5361\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1444 - val_loss: 57.9846\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2411 - val_loss: 58.8371\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1575 - val_loss: 58.8793\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2280 - val_loss: 58.3207\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2385 - val_loss: 58.6551\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3346 - val_loss: 59.4414\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3052 - val_loss: 59.1888\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5459 - val_loss: 58.6829\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5063 - val_loss: 58.9503\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2294 - val_loss: 58.2733\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3952 - val_loss: 59.0888\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6069 - val_loss: 58.9604\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2864 - val_loss: 58.5808\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3020 - val_loss: 58.2882\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2263 - val_loss: 58.6623\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.6222 - val_loss: 60.0628\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3849 - val_loss: 59.4056\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2960 - val_loss: 58.1267\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5830 - val_loss: 59.2094\n",
      "\n",
      "Mean Squared Error for iteration33: 49.31063680185769\n",
      "\n",
      "Iteration:  34\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5876 - val_loss: 58.8413\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.6236 - val_loss: 58.7229\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0546 - val_loss: 58.6268\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.1381 - val_loss: 57.5900\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2746 - val_loss: 58.7892\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1988 - val_loss: 58.0560\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5121 - val_loss: 59.1880\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2390 - val_loss: 58.3026\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0607 - val_loss: 58.3417\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1309 - val_loss: 58.7006\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1156 - val_loss: 58.2609\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1195 - val_loss: 58.3908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1818 - val_loss: 58.7151\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1843 - val_loss: 59.4592\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6870 - val_loss: 58.1036\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2189 - val_loss: 59.2368\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0905 - val_loss: 58.6440\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1231 - val_loss: 58.5895\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2602 - val_loss: 58.2420\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0363 - val_loss: 59.0189\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4632 - val_loss: 58.8305\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.1956 - val_loss: 58.1653\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.7158 - val_loss: 60.3966\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.8693 - val_loss: 58.9412\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.6243 - val_loss: 59.0598\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.3683 - val_loss: 57.6262\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2367 - val_loss: 59.5390\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3220 - val_loss: 58.3148\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1831 - val_loss: 58.9367\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.0921 - val_loss: 58.1387\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1074 - val_loss: 59.0670\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3002 - val_loss: 58.3851\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4130 - val_loss: 59.0187\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2916 - val_loss: 58.8570\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2231 - val_loss: 59.3335\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1964 - val_loss: 59.0423\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2425 - val_loss: 58.5553\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0888 - val_loss: 58.7804\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0575 - val_loss: 58.1084\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.1519 - val_loss: 58.2683\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1929 - val_loss: 58.6907\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1185 - val_loss: 58.6119\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 10.9915 - val_loss: 58.6533\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2521 - val_loss: 58.2901\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0932 - val_loss: 59.5725\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1407 - val_loss: 58.5616\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.1669 - val_loss: 58.7283\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1297 - val_loss: 59.0598\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1506 - val_loss: 58.4565\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4393 - val_loss: 58.5050\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2550 - val_loss: 58.6980\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.4057 - val_loss: 58.4011\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2446 - val_loss: 58.5610\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1470 - val_loss: 58.2853\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4578 - val_loss: 59.3939\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0981 - val_loss: 57.8741\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0332 - val_loss: 59.1733\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2844 - val_loss: 58.4200\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2293 - val_loss: 58.3991\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1803 - val_loss: 58.9856\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1097 - val_loss: 58.7163\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1730 - val_loss: 59.7497\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.7081 - val_loss: 58.6545\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.5268 - val_loss: 57.6015\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3273 - val_loss: 58.5788\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1027 - val_loss: 58.4110\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3248 - val_loss: 59.1996\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5642 - val_loss: 59.0153\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.7442 - val_loss: 58.4327\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4366 - val_loss: 58.6631\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3478 - val_loss: 60.1692\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4303 - val_loss: 58.6730\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5917 - val_loss: 57.8975\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2009 - val_loss: 59.6985\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.1552 - val_loss: 58.2548\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.0755 - val_loss: 58.9480\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2482 - val_loss: 57.9841\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4017 - val_loss: 59.4625\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1548 - val_loss: 58.6928\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.7518 - val_loss: 58.6616\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2568 - val_loss: 58.7411\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5458 - val_loss: 59.3184\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.7627 - val_loss: 59.1827\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1783 - val_loss: 57.9820\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0884 - val_loss: 58.6176\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0949 - val_loss: 58.5599\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2920 - val_loss: 58.3656\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1140 - val_loss: 58.7387\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0680 - val_loss: 58.6238\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1850 - val_loss: 58.1784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1144 - val_loss: 58.6347\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3344 - val_loss: 57.9461\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1164 - val_loss: 58.6999\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2012 - val_loss: 59.1307\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5385 - val_loss: 58.2407\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1588 - val_loss: 58.5921\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 178us/step - loss: 11.1648 - val_loss: 58.6094\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 150us/step - loss: 11.0834 - val_loss: 58.3404\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 224us/step - loss: 11.1851 - val_loss: 59.2899\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.2309 - val_loss: 58.8633\n",
      "\n",
      "Mean Squared Error for iteration34: 48.95620150327209\n",
      "\n",
      "Iteration:  35\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.1486 - val_loss: 58.2952\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2576 - val_loss: 58.1525\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 205us/step - loss: 11.9443 - val_loss: 59.9505\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 207us/step - loss: 11.2694 - val_loss: 58.7359\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 210us/step - loss: 11.1513 - val_loss: 58.1181\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 207us/step - loss: 11.2780 - val_loss: 58.8939\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.2239 - val_loss: 58.2938\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1580 - val_loss: 58.3971\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.0879 - val_loss: 58.0126\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.1029 - val_loss: 59.2262\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.6453 - val_loss: 58.3961\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3391 - val_loss: 58.4624\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 10.9901 - val_loss: 58.6810\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.1009 - val_loss: 58.6580\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.1634 - val_loss: 58.7023\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2283 - val_loss: 58.9952\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.1952 - val_loss: 58.3338\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2026 - val_loss: 58.9676\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2978 - val_loss: 58.8181\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 279us/step - loss: 11.2389 - val_loss: 58.9513\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.0781 - val_loss: 59.3160\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 191us/step - loss: 11.3482 - val_loss: 58.8869\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 322us/step - loss: 11.0296 - val_loss: 58.1033\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 176us/step - loss: 11.0892 - val_loss: 58.4681\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 167us/step - loss: 11.2394 - val_loss: 59.0503\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.4322 - val_loss: 58.0984\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.3193 - val_loss: 59.2657\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.0693 - val_loss: 58.2205\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.1618 - val_loss: 59.1593\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.1748 - val_loss: 58.3520\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 351us/step - loss: 11.0451 - val_loss: 59.0053\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4243 - val_loss: 58.6720\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1553 - val_loss: 58.9858\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.0670 - val_loss: 58.8278\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.4925 - val_loss: 57.8433\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1452 - val_loss: 59.0874\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0473 - val_loss: 58.1949\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3203 - val_loss: 59.1549\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2680 - val_loss: 59.7554\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 10.9563 - val_loss: 58.5551\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.0681 - val_loss: 58.5388\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 10.9948 - val_loss: 58.7562\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.0692 - val_loss: 58.6200\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2005 - val_loss: 58.3682\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2138 - val_loss: 59.0823\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2501 - val_loss: 58.0271\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.0872 - val_loss: 59.2889\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.4721 - val_loss: 58.0128\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.0930 - val_loss: 59.1829\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 138us/step - loss: 11.0587 - val_loss: 58.4388\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 154us/step - loss: 11.4887 - val_loss: 58.7230\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.3616 - val_loss: 58.5730\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.1336 - val_loss: 58.6092\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.1831 - val_loss: 58.5573\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.1696 - val_loss: 58.3774\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4362 - val_loss: 59.7690\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.4077 - val_loss: 58.5455\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.1074 - val_loss: 58.7613\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.0963 - val_loss: 58.2153\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4068 - val_loss: 58.8962\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4867 - val_loss: 58.2937\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.0958 - val_loss: 58.3435\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.1103 - val_loss: 58.1828\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 182us/step - loss: 11.1646 - val_loss: 58.5585\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.2030 - val_loss: 58.8246\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.2259 - val_loss: 58.7118\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 109us/step - loss: 11.4144 - val_loss: 58.9806\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 141us/step - loss: 11.2100 - val_loss: 58.7942\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.0226 - val_loss: 57.9357\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.1944 - val_loss: 58.8172\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1758 - val_loss: 58.2902\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2845 - val_loss: 58.2486\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.0165 - val_loss: 59.3587\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2960 - val_loss: 58.5324\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2037 - val_loss: 58.6762\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2076 - val_loss: 58.8523\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2944 - val_loss: 58.0210\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4379 - val_loss: 58.9191\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.1633 - val_loss: 58.3001\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.3125 - val_loss: 58.5263\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1879 - val_loss: 59.1639\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0802 - val_loss: 58.4912\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1713 - val_loss: 58.8156\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1696 - val_loss: 58.7648\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0209 - val_loss: 58.4391\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2872 - val_loss: 59.5576\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 165us/step - loss: 11.7352 - val_loss: 58.9492\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 212us/step - loss: 11.1845 - val_loss: 58.7062\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 146us/step - loss: 11.0906 - val_loss: 58.4173\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1292 - val_loss: 58.5221\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.1369 - val_loss: 58.8482\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 165us/step - loss: 11.2687 - val_loss: 58.3548\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 178us/step - loss: 11.4507 - val_loss: 58.3426\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1060 - val_loss: 58.5071\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2583 - val_loss: 58.9995\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.1759 - val_loss: 59.1631\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - ETA: 0s - loss: 11.6635 ETA: 0s - loss: 12. - 0s 454us/step - loss: 11.2032 - val_loss: 58.3810\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 325us/step - loss: 11.3057 - val_loss: 58.3066\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 259us/step - loss: 11.1473 - val_loss: 59.2625\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 201us/step - loss: 11.0230 - val_loss: 57.8091\n",
      "\n",
      "Mean Squared Error for iteration35: 47.29704539132291\n",
      "\n",
      "Iteration:  36\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.2398 - val_loss: 58.7809\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 284us/step - loss: 11.0631 - val_loss: 58.6555\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 248us/step - loss: 11.2094 - val_loss: 58.4207\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 218us/step - loss: 11.3048 - val_loss: 58.6090\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 228us/step - loss: 11.3018 - val_loss: 58.8574\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 270us/step - loss: 11.1307 - val_loss: 58.4401\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 203us/step - loss: 11.2625 - val_loss: 58.7802\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.2366 - val_loss: 58.6278\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 202us/step - loss: 11.2001 - val_loss: 59.0008\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.1289 - val_loss: 58.5717\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 177us/step - loss: 11.0434 - val_loss: 58.1597\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1171 - val_loss: 59.0776\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.0718 - val_loss: 57.9605\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 150us/step - loss: 11.1243 - val_loss: 58.1581\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 128us/step - loss: 11.4535 - val_loss: 58.5479\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 118us/step - loss: 11.0437 - val_loss: 59.6686\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.4198 - val_loss: 58.2668\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 10.9978 - val_loss: 58.4343\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.1690 - val_loss: 58.0189\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.6859 - val_loss: 59.1153\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 134us/step - loss: 11.2841 - val_loss: 58.1375\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0689 - val_loss: 58.6291\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.0925 - val_loss: 58.2102\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0518 - val_loss: 58.2394\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.1778 - val_loss: 57.9268\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2592 - val_loss: 59.8412\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2774 - val_loss: 58.8250\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.9880 - val_loss: 58.1344\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3483 - val_loss: 58.6506\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.3238 - val_loss: 58.0272\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 164us/step - loss: 10.9855 - val_loss: 58.9376\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1059 - val_loss: 58.8537\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1966 - val_loss: 57.9383\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3646 - val_loss: 58.7253\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1337 - val_loss: 58.5111\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1506 - val_loss: 58.2288\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1727 - val_loss: 58.5196\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.0234 - val_loss: 58.6069\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6445 - val_loss: 60.0724\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7934 - val_loss: 59.4054\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4004 - val_loss: 58.0293\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0942 - val_loss: 58.8184\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 85us/step - loss: 11.0094 - val_loss: 58.5646\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2329 - val_loss: 58.3738\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.0028 - val_loss: 59.1784\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0041 - val_loss: 58.4115\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1112 - val_loss: 58.4601\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1030 - val_loss: 58.6298\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1722 - val_loss: 59.5274\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.0533 - val_loss: 58.3940\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0779 - val_loss: 59.0946\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.3194 - val_loss: 58.5034\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5503 - val_loss: 59.5677\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2659 - val_loss: 58.1354\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3337 - val_loss: 58.3074\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2999 - val_loss: 58.7092\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1444 - val_loss: 57.9945\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1862 - val_loss: 58.5434\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1403 - val_loss: 59.3173\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2531 - val_loss: 58.7615\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.3973 - val_loss: 58.6394\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4121 - val_loss: 58.6622\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.9935 - val_loss: 58.6082\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3398 - val_loss: 58.4728\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1665 - val_loss: 58.3713\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2115 - val_loss: 58.0287\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.1517 - val_loss: 58.9024\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3804 - val_loss: 59.4824\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.7798 - val_loss: 58.4261\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2844 - val_loss: 58.7199\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 212us/step - loss: 11.8294 - val_loss: 59.2630\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 167us/step - loss: 11.9953 - val_loss: 59.0774\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 166us/step - loss: 11.9110 - val_loss: 58.6522\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.1393 - val_loss: 58.2074\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1649 - val_loss: 58.9967\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3774 - val_loss: 58.7642\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5008 - val_loss: 58.6521\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2069 - val_loss: 59.4008\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.6337 - val_loss: 58.6054\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.3345 - val_loss: 58.8078\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.2278 - val_loss: 58.3574\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 144us/step - loss: 11.1961 - val_loss: 58.5287\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0660 - val_loss: 58.7813\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1013 - val_loss: 57.9377\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.1429 - val_loss: 58.9111\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.4977 - val_loss: 58.8924\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4533 - val_loss: 58.8942\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.3434 - val_loss: 58.2423\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1270 - val_loss: 58.3293\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1473 - val_loss: 58.6523\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.3377 - val_loss: 58.3059\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1184 - val_loss: 58.4970\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0719 - val_loss: 58.5823\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.1258 - val_loss: 58.9881\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3249 - val_loss: 58.0072\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2113 - val_loss: 59.1659\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3800 - val_loss: 58.7652\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.0807 - val_loss: 58.0896\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1635 - val_loss: 59.6268\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1464 - val_loss: 58.2711\n",
      "\n",
      "Mean Squared Error for iteration36: 48.01426239136982\n",
      "\n",
      "Iteration:  37\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.1304 - val_loss: 58.7411\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.6548 - val_loss: 59.8952\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3868 - val_loss: 58.6056\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9809 - val_loss: 58.7353\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1625 - val_loss: 58.5634\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.0392 - val_loss: 59.0306\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.2315 - val_loss: 58.0770\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.7115 - val_loss: 58.6963\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4941 - val_loss: 59.3206\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.2454 - val_loss: 59.0005\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1737 - val_loss: 59.0238\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 11.3714 - val_loss: 58.6120\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1630 - val_loss: 58.8893\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2333 - val_loss: 58.6728\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2482 - val_loss: 58.1420\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9978 - val_loss: 58.3751\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0493 - val_loss: 58.4740\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1260 - val_loss: 58.8635\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4109 - val_loss: 58.4560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1714 - val_loss: 58.5793\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9710 - val_loss: 58.7499\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 133us/step - loss: 11.2260 - val_loss: 58.6102\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1239 - val_loss: 58.5086\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.0759 - val_loss: 58.3879\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.0913 - val_loss: 58.4761\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1959 - val_loss: 58.5746\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.0502 - val_loss: 57.8800\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0986 - val_loss: 58.9031\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 10.9841 - val_loss: 57.6523\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2675 - val_loss: 59.0841\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2064 - val_loss: 58.4538\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.1496 - val_loss: 59.5162\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.4633 - val_loss: 58.1887\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2856 - val_loss: 58.5079\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.0494 - val_loss: 58.7571\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0469 - val_loss: 58.4666\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1478 - val_loss: 58.8459\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2609 - val_loss: 58.0564\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3306 - val_loss: 59.1551\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2782 - val_loss: 58.9962\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.5853 - val_loss: 58.7265\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2533 - val_loss: 58.2249\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2690 - val_loss: 59.6334\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.3127 - val_loss: 58.1891\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1985 - val_loss: 59.2528\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2136 - val_loss: 58.0162\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0999 - val_loss: 58.3653\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0496 - val_loss: 58.6048\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0520 - val_loss: 58.6576\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2377 - val_loss: 58.6882\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3400 - val_loss: 59.0034\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3047 - val_loss: 58.8781\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2979 - val_loss: 59.1345\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.0725 - val_loss: 57.8818\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0167 - val_loss: 58.3110\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1510 - val_loss: 58.9716\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4227 - val_loss: 58.9587\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2793 - val_loss: 58.3166\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 12.0965 - val_loss: 59.1731\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.4188 - val_loss: 58.4317\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3447 - val_loss: 57.8623\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3853 - val_loss: 58.5476\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0042 - val_loss: 58.5676\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5715 - val_loss: 58.7436\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1174 - val_loss: 58.4288\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0623 - val_loss: 58.1715\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 10.9694 - val_loss: 58.2814\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5585 - val_loss: 59.3676\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 125us/step - loss: 11.4394 - val_loss: 58.1199\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1602 - val_loss: 59.2302\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 11.2242 - val_loss: 57.5209\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4691 - val_loss: 58.2583\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0300 - val_loss: 58.5913\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2292 - val_loss: 58.4903\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7265 - val_loss: 59.1996\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3784 - val_loss: 58.6328\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6429 - val_loss: 58.2018\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.0829 - val_loss: 59.4698\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6258 - val_loss: 58.8626\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3092 - val_loss: 58.8248\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1917 - val_loss: 58.5370\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2906 - val_loss: 58.6759\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2833 - val_loss: 59.4266\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2212 - val_loss: 58.7258\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.3284 - val_loss: 58.2067\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4933 - val_loss: 58.2602\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.7642 - val_loss: 58.2730\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.4703 - val_loss: 59.0781\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 203us/step - loss: 11.2822 - val_loss: 59.0519\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 334us/step - loss: 11.2862 - val_loss: 58.6430\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 168us/step - loss: 10.9123 - val_loss: 58.8960\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.3049 - val_loss: 58.5014\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3237 - val_loss: 57.8922\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1923 - val_loss: 58.7389\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 10.9759 - val_loss: 58.2071\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 242us/step - loss: 11.2111 - val_loss: 60.0426\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 248us/step - loss: 11.6372 - val_loss: 58.8791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 198us/step - loss: 11.3857 - val_loss: 58.2571\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 191us/step - loss: 11.1258 - val_loss: 58.6847\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 229us/step - loss: 11.1945 - val_loss: 58.3266\n",
      "\n",
      "Mean Squared Error for iteration37: 47.96933474214905\n",
      "\n",
      "Iteration:  38\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 218us/step - loss: 11.2220 - val_loss: 58.2201\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 180us/step - loss: 11.0990 - val_loss: 59.3007\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.4524 - val_loss: 58.1915\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2968 - val_loss: 58.5596\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 10.9583 - val_loss: 58.6116\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.3168 - val_loss: 58.7470\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3682 - val_loss: 58.4044\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4340 - val_loss: 59.0870\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2083 - val_loss: 58.3093\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2831 - val_loss: 58.2819\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4628 - val_loss: 59.3737\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2243 - val_loss: 58.5092\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.0911 - val_loss: 58.9378\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0782 - val_loss: 58.6154\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0565 - val_loss: 57.7326\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0436 - val_loss: 58.7729\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2841 - val_loss: 59.0325\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 11.1787 - val_loss: 58.8715\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 175us/step - loss: 11.2170 - val_loss: 58.4550\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2574 - val_loss: 58.4075\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2286 - val_loss: 58.6591\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1101 - val_loss: 58.6993\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.3121 - val_loss: 58.5721\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2680 - val_loss: 59.2164\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.8650 - val_loss: 59.4338\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1120 - val_loss: 58.4692\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3322 - val_loss: 59.1716\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.6315 - val_loss: 58.4275\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.3329 - val_loss: 58.4923\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.4710 - val_loss: 58.6220\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0387 - val_loss: 59.4732\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1949 - val_loss: 58.1385\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0922 - val_loss: 58.8059\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4765 - val_loss: 59.2768\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2278 - val_loss: 58.3201\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1432 - val_loss: 58.6468\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 10.9674 - val_loss: 57.8707\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2180 - val_loss: 58.3650\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2374 - val_loss: 58.6247\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6166 - val_loss: 59.4300\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0034 - val_loss: 58.5300\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2644 - val_loss: 58.6467\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2014 - val_loss: 58.3663\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0913 - val_loss: 58.6991\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0679 - val_loss: 58.2499\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0995 - val_loss: 58.2606\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0139 - val_loss: 58.3820\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.1288 - val_loss: 58.6923\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5712 - val_loss: 58.8250\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3825 - val_loss: 57.7650\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2177 - val_loss: 59.1936\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2330 - val_loss: 58.6372\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2187 - val_loss: 58.7149\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1614 - val_loss: 58.4915\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2977 - val_loss: 59.1668\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9160 - val_loss: 58.0464\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2655 - val_loss: 58.7899\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2918 - val_loss: 58.2145\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1495 - val_loss: 58.8466\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 144us/step - loss: 11.0381 - val_loss: 58.0333\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.2469 - val_loss: 58.9460\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1187 - val_loss: 57.8735\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 271us/step - loss: 11.2784 - val_loss: 58.5558\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 149us/step - loss: 11.1094 - val_loss: 58.3374\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1617 - val_loss: 58.8117\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2989 - val_loss: 58.1197\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.3400 - val_loss: 58.4107\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0584 - val_loss: 58.1984\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0145 - val_loss: 58.6177\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.0261 - val_loss: 58.1201\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.9673 - val_loss: 58.6876\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2000 - val_loss: 59.1299\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1046 - val_loss: 58.5964\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2281 - val_loss: 59.1378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.7441 - val_loss: 58.3271\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1071 - val_loss: 59.2482\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2726 - val_loss: 58.9555\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0599 - val_loss: 58.6520\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1769 - val_loss: 58.8041\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3702 - val_loss: 58.0834\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1938 - val_loss: 58.8814\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4919 - val_loss: 58.4700\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4631 - val_loss: 58.9916\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1540 - val_loss: 58.2585\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0735 - val_loss: 59.2890\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2694 - val_loss: 59.0838\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1211 - val_loss: 58.4986\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 83us/step - loss: 11.2105 - val_loss: 58.8109\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.0582 - val_loss: 58.2342\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4042 - val_loss: 58.8002\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2109 - val_loss: 58.2271\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4120 - val_loss: 59.1552\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2516 - val_loss: 58.1474\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0509 - val_loss: 58.8192\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.2758 - val_loss: 58.7751\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2620 - val_loss: 58.6878\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4081 - val_loss: 58.4966\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.3428 - val_loss: 58.6204\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2760 - val_loss: 59.3064\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.5661 - val_loss: 57.9879\n",
      "\n",
      "Mean Squared Error for iteration38: 48.11813248923204\n",
      "\n",
      "Iteration:  39\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 10.9847 - val_loss: 58.9332\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3520 - val_loss: 58.1203\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.0604 - val_loss: 58.3354\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0713 - val_loss: 58.0737\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2384 - val_loss: 58.0934\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.0322 - val_loss: 58.1189\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.0223 - val_loss: 58.6304\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1578 - val_loss: 58.3084\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0556 - val_loss: 58.7867\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0556 - val_loss: 58.0692\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2786 - val_loss: 58.9691\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0856 - val_loss: 57.9234\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3217 - val_loss: 59.2390\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7261 - val_loss: 59.4794\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1332 - val_loss: 58.1905\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.0728 - val_loss: 59.1739\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 154us/step - loss: 11.0921 - val_loss: 58.8400\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 138us/step - loss: 11.1533 - val_loss: 58.6508\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 166us/step - loss: 11.4540 - val_loss: 58.7345\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 175us/step - loss: 11.3316 - val_loss: 58.7090\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 147us/step - loss: 11.4731 - val_loss: 59.3233\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.4934 - val_loss: 59.1871\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 340us/step - loss: 11.5093 - val_loss: 58.1647\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 206us/step - loss: 11.0867 - val_loss: 58.6875\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 192us/step - loss: 11.2900 - val_loss: 58.5571\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 187us/step - loss: 11.4091 - val_loss: 58.4213\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 182us/step - loss: 11.3136 - val_loss: 58.4412\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 239us/step - loss: 11.1584 - val_loss: 58.7641\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 183us/step - loss: 11.0130 - val_loss: 58.8047\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 179us/step - loss: 11.1327 - val_loss: 58.1179\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 212us/step - loss: 11.1462 - val_loss: 58.4599\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 369us/step - loss: 11.1047 - val_loss: 57.9805\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 256us/step - loss: 11.3506 - val_loss: 59.3270\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 196us/step - loss: 11.2224 - val_loss: 59.1907\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 174us/step - loss: 11.1357 - val_loss: 58.6438\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 299us/step - loss: 11.1100 - val_loss: 58.6451\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 340us/step - loss: 11.0865 - val_loss: 59.4275\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 237us/step - loss: 11.3296 - val_loss: 58.1103\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 206us/step - loss: 11.2164 - val_loss: 58.8855\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 176us/step - loss: 10.9905 - val_loss: 58.4082\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 245us/step - loss: 11.0211 - val_loss: 58.8671\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.0553 - val_loss: 58.3534\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.3290 - val_loss: 59.1244\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 132us/step - loss: 11.0666 - val_loss: 58.7444\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 140us/step - loss: 11.4641 - val_loss: 58.4549\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 11.3444 - val_loss: 58.9591\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 127us/step - loss: 11.2154 - val_loss: 58.6050\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2257 - val_loss: 58.8496\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4599 - val_loss: 58.8179\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.1345 - val_loss: 58.8787\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 97us/step - loss: 11.1346 - val_loss: 58.6142\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2226 - val_loss: 58.4603\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0491 - val_loss: 58.6849\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2339 - val_loss: 58.6870\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.0092 - val_loss: 58.2842\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9969 - val_loss: 58.5703\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2752 - val_loss: 59.5080\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.5289 - val_loss: 58.6304\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3121 - val_loss: 59.1666\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.2513 - val_loss: 58.1721\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.6918 - val_loss: 58.7279\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2310 - val_loss: 58.3201\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1509 - val_loss: 58.8487\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0846 - val_loss: 58.4819\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2208 - val_loss: 58.1990\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.0870 - val_loss: 58.7008\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1792 - val_loss: 57.8297\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2898 - val_loss: 59.2128\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4308 - val_loss: 59.6013\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3108 - val_loss: 58.4291\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2839 - val_loss: 58.6407\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1023 - val_loss: 58.5439\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 129us/step - loss: 11.1761 - val_loss: 59.6969\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.4219 - val_loss: 58.1635\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9084 - val_loss: 59.0143\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1099 - val_loss: 57.9767\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3789 - val_loss: 59.2739\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2617 - val_loss: 59.2739\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1239 - val_loss: 58.5694\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1776 - val_loss: 58.5285\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3641 - val_loss: 59.1955\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1551 - val_loss: 58.4370\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3253 - val_loss: 57.9416\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.4220 - val_loss: 58.9854\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3873 - val_loss: 58.8228\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.8551 - val_loss: 59.5321\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.6411 - val_loss: 58.3638\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1654 - val_loss: 59.2952\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0099 - val_loss: 58.3772\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1145 - val_loss: 59.1688\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.5855 - val_loss: 58.5342\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1044 - val_loss: 58.8260\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0734 - val_loss: 58.4093\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1688 - val_loss: 58.7257\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3646 - val_loss: 58.6076\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1677 - val_loss: 58.9370\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2508 - val_loss: 58.4614\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3704 - val_loss: 59.2261\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.7162 - val_loss: 58.2504\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3488 - val_loss: 58.0206\n",
      "\n",
      "Mean Squared Error for iteration39: 47.459901043855695\n",
      "\n",
      "Iteration:  40\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4590 - val_loss: 58.9286\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1797 - val_loss: 58.7432\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.1476 - val_loss: 59.1361\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3832 - val_loss: 58.6390\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2406 - val_loss: 57.9211\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.3856 - val_loss: 58.4478\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3769 - val_loss: 58.9476\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6069 - val_loss: 58.9415\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0725 - val_loss: 57.8578\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.0719 - val_loss: 58.6662\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2630 - val_loss: 59.0331\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4453 - val_loss: 58.9074\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2149 - val_loss: 58.2773\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0040 - val_loss: 57.9565\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0097 - val_loss: 58.7847\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3405 - val_loss: 57.9544\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0986 - val_loss: 58.4128\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0608 - val_loss: 57.5366\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2766 - val_loss: 58.8878\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2160 - val_loss: 58.5775\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.9414 - val_loss: 58.5318\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3786 - val_loss: 58.0149\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2371 - val_loss: 58.4064\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4447 - val_loss: 58.8155\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2059 - val_loss: 58.4748\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4307 - val_loss: 59.0951\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5662 - val_loss: 58.7735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1513 - val_loss: 58.3555\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0737 - val_loss: 58.4442\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1151 - val_loss: 58.2937\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1849 - val_loss: 58.6283\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0910 - val_loss: 58.1803\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1855 - val_loss: 58.2865\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0764 - val_loss: 59.4333\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5490 - val_loss: 59.5116\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6822 - val_loss: 58.2819\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5074 - val_loss: 58.0358\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9659 - val_loss: 58.4084\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0234 - val_loss: 58.0131\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2406 - val_loss: 59.0006\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0368 - val_loss: 58.1401\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1202 - val_loss: 58.7235\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3840 - val_loss: 58.6767\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6354 - val_loss: 58.0641\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3601 - val_loss: 59.0518\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1347 - val_loss: 58.2237\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1096 - val_loss: 58.4056\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1421 - val_loss: 58.7107\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1652 - val_loss: 58.5904\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4541 - val_loss: 58.3328\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3880 - val_loss: 58.1805\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0205 - val_loss: 58.9646\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1617 - val_loss: 58.2285\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1813 - val_loss: 58.5102\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.0355 - val_loss: 58.8494\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1777 - val_loss: 58.3213\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0571 - val_loss: 58.9383\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0994 - val_loss: 58.0256\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1471 - val_loss: 59.2842\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 230us/step - loss: 11.1505 - val_loss: 58.9395\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.7672 - val_loss: 59.1861\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5550 - val_loss: 58.6255\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2064 - val_loss: 58.2785\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5945 - val_loss: 59.0509\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.4647 - val_loss: 58.3539\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1295 - val_loss: 58.2198\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1620 - val_loss: 59.3090\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9976 - val_loss: 57.9738\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0891 - val_loss: 58.9013\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9904 - val_loss: 58.0002\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 182us/step - loss: 11.0357 - val_loss: 58.1290\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1496 - val_loss: 58.6411\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3117 - val_loss: 58.8683\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0554 - val_loss: 58.5315\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.1881 - val_loss: 58.4056\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.2238 - val_loss: 58.5833\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2973 - val_loss: 57.8902\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1481 - val_loss: 59.1930\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1852 - val_loss: 58.2670\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1392 - val_loss: 58.9663\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2987 - val_loss: 57.9386\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3302 - val_loss: 59.2797\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.5036 - val_loss: 58.5001\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0887 - val_loss: 58.6303\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1728 - val_loss: 58.9160\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2126 - val_loss: 58.1782\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 108us/step - loss: 11.2021 - val_loss: 58.5485\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2251 - val_loss: 58.4690\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2482 - val_loss: 59.1540\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1223 - val_loss: 57.7508\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1962 - val_loss: 58.6589\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6518 - val_loss: 58.8441\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3353 - val_loss: 58.0579\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3755 - val_loss: 59.2035\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2083 - val_loss: 58.3584\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2223 - val_loss: 58.3620\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1560 - val_loss: 58.6172\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0674 - val_loss: 59.0249\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1239 - val_loss: 58.5717\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1300 - val_loss: 58.9207\n",
      "\n",
      "Mean Squared Error for iteration40: 48.82177842129018\n",
      "\n",
      "Iteration:  41\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0648 - val_loss: 58.2358\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1395 - val_loss: 58.5224\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2106 - val_loss: 58.9678\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0697 - val_loss: 58.5275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1515 - val_loss: 58.6516\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0086 - val_loss: 58.5027\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2895 - val_loss: 58.6047\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2643 - val_loss: 58.4637\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3203 - val_loss: 58.6756\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1655 - val_loss: 58.7049\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9297 - val_loss: 58.2164\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 10.9014 - val_loss: 58.4074\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 10.9868 - val_loss: 58.5549\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2204 - val_loss: 58.7589\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1979 - val_loss: 58.4288\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2602 - val_loss: 58.2280\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4831 - val_loss: 58.9492\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0661 - val_loss: 58.5919\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0315 - val_loss: 59.3697\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 11.0661 - val_loss: 58.0573\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1600 - val_loss: 58.9235\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1960 - val_loss: 58.2907\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2205 - val_loss: 57.9935\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1567 - val_loss: 58.8251\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2550 - val_loss: 58.1269\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0543 - val_loss: 58.3694\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1512 - val_loss: 59.0994\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0352 - val_loss: 57.5475\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1409 - val_loss: 57.9077\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5516 - val_loss: 57.6417\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5473 - val_loss: 58.5325\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4370 - val_loss: 59.1390\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4921 - val_loss: 58.1907\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2114 - val_loss: 58.6375\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1085 - val_loss: 58.4349\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0138 - val_loss: 58.6567\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.2377 - val_loss: 58.8399\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1096 - val_loss: 58.2542\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2870 - val_loss: 58.2614\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0245 - val_loss: 58.9142\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1340 - val_loss: 58.5133\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0858 - val_loss: 58.4359\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 240us/step - loss: 11.2102 - val_loss: 58.0044\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 137us/step - loss: 11.0922 - val_loss: 58.8156\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2554 - val_loss: 58.3838\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 197us/step - loss: 11.1243 - val_loss: 58.5947\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 369us/step - loss: 11.2799 - val_loss: 58.8240\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 236us/step - loss: 11.0517 - val_loss: 58.5329\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2586 - val_loss: 58.0844\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2810 - val_loss: 59.0399\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0241 - val_loss: 58.0468\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0501 - val_loss: 58.2642\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1022 - val_loss: 58.6194\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3267 - val_loss: 58.7611\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1093 - val_loss: 58.9628\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2489 - val_loss: 58.4013\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2761 - val_loss: 59.3751\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2845 - val_loss: 58.4347\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0925 - val_loss: 58.9815\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.0588 - val_loss: 58.3944\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 145us/step - loss: 11.2336 - val_loss: 58.0117\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 173us/step - loss: 11.3417 - val_loss: 58.5753\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 156us/step - loss: 11.0924 - val_loss: 58.5204\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 176us/step - loss: 11.0388 - val_loss: 58.0100\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.3926 - val_loss: 60.0753\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0983 - val_loss: 57.6971\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1524 - val_loss: 58.8984\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1630 - val_loss: 58.4977\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3616 - val_loss: 58.2067\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2548 - val_loss: 58.6937\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3337 - val_loss: 58.2164\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1724 - val_loss: 58.5316\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3409 - val_loss: 58.3284\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0280 - val_loss: 57.8839\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1994 - val_loss: 58.8649\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 123us/step - loss: 11.3652 - val_loss: 58.2433\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0559 - val_loss: 58.3986\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1174 - val_loss: 58.1917\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1061 - val_loss: 58.7673\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2920 - val_loss: 58.3642\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5708 - val_loss: 58.1685\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3714 - val_loss: 58.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.2790 - val_loss: 58.0428\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3298 - val_loss: 58.3746\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0783 - val_loss: 58.2528\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0751 - val_loss: 58.0835\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2203 - val_loss: 58.2739\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0299 - val_loss: 58.6438\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2593 - val_loss: 58.5214\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2579 - val_loss: 58.4492\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4050 - val_loss: 58.1631\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3879 - val_loss: 58.7687\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.4956 - val_loss: 58.1672\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2288 - val_loss: 58.6457\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0920 - val_loss: 58.1793\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0798 - val_loss: 59.6716\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4418 - val_loss: 58.0973\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3406 - val_loss: 58.4956\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3199 - val_loss: 58.6680\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6115 - val_loss: 58.6179\n",
      "\n",
      "Mean Squared Error for iteration41: 47.67149231241434\n",
      "\n",
      "Iteration:  42\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1639 - val_loss: 58.6174\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 10.9014 - val_loss: 58.8061\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2625 - val_loss: 58.6961\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5077 - val_loss: 58.3759\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3805 - val_loss: 58.0341\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0744 - val_loss: 58.5143\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1653 - val_loss: 58.1875\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9746 - val_loss: 58.2152\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1943 - val_loss: 58.7381\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1632 - val_loss: 58.2408\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2318 - val_loss: 58.7678\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1044 - val_loss: 57.9151\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0850 - val_loss: 58.3148\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.0583 - val_loss: 58.8618\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1734 - val_loss: 58.7995\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4014 - val_loss: 58.4240\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9028 - val_loss: 58.3459\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0020 - val_loss: 58.6729\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0436 - val_loss: 58.1958\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0936 - val_loss: 58.8057\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0757 - val_loss: 58.3479\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1877 - val_loss: 59.1608\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2966 - val_loss: 58.9052\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1927 - val_loss: 59.0332\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1276 - val_loss: 58.1499\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5090 - val_loss: 58.7959\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3639 - val_loss: 58.5191\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.0261 - val_loss: 58.7135\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0051 - val_loss: 58.3483\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0865 - val_loss: 58.1483\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2560 - val_loss: 58.8216\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1627 - val_loss: 58.3095\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1239 - val_loss: 58.4433\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4462 - val_loss: 59.1977\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0848 - val_loss: 58.1574\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0367 - val_loss: 58.3653\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1732 - val_loss: 58.1410\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3033 - val_loss: 58.2129\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0951 - val_loss: 58.6132\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0477 - val_loss: 58.6696\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.8238 - val_loss: 58.9724\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0923 - val_loss: 58.1390\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5032 - val_loss: 60.0166\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5207 - val_loss: 58.5706\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0745 - val_loss: 58.2103\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1842 - val_loss: 59.5002\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4459 - val_loss: 58.1080\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1990 - val_loss: 58.2785\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2435 - val_loss: 58.3212\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0878 - val_loss: 57.8755\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3207 - val_loss: 59.1634\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 119us/step - loss: 11.0515 - val_loss: 58.7108\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0426 - val_loss: 58.2444\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0304 - val_loss: 58.6970\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1127 - val_loss: 58.4372\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.8839 - val_loss: 58.7299\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9980 - val_loss: 58.3336\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1924 - val_loss: 58.2932\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4800 - val_loss: 59.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1601 - val_loss: 57.9850\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2063 - val_loss: 58.7839\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3772 - val_loss: 59.8879\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2288 - val_loss: 58.0036\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9740 - val_loss: 58.6195\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3061 - val_loss: 57.9225\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0872 - val_loss: 58.3565\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0848 - val_loss: 58.2189\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9664 - val_loss: 58.5266\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0597 - val_loss: 58.1769\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1389 - val_loss: 58.3804\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1609 - val_loss: 58.2575\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1202 - val_loss: 58.2693\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1278 - val_loss: 58.5047\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2506 - val_loss: 58.3993\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2514 - val_loss: 59.0722\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4562 - val_loss: 59.2073\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.0652 - val_loss: 58.3712\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1568 - val_loss: 58.3255\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2419 - val_loss: 58.7132\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1288 - val_loss: 58.8428\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2075 - val_loss: 57.7769\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1557 - val_loss: 59.2418\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3260 - val_loss: 58.4517\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2769 - val_loss: 58.6270\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1682 - val_loss: 58.2862\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 10.9195 - val_loss: 59.1042\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 164us/step - loss: 11.0943 - val_loss: 58.1211\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 252us/step - loss: 10.9413 - val_loss: 58.6487\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1207 - val_loss: 58.9613\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0602 - val_loss: 58.7038\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0867 - val_loss: 58.2069\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1306 - val_loss: 58.8670\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.8080 - val_loss: 58.5716\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5863 - val_loss: 58.8761\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1517 - val_loss: 58.5251\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3480 - val_loss: 58.1105\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4420 - val_loss: 58.7719\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9837 - val_loss: 58.3293\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0126 - val_loss: 58.2025\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0323 - val_loss: 58.1895\n",
      "\n",
      "Mean Squared Error for iteration42: 47.68827986239594\n",
      "\n",
      "Iteration:  43\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1109 - val_loss: 58.7082\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.7828 - val_loss: 59.2668\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2146 - val_loss: 59.2697\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0931 - val_loss: 58.8821\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1632 - val_loss: 58.6088\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1416 - val_loss: 58.6858\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9482 - val_loss: 58.4447\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 10.9587 - val_loss: 58.9872\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 10.9501 - val_loss: 58.8245\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.6192 - val_loss: 58.2049\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4093 - val_loss: 58.1007\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2357 - val_loss: 59.3406\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3546 - val_loss: 58.8108\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2279 - val_loss: 58.7319\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2100 - val_loss: 58.2495\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0361 - val_loss: 58.4444\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0347 - val_loss: 58.3974\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3328 - val_loss: 58.6534\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1051 - val_loss: 58.6606\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1149 - val_loss: 57.9902\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0836 - val_loss: 58.7081\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9475 - val_loss: 58.5729\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2612 - val_loss: 58.8824\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4441 - val_loss: 58.4470\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 107us/step - loss: 11.6024 - val_loss: 58.5791\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2504 - val_loss: 59.5553\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4943 - val_loss: 59.1427\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0965 - val_loss: 57.9352\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1715 - val_loss: 58.7716\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2644 - val_loss: 57.9017\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0839 - val_loss: 58.7427\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.3122 - val_loss: 58.7300\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2637 - val_loss: 58.3584\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.5364 - val_loss: 59.1341\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2888 - val_loss: 58.1844\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1211 - val_loss: 58.7174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4237 - val_loss: 58.8373\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1634 - val_loss: 58.0467\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1977 - val_loss: 59.2714\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5452 - val_loss: 58.5280\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2705 - val_loss: 58.6528\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5245 - val_loss: 58.4707\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2303 - val_loss: 57.7048\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0510 - val_loss: 58.6242\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0728 - val_loss: 58.6427\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3942 - val_loss: 58.2900\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1736 - val_loss: 58.4677\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1758 - val_loss: 58.8974\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1328 - val_loss: 58.4777\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0082 - val_loss: 58.2226\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1214 - val_loss: 58.6234\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1863 - val_loss: 58.0873\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0823 - val_loss: 59.2015\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2444 - val_loss: 57.5125\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1445 - val_loss: 59.4182\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3262 - val_loss: 58.8459\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2627 - val_loss: 58.5294\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4986 - val_loss: 58.6194\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2035 - val_loss: 58.4704\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1064 - val_loss: 59.1539\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0747 - val_loss: 58.2924\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0617 - val_loss: 58.4603\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.5217 - val_loss: 58.0370\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0602 - val_loss: 59.3298\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0776 - val_loss: 58.4404\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2324 - val_loss: 59.0827\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4532 - val_loss: 58.3986\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1872 - val_loss: 59.0974\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1149 - val_loss: 57.9973\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2344 - val_loss: 58.5811\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1555 - val_loss: 57.8686\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.8917 - val_loss: 58.7461\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2355 - val_loss: 58.6722\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2464 - val_loss: 58.0167\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - ETA: 0s - loss: 11.65 - 0s 87us/step - loss: 11.1358 - val_loss: 58.2125\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4386 - val_loss: 59.1548\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2677 - val_loss: 58.0083\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5403 - val_loss: 58.7446\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 143us/step - loss: 11.6652 - val_loss: 59.1123\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 180us/step - loss: 11.7385 - val_loss: 58.7857\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 153us/step - loss: 11.2384 - val_loss: 58.8013\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 177us/step - loss: 11.1345 - val_loss: 58.3979\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 151us/step - loss: 11.1174 - val_loss: 59.1033\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 135us/step - loss: 10.9778 - val_loss: 58.3048\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0965 - val_loss: 58.2896\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1866 - val_loss: 58.3166\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2744 - val_loss: 58.9661\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1842 - val_loss: 58.5406\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3199 - val_loss: 58.6956\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3103 - val_loss: 59.8783\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.9588 - val_loss: 58.1361\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1913 - val_loss: 58.4577\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0533 - val_loss: 59.0137\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3182 - val_loss: 58.4746\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3518 - val_loss: 59.1009\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3851 - val_loss: 59.3265\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 120us/step - loss: 11.6120 - val_loss: 58.3348\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2730 - val_loss: 58.5655\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.4039 - val_loss: 59.0264\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1285 - val_loss: 57.9060\n",
      "\n",
      "Mean Squared Error for iteration43: 47.738131875745246\n",
      "\n",
      "Iteration:  44\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3774 - val_loss: 59.4148\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9119 - val_loss: 57.5172\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.1152 - val_loss: 58.4424\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0105 - val_loss: 58.2644\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0717 - val_loss: 58.3852\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1910 - val_loss: 58.1528\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0448 - val_loss: 58.7901\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9568 - val_loss: 58.2180\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5599 - val_loss: 58.4706\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.2434 - val_loss: 58.3449\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0961 - val_loss: 58.3253\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9867 - val_loss: 58.5941\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 87us/step - loss: 11.1161 - val_loss: 58.5497\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1957 - val_loss: 58.3497\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9788 - val_loss: 58.3402\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1034 - val_loss: 58.3973\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0462 - val_loss: 58.3502\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.4607 - val_loss: 58.7810\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2993 - val_loss: 58.3862\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1994 - val_loss: 58.6078\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0829 - val_loss: 58.3786\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2197 - val_loss: 58.9239\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2504 - val_loss: 59.0114\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 10.9827 - val_loss: 58.2505\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.7133 - val_loss: 58.0030\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4063 - val_loss: 58.8038\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2394 - val_loss: 59.1409\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1606 - val_loss: 58.7401\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0373 - val_loss: 58.0064\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0950 - val_loss: 58.3321\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1260 - val_loss: 58.7237\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1558 - val_loss: 57.7604\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0424 - val_loss: 58.6830\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1087 - val_loss: 58.8855\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.2837 - val_loss: 58.4420\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0385 - val_loss: 58.4556\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.0522 - val_loss: 58.4768\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2308 - val_loss: 58.2673\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0075 - val_loss: 58.9295\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9755 - val_loss: 58.1847\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0179 - val_loss: 58.5651\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.3660 - val_loss: 59.1112\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3387 - val_loss: 58.2001\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3986 - val_loss: 59.0678\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2384 - val_loss: 58.7182\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1956 - val_loss: 59.3210\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0354 - val_loss: 57.8453\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2225 - val_loss: 58.5523\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1647 - val_loss: 58.8906\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0931 - val_loss: 58.5796\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2748 - val_loss: 58.1584\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3062 - val_loss: 59.1569\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4190 - val_loss: 58.5576\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1212 - val_loss: 58.4831\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1405 - val_loss: 58.2832\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 10.9934 - val_loss: 58.7150\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2218 - val_loss: 58.3433\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2413 - val_loss: 58.7489\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1968 - val_loss: 58.4908\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.5188 - val_loss: 58.8098\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2191 - val_loss: 57.9078\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9975 - val_loss: 60.0566\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3010 - val_loss: 58.4484\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4076 - val_loss: 58.7009\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2079 - val_loss: 58.2357\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2630 - val_loss: 59.5208\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0718 - val_loss: 57.5160\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1128 - val_loss: 59.0128\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3115 - val_loss: 58.5189\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2368 - val_loss: 59.2924\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3668 - val_loss: 57.3234\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3223 - val_loss: 58.7653\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.0407 - val_loss: 58.6706\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1607 - val_loss: 58.3233\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3100 - val_loss: 58.6432\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3642 - val_loss: 58.2400\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0606 - val_loss: 58.4609\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2510 - val_loss: 57.7429\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2619 - val_loss: 58.9065\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1990 - val_loss: 58.3259\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0119 - val_loss: 58.0906\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0023 - val_loss: 58.1747\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 10.8823 - val_loss: 58.9386\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 144us/step - loss: 11.1390 - val_loss: 57.8273\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 184us/step - loss: 11.2820 - val_loss: 59.2788\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 136us/step - loss: 12.0578 - val_loss: 57.8158\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1822 - val_loss: 58.5566\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0317 - val_loss: 57.9879\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2569 - val_loss: 58.6464\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1482 - val_loss: 58.5850\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 95us/step - loss: 11.1193 - val_loss: 58.8460\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1639 - val_loss: 57.4605\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2511 - val_loss: 59.2728\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2598 - val_loss: 58.5533\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3305 - val_loss: 58.0296\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.2280 - val_loss: 59.8177\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3371 - val_loss: 58.2913\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3690 - val_loss: 58.9627\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 144us/step - loss: 11.4406 - val_loss: 58.4620\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.2186 - val_loss: 58.9320\n",
      "\n",
      "Mean Squared Error for iteration44: 47.65682032407344\n",
      "\n",
      "Iteration:  45\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5218 - val_loss: 58.5134\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1356 - val_loss: 58.1126\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1652 - val_loss: 58.3856\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0382 - val_loss: 58.7331\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2343 - val_loss: 58.8459\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0506 - val_loss: 58.5103\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.1318 - val_loss: 58.7255\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9274 - val_loss: 58.9658\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4293 - val_loss: 58.1477\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3460 - val_loss: 57.6632\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2738 - val_loss: 59.0749\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9910 - val_loss: 58.2428\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0780 - val_loss: 58.0329\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 111us/step - loss: 11.0608 - val_loss: 58.9810\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1163 - val_loss: 58.2586\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1121 - val_loss: 58.5240\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2151 - val_loss: 57.5287\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2341 - val_loss: 58.8792\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0485 - val_loss: 57.9230\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.5165 - val_loss: 58.1789\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4016 - val_loss: 58.1796\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2199 - val_loss: 58.6784\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4653 - val_loss: 58.0056\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1500 - val_loss: 59.0214\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2028 - val_loss: 58.4116\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1084 - val_loss: 58.3163\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2670 - val_loss: 58.0985\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2802 - val_loss: 58.4831\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2853 - val_loss: 58.7883\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3729 - val_loss: 58.7235\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3379 - val_loss: 59.0516\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1262 - val_loss: 58.3526\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.0698 - val_loss: 58.5588\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2746 - val_loss: 58.3973\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9766 - val_loss: 58.5872\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1766 - val_loss: 58.4456\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2489 - val_loss: 58.5198\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2613 - val_loss: 58.8189\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5738 - val_loss: 59.0562\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0595 - val_loss: 58.0335\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0269 - val_loss: 58.7134\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0702 - val_loss: 58.3197\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9927 - val_loss: 58.6628\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1199 - val_loss: 58.4703\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 122us/step - loss: 11.0984 - val_loss: 58.6426\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0918 - val_loss: 59.0967\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.7016 - val_loss: 58.8592\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.8280 - val_loss: 58.7996\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9979 - val_loss: 58.5282\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2733 - val_loss: 57.9898\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0932 - val_loss: 58.5411\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2256 - val_loss: 58.1402\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1771 - val_loss: 58.8509\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0578 - val_loss: 58.3745\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0572 - val_loss: 58.6838\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9066 - val_loss: 58.2677\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9816 - val_loss: 58.4102\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0269 - val_loss: 58.2131\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0949 - val_loss: 58.8660\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 10.9574 - val_loss: 58.3904\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1822 - val_loss: 58.4191\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5414 - val_loss: 57.9269\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1956 - val_loss: 58.6452\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2209 - val_loss: 58.8132\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0312 - val_loss: 58.1194\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1348 - val_loss: 58.2752\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.5272 - val_loss: 58.6929\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 88us/step - loss: 11.3552 - val_loss: 58.4341\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5253 - val_loss: 57.8160\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.2392 - val_loss: 58.7930\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1455 - val_loss: 58.5810\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1594 - val_loss: 58.1172\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.6106 - val_loss: 59.0774\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1443 - val_loss: 58.3104\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0391 - val_loss: 57.6834\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9927 - val_loss: 58.5580\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0509 - val_loss: 58.3324\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1654 - val_loss: 58.8308\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1925 - val_loss: 58.1643\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0094 - val_loss: 58.5364\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4745 - val_loss: 58.4782\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1319 - val_loss: 59.0799\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2933 - val_loss: 57.2092\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2861 - val_loss: 58.9603\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0606 - val_loss: 57.6542\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1240 - val_loss: 58.4984\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0287 - val_loss: 58.5491\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3216 - val_loss: 58.5423\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3941 - val_loss: 58.2164\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.3392 - val_loss: 58.9039\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 12.2569 - val_loss: 57.5225\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4807 - val_loss: 58.4939\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1695 - val_loss: 58.6771\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4837 - val_loss: 58.5438\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2912 - val_loss: 57.6674\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0771 - val_loss: 59.0809\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2461 - val_loss: 58.2640\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.6791 - val_loss: 57.9266\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0802 - val_loss: 58.6462\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.0094 - val_loss: 59.0017\n",
      "\n",
      "Mean Squared Error for iteration45: 49.077867887099906\n",
      "\n",
      "Iteration:  46\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5205 - val_loss: 58.5759\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2836 - val_loss: 59.3321\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 10.9579 - val_loss: 58.1440\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0780 - val_loss: 58.8985\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2773 - val_loss: 58.9440\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1416 - val_loss: 58.3121\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0704 - val_loss: 57.5389\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 254us/step - loss: 11.0350 - val_loss: 59.2794\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1202 - val_loss: 58.6697\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 10.9803 - val_loss: 58.5978\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.9103 - val_loss: 58.7292\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4880 - val_loss: 57.9162\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1511 - val_loss: 58.3950\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0702 - val_loss: 58.4920\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9522 - val_loss: 59.0983\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2846 - val_loss: 58.7431\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.0554 - val_loss: 58.4058\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.2945 - val_loss: 58.5169\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2439 - val_loss: 58.3950\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9692 - val_loss: 58.1558\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0350 - val_loss: 58.9780\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 10.9645 - val_loss: 58.1073\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2580 - val_loss: 58.5438\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4302 - val_loss: 59.3197\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.8181 - val_loss: 57.8083\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1704 - val_loss: 58.6660\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9927 - val_loss: 58.8815\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 10.9295 - val_loss: 58.1987\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1687 - val_loss: 58.4049\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0527 - val_loss: 59.0811\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 109us/step - loss: 11.5139 - val_loss: 59.3203\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3120 - val_loss: 58.0795\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2538 - val_loss: 58.9478\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5099 - val_loss: 58.1399\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1051 - val_loss: 58.3589\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0092 - val_loss: 58.6451\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2355 - val_loss: 58.3299\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 12.0133 - val_loss: 59.2299\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1124 - val_loss: 57.7608\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4462 - val_loss: 58.4101\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.0622 - val_loss: 58.5058\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3212 - val_loss: 58.8499\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1756 - val_loss: 58.9076\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2714 - val_loss: 57.7877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5141 - val_loss: 58.4507\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3740 - val_loss: 58.8789\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2297 - val_loss: 58.5126\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1172 - val_loss: 58.8465\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1242 - val_loss: 57.7431\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0696 - val_loss: 58.5334\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 10.9720 - val_loss: 58.5790\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1466 - val_loss: 58.7663\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3449 - val_loss: 57.5761\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0531 - val_loss: 58.9697\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 124us/step - loss: 11.1794 - val_loss: 58.4641\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9677 - val_loss: 58.8562\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1917 - val_loss: 59.0212\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9736 - val_loss: 58.3999\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.0549 - val_loss: 58.1994\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1287 - val_loss: 59.0684\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2607 - val_loss: 58.5108\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4818 - val_loss: 59.9291\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1753 - val_loss: 58.3108\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 117us/step - loss: 11.3417 - val_loss: 58.0435\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3690 - val_loss: 58.6905\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0998 - val_loss: 58.6823\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2198 - val_loss: 58.1925\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.6077 - val_loss: 60.6088\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.7128 - val_loss: 58.7726\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2362 - val_loss: 58.2313\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1110 - val_loss: 58.9394\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1070 - val_loss: 58.2084\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.5496 - val_loss: 59.3102\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3227 - val_loss: 58.2639\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0408 - val_loss: 58.9649\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0276 - val_loss: 59.6975\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.8371 - val_loss: 58.9445\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5929 - val_loss: 57.9091\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.2910 - val_loss: 59.0233\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3782 - val_loss: 58.3293\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4562 - val_loss: 57.9936\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1453 - val_loss: 58.7111\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1602 - val_loss: 58.2392\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0082 - val_loss: 58.5097\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1452 - val_loss: 58.7241\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3994 - val_loss: 59.3032\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1041 - val_loss: 57.9133\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 172us/step - loss: 11.1204 - val_loss: 58.7438\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 180us/step - loss: 10.9054 - val_loss: 58.8463\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 204us/step - loss: 11.2335 - val_loss: 57.9407\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.0531 - val_loss: 58.8766\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1308 - val_loss: 58.7735\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0646 - val_loss: 58.4098\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1881 - val_loss: 58.6567\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0620 - val_loss: 58.2227\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.5165 - val_loss: 59.3028\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4495 - val_loss: 59.1840\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.7009 - val_loss: 58.4329\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0722 - val_loss: 58.8042\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0561 - val_loss: 58.5732\n",
      "\n",
      "Mean Squared Error for iteration46: 47.94584683186005\n",
      "\n",
      "Iteration:  47\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2098 - val_loss: 58.1565\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.3246 - val_loss: 58.9836\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 271us/step - loss: 11.3922 - val_loss: 58.3907\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 157us/step - loss: 11.3693 - val_loss: 58.8864\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0229 - val_loss: 57.9277\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2105 - val_loss: 58.3909\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.2775 - val_loss: 58.5385\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3045 - val_loss: 58.2573\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1478 - val_loss: 58.8462\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.8300 - val_loss: 58.9378\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.3754 - val_loss: 59.5536\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5155 - val_loss: 58.7091\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1466 - val_loss: 59.0065\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.5296 - val_loss: 57.9562\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 179us/step - loss: 11.1902 - val_loss: 58.3424\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 279us/step - loss: 11.0970 - val_loss: 58.5601\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 161us/step - loss: 11.1684 - val_loss: 57.6746\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.2202 - val_loss: 58.4842\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 10.9758 - val_loss: 58.2582\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.0047 - val_loss: 58.7079\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1430 - val_loss: 58.3160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0431 - val_loss: 58.8351\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1375 - val_loss: 59.1514\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4604 - val_loss: 57.7257\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2741 - val_loss: 59.5066\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1490 - val_loss: 57.9835\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.4248 - val_loss: 59.1587\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1454 - val_loss: 58.4026\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 10.9881 - val_loss: 59.1787\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.9553 - val_loss: 58.0064\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0672 - val_loss: 58.1996\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4753 - val_loss: 59.2406\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3278 - val_loss: 58.3502\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0246 - val_loss: 58.2917\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0873 - val_loss: 58.8309\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1835 - val_loss: 58.2069\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2689 - val_loss: 59.3438\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1944 - val_loss: 58.3953\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3060 - val_loss: 58.9768\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1622 - val_loss: 58.3072\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2706 - val_loss: 58.3928\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1257 - val_loss: 58.6638\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1363 - val_loss: 58.2115\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 10.9385 - val_loss: 58.4003\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1276 - val_loss: 58.2436\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0256 - val_loss: 59.0202\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0631 - val_loss: 57.9009\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1562 - val_loss: 58.1461\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 10.9905 - val_loss: 58.6067\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0726 - val_loss: 58.2360\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1676 - val_loss: 59.6994\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9775 - val_loss: 58.2440\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0664 - val_loss: 58.7444\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1366 - val_loss: 58.4343\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0154 - val_loss: 58.3568\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1814 - val_loss: 58.4566\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.1814 - val_loss: 58.2720\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.3413 - val_loss: 58.2516\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0624 - val_loss: 59.8319\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.6462 - val_loss: 58.3619\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9611 - val_loss: 58.1176\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1682 - val_loss: 58.4870\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.1579 - val_loss: 58.4289\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1230 - val_loss: 58.3486\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1069 - val_loss: 58.8432\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1931 - val_loss: 58.7169\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2126 - val_loss: 58.0738\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2207 - val_loss: 58.9242\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1741 - val_loss: 58.5840\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0503 - val_loss: 58.8291\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.1420 - val_loss: 58.1583\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0824 - val_loss: 58.6477\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3205 - val_loss: 57.9941\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1041 - val_loss: 58.2817\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0124 - val_loss: 58.5357\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2449 - val_loss: 58.5734\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1338 - val_loss: 57.9853\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0648 - val_loss: 58.2684\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5960 - val_loss: 58.6043\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.5681 - val_loss: 58.2485\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9360 - val_loss: 58.1167\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2877 - val_loss: 58.7503\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1202 - val_loss: 59.1139\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.4619 - val_loss: 58.4167\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.1525 - val_loss: 58.2858\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.7667 - val_loss: 58.8643\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1346 - val_loss: 58.4434\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1246 - val_loss: 58.5635\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2263 - val_loss: 58.5491\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3301 - val_loss: 58.8348\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0943 - val_loss: 58.0412\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1621 - val_loss: 58.8280\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0807 - val_loss: 59.1153\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0878 - val_loss: 58.2223\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.2495 - val_loss: 58.5313\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0984 - val_loss: 58.7002\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0943 - val_loss: 58.6526\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1139 - val_loss: 58.3443\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0764 - val_loss: 58.4763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1247 - val_loss: 58.9393\n",
      "\n",
      "Mean Squared Error for iteration47: 48.38279273993039\n",
      "\n",
      "Iteration:  48\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1207 - val_loss: 58.1294\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1695 - val_loss: 58.5960\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1030 - val_loss: 58.4297\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 10.9602 - val_loss: 58.3835\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 10.9438 - val_loss: 58.1395\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 223us/step - loss: 11.1188 - val_loss: 59.0265\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0311 - val_loss: 57.7063\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0454 - val_loss: 58.1053\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 112us/step - loss: 11.1154 - val_loss: 58.9894\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 189us/step - loss: 11.2455 - val_loss: 58.2986\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 217us/step - loss: 11.0254 - val_loss: 58.9765\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 200us/step - loss: 10.9534 - val_loss: 57.9886\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 146us/step - loss: 11.0813 - val_loss: 58.8402\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3220 - val_loss: 57.6265\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3555 - val_loss: 59.6180\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2229 - val_loss: 58.2885\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5562 - val_loss: 58.5861\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0716 - val_loss: 58.0388\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.0432 - val_loss: 59.9468\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2852 - val_loss: 57.7966\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2152 - val_loss: 58.1116\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2138 - val_loss: 58.8475\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 11.2407 - val_loss: 59.0493\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1157 - val_loss: 57.9398\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.0620 - val_loss: 57.8877\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 131us/step - loss: 11.2393 - val_loss: 58.3630\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0586 - val_loss: 58.8103\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4284 - val_loss: 57.7737\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1423 - val_loss: 59.0574\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0422 - val_loss: 58.2215\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0940 - val_loss: 58.4812\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0193 - val_loss: 58.1954\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1151 - val_loss: 58.3346\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1620 - val_loss: 58.9226\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1432 - val_loss: 58.2908\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2353 - val_loss: 58.5875\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1208 - val_loss: 59.1286\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0545 - val_loss: 58.3483\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9551 - val_loss: 58.9287\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4231 - val_loss: 58.0980\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0347 - val_loss: 58.4890\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2572 - val_loss: 58.2329\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9660 - val_loss: 58.1397\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 10.9678 - val_loss: 58.7241\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.5439 - val_loss: 58.1153\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1837 - val_loss: 58.5705\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.7337 - val_loss: 58.2894\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1882 - val_loss: 58.7042\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3281 - val_loss: 58.6285\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1156 - val_loss: 59.1054\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2138 - val_loss: 57.9641\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.4168 - val_loss: 58.8542\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1195 - val_loss: 57.9713\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0745 - val_loss: 59.1025\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0850 - val_loss: 58.5471\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1749 - val_loss: 58.6747\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2897 - val_loss: 58.1969\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9442 - val_loss: 58.5198\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.0122 - val_loss: 58.7731\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.4348 - val_loss: 58.4957\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3789 - val_loss: 58.2166\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2230 - val_loss: 59.1288\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.1325 - val_loss: 58.5635\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.0181 - val_loss: 58.6756\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1965 - val_loss: 57.8266\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1291 - val_loss: 59.1589\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1424 - val_loss: 58.6613\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1317 - val_loss: 57.9607\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.2122 - val_loss: 59.1261\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.6080 - val_loss: 58.2715\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4989 - val_loss: 58.5434\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2559 - val_loss: 58.6687\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1759 - val_loss: 58.4760\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3596 - val_loss: 59.7081\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3211 - val_loss: 57.9219\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4577 - val_loss: 59.2916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0891 - val_loss: 58.2387\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 10.9207 - val_loss: 58.3918\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1053 - val_loss: 59.0717\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.2186 - val_loss: 58.2384\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2076 - val_loss: 58.8604\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2723 - val_loss: 58.6693\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.8858 - val_loss: 58.5115\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2723 - val_loss: 58.7356\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2509 - val_loss: 58.5216\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 11.2529 - val_loss: 58.9665\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0505 - val_loss: 58.4620\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0292 - val_loss: 58.7245\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3369 - val_loss: 58.3836\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.1063 - val_loss: 58.8182\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1795 - val_loss: 58.1017\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0130 - val_loss: 58.6273\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0478 - val_loss: 58.5275\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1161 - val_loss: 58.2690\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1727 - val_loss: 59.2616\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1952 - val_loss: 57.8610\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1185 - val_loss: 58.7219\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 10.9094 - val_loss: 58.0282\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 10.9924 - val_loss: 58.8386\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0808 - val_loss: 58.9722\n",
      "\n",
      "Mean Squared Error for iteration48: 49.30491181259071\n",
      "\n",
      "Iteration:  49\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 10.8954 - val_loss: 59.6343\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 106us/step - loss: 11.1923 - val_loss: 58.6225\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 10.9060 - val_loss: 58.5473\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9895 - val_loss: 58.2146\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 10.9575 - val_loss: 58.2028\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9517 - val_loss: 58.4587\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1770 - val_loss: 58.5850\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0619 - val_loss: 58.4338\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.0629 - val_loss: 57.7732\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9990 - val_loss: 59.1406\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1206 - val_loss: 58.3858\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5031 - val_loss: 58.4503\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.5971 - val_loss: 58.8293\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2112 - val_loss: 58.5798\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0337 - val_loss: 58.5615\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0987 - val_loss: 58.5160\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0661 - val_loss: 58.3179\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0797 - val_loss: 59.4689\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5391 - val_loss: 58.1359\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2823 - val_loss: 59.2868\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.2569 - val_loss: 58.6059\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0944 - val_loss: 58.1604\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3493 - val_loss: 58.5216\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0720 - val_loss: 58.7796\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1040 - val_loss: 58.8597\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1125 - val_loss: 58.5544\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.3570 - val_loss: 58.8831\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2899 - val_loss: 58.5343\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3284 - val_loss: 58.9918\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3705 - val_loss: 60.4997\n",
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4252 - val_loss: 58.5106\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.5993 - val_loss: 57.9534\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0743 - val_loss: 59.0028\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9150 - val_loss: 58.2563\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9886 - val_loss: 58.6728\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2372 - val_loss: 57.8755\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9997 - val_loss: 59.2030\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2550 - val_loss: 57.9364\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1173 - val_loss: 59.0375\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 116us/step - loss: 11.0604 - val_loss: 58.3869\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.0441 - val_loss: 58.5027\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0506 - val_loss: 58.5925\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1598 - val_loss: 57.5172\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4308 - val_loss: 59.4280\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3190 - val_loss: 59.4918\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4915 - val_loss: 58.2578\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 100us/step - loss: 11.1514 - val_loss: 58.0195\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1003 - val_loss: 58.2991\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1014 - val_loss: 58.5596\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0304 - val_loss: 58.1022\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1959 - val_loss: 58.8045\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 11.0122 - val_loss: 58.3770\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 97us/step - loss: 11.1622 - val_loss: 58.9326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2729 - val_loss: 57.7893\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0690 - val_loss: 58.6097\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9878 - val_loss: 58.6345\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.5686 - val_loss: 59.2815\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1954 - val_loss: 58.2496\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3490 - val_loss: 59.5747\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2281 - val_loss: 58.4723\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0295 - val_loss: 58.4662\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1479 - val_loss: 58.2326\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2487 - val_loss: 58.5344\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1379 - val_loss: 58.1629\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2505 - val_loss: 59.0049\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.1789 - val_loss: 58.0197\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3472 - val_loss: 58.7306\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0588 - val_loss: 58.3385\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.8753 - val_loss: 58.7631\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.7105 - val_loss: 59.2098\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9988 - val_loss: 57.8856\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1551 - val_loss: 58.2333\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.1748 - val_loss: 59.1633\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0156 - val_loss: 58.1107\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4104 - val_loss: 58.5865\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2524 - val_loss: 58.9503\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1342 - val_loss: 57.8399\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 126us/step - loss: 11.8390 - val_loss: 58.3493\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.4938 - val_loss: 59.3504\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1775 - val_loss: 58.0016\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.4605 - val_loss: 58.9923\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2765 - val_loss: 58.7509\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.3882 - val_loss: 58.6983\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2724 - val_loss: 58.4174\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.2354 - val_loss: 58.5635\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2824 - val_loss: 59.1019\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2804 - val_loss: 58.5913\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0268 - val_loss: 58.8071\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2714 - val_loss: 58.9939\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1626 - val_loss: 58.6723\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0206 - val_loss: 58.1120\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0727 - val_loss: 58.6297\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.1534 - val_loss: 58.1103\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0760 - val_loss: 58.7207\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2403 - val_loss: 58.6944\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.0260 - val_loss: 58.2041\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 92us/step - loss: 10.9864 - val_loss: 58.7907\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 10.9860 - val_loss: 57.9073\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 10.9957 - val_loss: 59.0510\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 10.9708 - val_loss: 58.3740\n",
      "\n",
      "Mean Squared Error for iteration49: 48.62345924526684\n",
      "\n",
      "Iteration:  50\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0084 - val_loss: 59.1510\n",
      "Epoch 2/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3630 - val_loss: 57.5637\n",
      "Epoch 3/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2715 - val_loss: 58.1608\n",
      "Epoch 4/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 10.9658 - val_loss: 57.9075\n",
      "Epoch 5/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.9976 - val_loss: 58.8309\n",
      "Epoch 6/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2548 - val_loss: 58.4281\n",
      "Epoch 7/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4125 - val_loss: 58.4425\n",
      "Epoch 8/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0020 - val_loss: 58.7028\n",
      "Epoch 9/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.3720 - val_loss: 58.3562\n",
      "Epoch 10/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2080 - val_loss: 59.2386\n",
      "Epoch 11/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9987 - val_loss: 58.3281\n",
      "Epoch 12/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0051 - val_loss: 58.3559\n",
      "Epoch 13/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.3279 - val_loss: 58.9374\n",
      "Epoch 14/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0848 - val_loss: 57.9384\n",
      "Epoch 15/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 10.9322 - val_loss: 58.4665\n",
      "Epoch 16/100\n",
      "576/576 [==============================] - 0s 114us/step - loss: 11.0265 - val_loss: 57.9571\n",
      "Epoch 17/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0390 - val_loss: 58.6333\n",
      "Epoch 18/100\n",
      "576/576 [==============================] - 0s 105us/step - loss: 11.2067 - val_loss: 58.4667\n",
      "Epoch 19/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.2689 - val_loss: 59.1747\n",
      "Epoch 20/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.2594 - val_loss: 58.4305\n",
      "Epoch 21/100\n",
      "576/576 [==============================] - 0s 148us/step - loss: 11.1022 - val_loss: 58.6340\n",
      "Epoch 22/100\n",
      "576/576 [==============================] - 0s 113us/step - loss: 10.9876 - val_loss: 57.9807\n",
      "Epoch 23/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.2641 - val_loss: 58.9246\n",
      "Epoch 24/100\n",
      "576/576 [==============================] - 0s 102us/step - loss: 11.1891 - val_loss: 58.6394\n",
      "Epoch 25/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.1618 - val_loss: 58.2650\n",
      "Epoch 26/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.0736 - val_loss: 58.2104\n",
      "Epoch 27/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 10.9957 - val_loss: 58.5870\n",
      "Epoch 28/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.1454 - val_loss: 58.6748\n",
      "Epoch 29/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1691 - val_loss: 58.5273\n",
      "Epoch 30/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1522 - val_loss: 58.4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3673 - val_loss: 57.9089\n",
      "Epoch 32/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2474 - val_loss: 58.7394\n",
      "Epoch 33/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1703 - val_loss: 58.2384\n",
      "Epoch 34/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2347 - val_loss: 58.7044\n",
      "Epoch 35/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1623 - val_loss: 58.6669\n",
      "Epoch 36/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0945 - val_loss: 58.2053\n",
      "Epoch 37/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1392 - val_loss: 58.5747\n",
      "Epoch 38/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0344 - val_loss: 58.5060\n",
      "Epoch 39/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.2857 - val_loss: 58.0983\n",
      "Epoch 40/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0277 - val_loss: 58.1968\n",
      "Epoch 41/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1826 - val_loss: 58.2471\n",
      "Epoch 42/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1442 - val_loss: 58.2146\n",
      "Epoch 43/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0722 - val_loss: 58.1064\n",
      "Epoch 44/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2333 - val_loss: 59.2701\n",
      "Epoch 45/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.3963 - val_loss: 59.0628\n",
      "Epoch 46/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.2635 - val_loss: 57.9298\n",
      "Epoch 47/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0842 - val_loss: 58.6670\n",
      "Epoch 48/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.1096 - val_loss: 58.0555\n",
      "Epoch 49/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 10.9867 - val_loss: 58.7212\n",
      "Epoch 50/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1339 - val_loss: 58.0207\n",
      "Epoch 51/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.1779 - val_loss: 58.6409\n",
      "Epoch 52/100\n",
      "576/576 [==============================] - 0s 115us/step - loss: 11.6455 - val_loss: 58.2778\n",
      "Epoch 53/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.3824 - val_loss: 58.4506\n",
      "Epoch 54/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.3016 - val_loss: 58.6482\n",
      "Epoch 55/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0607 - val_loss: 58.0258\n",
      "Epoch 56/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.0232 - val_loss: 58.5017\n",
      "Epoch 57/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.1046 - val_loss: 58.2409\n",
      "Epoch 58/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.1050 - val_loss: 58.8823\n",
      "Epoch 59/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1306 - val_loss: 58.8435\n",
      "Epoch 60/100\n",
      "576/576 [==============================] - 0s 85us/step - loss: 11.4576 - val_loss: 58.2936\n",
      "Epoch 61/100\n",
      "576/576 [==============================] - 0s 84us/step - loss: 11.5631 - val_loss: 58.8094\n",
      "Epoch 62/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.4208 - val_loss: 58.9275\n",
      "Epoch 63/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.2221 - val_loss: 59.3754\n",
      "Epoch 64/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.2244 - val_loss: 59.1507\n",
      "Epoch 65/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.2078 - val_loss: 58.3071\n",
      "Epoch 66/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.1076 - val_loss: 59.7259\n",
      "Epoch 67/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.6634 - val_loss: 58.5369\n",
      "Epoch 68/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 10.8535 - val_loss: 58.8454\n",
      "Epoch 69/100\n",
      "576/576 [==============================] - 0s 95us/step - loss: 11.4027 - val_loss: 58.8365\n",
      "Epoch 70/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.4131 - val_loss: 58.9799\n",
      "Epoch 71/100\n",
      "576/576 [==============================] - 0s 96us/step - loss: 11.2534 - val_loss: 58.3635\n",
      "Epoch 72/100\n",
      "576/576 [==============================] - 0s 99us/step - loss: 11.3489 - val_loss: 58.5295\n",
      "Epoch 73/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.3569 - val_loss: 58.6585\n",
      "Epoch 74/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.0548 - val_loss: 59.1311\n",
      "Epoch 75/100\n",
      "576/576 [==============================] - 0s 199us/step - loss: 11.1950 - val_loss: 59.3281\n",
      "Epoch 76/100\n",
      "576/576 [==============================] - 0s 230us/step - loss: 11.3955 - val_loss: 58.4769\n",
      "Epoch 77/100\n",
      "576/576 [==============================] - 0s 110us/step - loss: 11.1297 - val_loss: 58.1334\n",
      "Epoch 78/100\n",
      "576/576 [==============================] - 0s 104us/step - loss: 10.9392 - val_loss: 58.6148\n",
      "Epoch 79/100\n",
      "576/576 [==============================] - 0s 86us/step - loss: 11.4780 - val_loss: 58.3961\n",
      "Epoch 80/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2826 - val_loss: 58.6061\n",
      "Epoch 81/100\n",
      "576/576 [==============================] - 0s 87us/step - loss: 11.0820 - val_loss: 57.8511\n",
      "Epoch 82/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.8697 - val_loss: 59.0042\n",
      "Epoch 83/100\n",
      "576/576 [==============================] - 0s 91us/step - loss: 11.2056 - val_loss: 58.9688\n",
      "Epoch 84/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.9762 - val_loss: 57.9766\n",
      "Epoch 85/100\n",
      "576/576 [==============================] - 0s 88us/step - loss: 11.0725 - val_loss: 58.6502\n",
      "Epoch 86/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.9998 - val_loss: 58.5147\n",
      "Epoch 87/100\n",
      "576/576 [==============================] - 0s 142us/step - loss: 10.9326 - val_loss: 58.0734\n",
      "Epoch 88/100\n",
      "576/576 [==============================] - 0s 103us/step - loss: 11.0187 - val_loss: 58.7552\n",
      "Epoch 89/100\n",
      "576/576 [==============================] - 0s 139us/step - loss: 11.0171 - val_loss: 57.8425\n",
      "Epoch 90/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0571 - val_loss: 58.8419\n",
      "Epoch 91/100\n",
      "576/576 [==============================] - 0s 98us/step - loss: 11.0993 - val_loss: 58.0960\n",
      "Epoch 92/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0657 - val_loss: 59.0573\n",
      "Epoch 93/100\n",
      "576/576 [==============================] - 0s 121us/step - loss: 11.0117 - val_loss: 57.7661\n",
      "Epoch 94/100\n",
      "576/576 [==============================] - 0s 93us/step - loss: 10.9850 - val_loss: 58.3980\n",
      "Epoch 95/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 10.9368 - val_loss: 58.5738\n",
      "Epoch 96/100\n",
      "576/576 [==============================] - 0s 101us/step - loss: 11.1943 - val_loss: 58.6587\n",
      "Epoch 97/100\n",
      "576/576 [==============================] - 0s 94us/step - loss: 11.0623 - val_loss: 58.2145\n",
      "Epoch 98/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.3165 - val_loss: 58.0471\n",
      "Epoch 99/100\n",
      "576/576 [==============================] - 0s 89us/step - loss: 11.1056 - val_loss: 58.1003\n",
      "Epoch 100/100\n",
      "576/576 [==============================] - 0s 90us/step - loss: 11.0022 - val_loss: 58.6298\n",
      "\n",
      "Mean Squared Error for iteration50: 48.176434519377445\n"
     ]
    }
   ],
   "source": [
    "mse_total = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    print('\\nIteration: ', i+1)\n",
    "    model.fit(X_train_norm, y_train, validation_split=0.2, epochs=100)\n",
    "    predict_yhat = model.predict(X_test_norm)\n",
    "    mse = mean_squared_error(y_test, predict_yhat)\n",
    "    print('\\n''Mean Squared Error for iteration{}: {}'.format(i+1, mse))\n",
    "    mse_total.append(mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_total)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Part A - Mean of MSE and Std. Dev.\n",
    "\n",
    "The mean MSE value is 50.59490996401415 and standard deviation for MSE is 1.0276902495212634"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Part B - Mean of MSE and Std. Dev.\n",
    "\n",
    "The mean MSE value is 46.317387506891215 and standard deviation for MSE is 0.17963278002251176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Part C - Mean of MSE and Std. Dev.\n",
    "\n",
    "The mean MSE value is 51.12350691305703 and standard deviation for MSE is 15.7663319140305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean MSE value is 48.04890876138753 and standard deviation for MSE is 0.6324825358700743\n"
     ]
    }
   ],
   "source": [
    "#Calculating mean and standard deviation of MSE - Part D\n",
    "mean = np.mean(mse_total)\n",
    "std_dev=np.std(mse_total)\n",
    "\n",
    "print('The mean MSE value is {} and standard deviation for MSE is {}'.format(mean, std_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
