{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM Keras - Final Assignment - Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('concrete_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks clean, with no null values. We have to predict data of concrete strength\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[df.columns != 'Strength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Strength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A - Build Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Neural Network\n",
    "\n",
    "def regression_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss ='mean_squared_error')\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "Since the data is clean we can go ahead and split the data in train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = X_train.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (721, 8)\n",
      "y_train: (721,)\n",
      "X_test: (309, 8)\n",
      "y_test: (309,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B - Normalize the Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = (X_train - X_train.mean()) / X_train.std()\n",
    "#X_train_norm\n",
    "X_test_norm = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 180us/step - loss: 26.6861 - val_loss: 46.6288\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6773 - val_loss: 46.6566\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6817 - val_loss: 46.6222\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 120us/step - loss: 26.6769 - val_loss: 46.6803\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6789 - val_loss: 46.7247\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.7500 - val_loss: 46.6052\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.7138 - val_loss: 46.6491\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 114us/step - loss: 26.6931 - val_loss: 46.6931\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 114us/step - loss: 26.7008 - val_loss: 46.6588\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.8020 - val_loss: 46.6656\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6927 - val_loss: 46.6822\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.7592 - val_loss: 46.6224\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.7265 - val_loss: 46.7690\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6880 - val_loss: 46.6050\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.6827 - val_loss: 46.6095\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.7250 - val_loss: 46.6989\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.7099 - val_loss: 46.7531\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6795 - val_loss: 46.6980\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6972 - val_loss: 46.6369\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6738 - val_loss: 46.6226\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.7017 - val_loss: 46.6412\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.6865 - val_loss: 46.7399\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.6770 - val_loss: 46.6558\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.7458 - val_loss: 46.6519\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.7047 - val_loss: 46.5990\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6961 - val_loss: 46.7550\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6984 - val_loss: 46.6574\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6833 - val_loss: 46.6817\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.7253 - val_loss: 46.6236\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6812 - val_loss: 46.7118\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6961 - val_loss: 46.6743\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6879 - val_loss: 46.6665\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.7025 - val_loss: 46.7042\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.8615 - val_loss: 46.5894\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.7630 - val_loss: 46.6937\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.7152 - val_loss: 46.6400\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6860 - val_loss: 46.7045\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.7225 - val_loss: 46.6091\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6771 - val_loss: 46.6110\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.7163 - val_loss: 46.7227\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7568 - val_loss: 46.6181\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.7034 - val_loss: 46.6742\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 195us/step - loss: 26.7059 - val_loss: 46.6797\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 292us/step - loss: 26.6937 - val_loss: 46.7734\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 141us/step - loss: 26.7038 - val_loss: 46.7002\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.7165 - val_loss: 46.7130\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6907 - val_loss: 46.6008\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6844 - val_loss: 46.6507\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6994 - val_loss: 46.6440\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6733 - val_loss: 46.6344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff5c4f53470>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "\n",
    "model.fit(X_train_norm, y_train, validation_split=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "\n",
    "predict_yhat = model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.05576747496959"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, predict_yhat)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.7527 - val_loss: 46.7686\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6802 - val_loss: 46.7348\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.7129 - val_loss: 46.6938\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.7368 - val_loss: 46.6369\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.7126 - val_loss: 46.6950\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.7017 - val_loss: 46.5179\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.7165 - val_loss: 46.6301\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.7187 - val_loss: 46.7084\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.7021 - val_loss: 46.6520\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7348 - val_loss: 46.8382\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.7835 - val_loss: 46.6475\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6750 - val_loss: 46.6100\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6975 - val_loss: 46.6655\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6903 - val_loss: 46.8180\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6947 - val_loss: 46.7812\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.8213 - val_loss: 46.6680\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6978 - val_loss: 46.5940\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6846 - val_loss: 46.6095\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 26.6951 - val_loss: 46.7080\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 155us/step - loss: 26.7158 - val_loss: 46.6773\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 114us/step - loss: 26.7253 - val_loss: 46.6998\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 26.7060 - val_loss: 46.6387\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6856 - val_loss: 46.5966\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6683 - val_loss: 46.6477\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6737 - val_loss: 46.5806\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.7608 - val_loss: 46.7548\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.7122 - val_loss: 46.6961\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7920 - val_loss: 46.7104\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.7468 - val_loss: 46.6535\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.7358 - val_loss: 46.5477\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.7088 - val_loss: 46.6439\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6657 - val_loss: 46.6946\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6796 - val_loss: 46.7998\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.7043 - val_loss: 46.6812\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.7312 - val_loss: 46.7235\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6749 - val_loss: 46.7195\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6609 - val_loss: 46.6283\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.6999 - val_loss: 46.6193\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6734 - val_loss: 46.7142\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 201us/step - loss: 26.6852 - val_loss: 46.6337\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 350us/step - loss: 26.6996 - val_loss: 46.8114\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 220us/step - loss: 26.7555 - val_loss: 46.7043\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 26.6757 - val_loss: 46.6627\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.7077 - val_loss: 46.7436\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6977 - val_loss: 46.7121\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.7001 - val_loss: 46.6208\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.7136 - val_loss: 46.6618\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 26.6548 - val_loss: 46.6455\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6970 - val_loss: 46.6142\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7236 - val_loss: 46.5402\n",
      "\n",
      "Mean Squared Error for iteration1: 46.05990814864631\n",
      "\n",
      "Iteration: 2\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.6827 - val_loss: 46.7487\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.7005 - val_loss: 46.7252\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6762 - val_loss: 46.7721\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.7193 - val_loss: 46.7432\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.7066 - val_loss: 46.6180\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7463 - val_loss: 46.7257\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6989 - val_loss: 46.6444\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.7297 - val_loss: 46.6751\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 127us/step - loss: 26.7045 - val_loss: 46.6547\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6649 - val_loss: 46.6721\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7145 - val_loss: 46.7050\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7255 - val_loss: 46.6168\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6555 - val_loss: 46.6527\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6734 - val_loss: 46.7336\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.7111 - val_loss: 46.5503\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.7062 - val_loss: 46.6781\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6874 - val_loss: 46.7788\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6685 - val_loss: 46.7199\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6677 - val_loss: 46.7251\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 26.6894 - val_loss: 46.7015\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.7286 - val_loss: 46.7981\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6600 - val_loss: 46.6565\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6760 - val_loss: 46.6508\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.7106 - val_loss: 46.6767\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6793 - val_loss: 46.6917\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.7106 - val_loss: 46.7092\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.7086 - val_loss: 46.6253\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 79us/step - loss: 26.6952 - val_loss: 46.7354\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6865 - val_loss: 46.6332\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6835 - val_loss: 46.7162\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6970 - val_loss: 46.6441\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6837 - val_loss: 46.8372\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7066 - val_loss: 46.6457\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6648 - val_loss: 46.6762\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6728 - val_loss: 46.6529\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6972 - val_loss: 46.6812\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.7222 - val_loss: 46.6363\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7354 - val_loss: 46.7113\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6785 - val_loss: 46.7147\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.7253 - val_loss: 46.7393\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.7302 - val_loss: 46.6644\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6877 - val_loss: 46.7091\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6983 - val_loss: 46.7090\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6856 - val_loss: 46.6829\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6768 - val_loss: 46.7034\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6958 - val_loss: 46.6108\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6538 - val_loss: 46.6324\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6765 - val_loss: 46.7538\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7657 - val_loss: 46.6130\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6850 - val_loss: 46.7105\n",
      "\n",
      "Mean Squared Error for iteration2: 46.099451685447654\n",
      "\n",
      "Iteration: 3\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6559 - val_loss: 46.7000\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7033 - val_loss: 46.7299\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.7358 - val_loss: 46.7045\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.7194 - val_loss: 46.6509\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 120us/step - loss: 26.6887 - val_loss: 46.7425\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 172us/step - loss: 26.7175 - val_loss: 46.6664\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 26.7157 - val_loss: 46.7297\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 26.7068 - val_loss: 46.7414\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.7133 - val_loss: 46.6590\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6690 - val_loss: 46.6169\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 195us/step - loss: 26.7631 - val_loss: 46.6647\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 185us/step - loss: 26.7197 - val_loss: 46.7244\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 26.7049 - val_loss: 46.7021\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7744 - val_loss: 46.7359\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6644 - val_loss: 46.6570\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7276 - val_loss: 46.7073\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7332 - val_loss: 46.5679\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6882 - val_loss: 46.8354\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6970 - val_loss: 46.7362\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7062 - val_loss: 46.6280\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7010 - val_loss: 46.7465\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6596 - val_loss: 46.7082\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6412 - val_loss: 46.6623\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6953 - val_loss: 46.7008\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.7340 - val_loss: 46.6712\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7109 - val_loss: 46.6318\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 26.6645 - val_loss: 46.6777\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6833 - val_loss: 46.6977\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6856 - val_loss: 46.7416\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7169 - val_loss: 46.7055\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.7703 - val_loss: 46.7063\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6990 - val_loss: 46.7590\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7124 - val_loss: 46.6414\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6800 - val_loss: 46.6501\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7242 - val_loss: 46.6955\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6850 - val_loss: 46.6961\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7369 - val_loss: 46.7074\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6421 - val_loss: 46.6436\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7236 - val_loss: 46.6071\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6840 - val_loss: 46.8104\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7393 - val_loss: 46.6877\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.7235 - val_loss: 46.7138\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6824 - val_loss: 46.6935\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6885 - val_loss: 46.6534\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6933 - val_loss: 46.7077\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6769 - val_loss: 46.7494\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6956 - val_loss: 46.6718\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6770 - val_loss: 46.8441\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.7311 - val_loss: 46.6348\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.8237 - val_loss: 46.7975\n",
      "\n",
      "Mean Squared Error for iteration3: 46.11545487935594\n",
      "\n",
      "Iteration: 4\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6750 - val_loss: 46.7677\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6726 - val_loss: 46.6486\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6745 - val_loss: 46.7410\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 72us/step - loss: 26.6961 - val_loss: 46.7163\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6841 - val_loss: 46.6261\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6954 - val_loss: 46.7296\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6907 - val_loss: 46.6936\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7430 - val_loss: 46.7047\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6912 - val_loss: 46.7660\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6927 - val_loss: 46.6381\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6767 - val_loss: 46.6083\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6795 - val_loss: 46.6316\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7184 - val_loss: 46.7874\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7162 - val_loss: 46.6745\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6662 - val_loss: 46.6982\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6907 - val_loss: 46.6522\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7069 - val_loss: 46.7196\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6774 - val_loss: 46.6914\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6972 - val_loss: 46.8088\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7356 - val_loss: 46.7274\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6827 - val_loss: 46.7334\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6984 - val_loss: 46.6383\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7546 - val_loss: 46.7498\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7290 - val_loss: 46.8132\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6706 - val_loss: 46.7071\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.7247 - val_loss: 46.6352\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.7194 - val_loss: 46.7488\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7305 - val_loss: 46.7238\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6553 - val_loss: 46.7508\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6566 - val_loss: 46.6906\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6710 - val_loss: 46.7407\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7386 - val_loss: 46.6174\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6753 - val_loss: 46.6901\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6530 - val_loss: 46.7619\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6712 - val_loss: 46.7264\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7699 - val_loss: 46.6027\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.7131 - val_loss: 46.7078\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6839 - val_loss: 46.7230\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6750 - val_loss: 46.7012\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6889 - val_loss: 46.6859\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6722 - val_loss: 46.7089\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6921 - val_loss: 46.6936\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6610 - val_loss: 46.7051\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6539 - val_loss: 46.7260\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6787 - val_loss: 46.6321\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7345 - val_loss: 46.8126\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6722 - val_loss: 46.7522\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6777 - val_loss: 46.7058\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6764 - val_loss: 46.7241\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7201 - val_loss: 46.6485\n",
      "\n",
      "Mean Squared Error for iteration4: 46.05469569702776\n",
      "\n",
      "Iteration: 5\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6940 - val_loss: 46.7039\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6514 - val_loss: 46.7236\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6694 - val_loss: 46.6910\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6567 - val_loss: 46.6938\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6917 - val_loss: 46.6722\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6970 - val_loss: 46.7609\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6931 - val_loss: 46.6999\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6678 - val_loss: 46.7409\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6494 - val_loss: 46.6912\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.7068 - val_loss: 46.7862\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6904 - val_loss: 46.7365\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7281 - val_loss: 46.6365\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7125 - val_loss: 46.7840\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6875 - val_loss: 46.7269\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7508 - val_loss: 46.5285\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6526 - val_loss: 46.6108\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.6634 - val_loss: 46.8046\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6646 - val_loss: 46.7811\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6926 - val_loss: 46.7022\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6719 - val_loss: 46.7207\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6609 - val_loss: 46.6617\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.7452 - val_loss: 46.6894\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6617 - val_loss: 46.6175\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6706 - val_loss: 46.6857\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7228 - val_loss: 46.7549\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6989 - val_loss: 46.7647\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7154 - val_loss: 46.7711\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6810 - val_loss: 46.6651\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7447 - val_loss: 46.7518\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7327 - val_loss: 46.6333\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6505 - val_loss: 46.7367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7300 - val_loss: 46.7709\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6951 - val_loss: 46.7786\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7076 - val_loss: 46.5946\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7774 - val_loss: 46.8076\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6866 - val_loss: 46.6787\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6581 - val_loss: 46.7257\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6857 - val_loss: 46.8146\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6672 - val_loss: 46.6730\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.7257 - val_loss: 46.6698\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7729 - val_loss: 46.7374\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6575 - val_loss: 46.7432\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6662 - val_loss: 46.7253\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6765 - val_loss: 46.7033\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6693 - val_loss: 46.7070\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.7056 - val_loss: 46.7541\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6715 - val_loss: 46.7388\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7857 - val_loss: 46.7350\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6840 - val_loss: 46.6853\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7491 - val_loss: 46.6576\n",
      "\n",
      "Mean Squared Error for iteration5: 46.043832151400395\n",
      "\n",
      "Iteration: 6\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6794 - val_loss: 46.7564\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7429 - val_loss: 46.6956\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7836 - val_loss: 46.7073\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6844 - val_loss: 46.7939\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6820 - val_loss: 46.6732\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6773 - val_loss: 46.7606\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6846 - val_loss: 46.7306\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7127 - val_loss: 46.6988\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6668 - val_loss: 46.7621\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6855 - val_loss: 46.7256\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6568 - val_loss: 46.7020\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6759 - val_loss: 46.6486\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.8405 - val_loss: 46.7506\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7132 - val_loss: 46.7433\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7058 - val_loss: 46.6866\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7094 - val_loss: 46.7177\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6583 - val_loss: 46.6581\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.7012 - val_loss: 46.6924\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6460 - val_loss: 46.6559\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7058 - val_loss: 46.7860\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6661 - val_loss: 46.6766\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6740 - val_loss: 46.6769\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7153 - val_loss: 46.8150\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6585 - val_loss: 46.7747\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6469 - val_loss: 46.6993\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6963 - val_loss: 46.7675\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6810 - val_loss: 46.7148\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.8568 - val_loss: 46.8407\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6531 - val_loss: 46.6639\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6632 - val_loss: 46.7342\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6691 - val_loss: 46.6964\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6378 - val_loss: 46.6537\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6940 - val_loss: 46.6667\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6480 - val_loss: 46.7514\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.7187 - val_loss: 46.6895\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6923 - val_loss: 46.8525\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6969 - val_loss: 46.7408\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6855 - val_loss: 46.6098\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6495 - val_loss: 46.6849\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6627 - val_loss: 46.7147\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6557 - val_loss: 46.7316\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6919 - val_loss: 46.7391\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6594 - val_loss: 46.7444\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6748 - val_loss: 46.7500\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6659 - val_loss: 46.6927\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6772 - val_loss: 46.6655\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6879 - val_loss: 46.7995\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7842 - val_loss: 46.6932\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.7203 - val_loss: 46.7695\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6748 - val_loss: 46.7693\n",
      "\n",
      "Mean Squared Error for iteration6: 46.05992268163505\n",
      "\n",
      "Iteration: 7\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6758 - val_loss: 46.7344\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6877 - val_loss: 46.6346\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6649 - val_loss: 46.7055\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6905 - val_loss: 46.6568\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7096 - val_loss: 46.7043\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.7095 - val_loss: 46.7233\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.6394 - val_loss: 46.7689\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 81us/step - loss: 26.6882 - val_loss: 46.8178\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6378 - val_loss: 46.7267\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6664 - val_loss: 46.7766\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6541 - val_loss: 46.7138\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.7249 - val_loss: 46.7272\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6560 - val_loss: 46.7254\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6763 - val_loss: 46.7701\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7177 - val_loss: 46.7165\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6778 - val_loss: 46.8077\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6676 - val_loss: 46.6908\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6782 - val_loss: 46.7190\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6652 - val_loss: 46.7632\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7612 - val_loss: 46.7074\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6482 - val_loss: 46.6300\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7050 - val_loss: 46.6746\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6682 - val_loss: 46.7857\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7250 - val_loss: 46.6967\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7307 - val_loss: 46.6570\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6482 - val_loss: 46.7282\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6839 - val_loss: 46.7584\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6533 - val_loss: 46.6890\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6943 - val_loss: 46.7822\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6509 - val_loss: 46.7749\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.7105 - val_loss: 46.7380\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6855 - val_loss: 46.7395\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6778 - val_loss: 46.6664\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7725 - val_loss: 46.7779\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6805 - val_loss: 46.7595\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6568 - val_loss: 46.7233\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6823 - val_loss: 46.7373\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6522 - val_loss: 46.7353\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7245 - val_loss: 46.8332\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6590 - val_loss: 46.7581\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 201us/step - loss: 26.6871 - val_loss: 46.7295\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 170us/step - loss: 26.6617 - val_loss: 46.6834\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 154us/step - loss: 26.6935 - val_loss: 46.6913\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 134us/step - loss: 26.6860 - val_loss: 46.7587\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 191us/step - loss: 26.6835 - val_loss: 46.6730\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 26.6607 - val_loss: 46.7160\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7307 - val_loss: 46.7858\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6639 - val_loss: 46.7216\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6733 - val_loss: 46.7607\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.6789 - val_loss: 46.7676\n",
      "\n",
      "Mean Squared Error for iteration7: 46.10452854039447\n",
      "\n",
      "Iteration: 8\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7147 - val_loss: 46.7426\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6492 - val_loss: 46.8320\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7284 - val_loss: 46.7904\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6811 - val_loss: 46.7299\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6662 - val_loss: 46.8098\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6852 - val_loss: 46.6854\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6696 - val_loss: 46.6536\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.7295 - val_loss: 46.9152\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.6636 - val_loss: 46.7528\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.7109 - val_loss: 46.7556\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6553 - val_loss: 46.7135\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6800 - val_loss: 46.6278\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.7201 - val_loss: 46.7626\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6471 - val_loss: 46.7203\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6311 - val_loss: 46.7035\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6969 - val_loss: 46.6473\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6763 - val_loss: 46.7556\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6746 - val_loss: 46.7041\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6868 - val_loss: 46.6940\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6706 - val_loss: 46.8543\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6648 - val_loss: 46.8517\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6653 - val_loss: 46.6782\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6827 - val_loss: 46.7819\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6791 - val_loss: 46.7871\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6572 - val_loss: 46.6737\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6959 - val_loss: 46.7409\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6557 - val_loss: 46.7931\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6566 - val_loss: 46.6812\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7157 - val_loss: 46.7152\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6606 - val_loss: 46.6411\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7726 - val_loss: 46.7513\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6694 - val_loss: 46.7917\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7260 - val_loss: 46.7375\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6914 - val_loss: 46.7463\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6805 - val_loss: 46.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6939 - val_loss: 46.6974\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6661 - val_loss: 46.7350\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6932 - val_loss: 46.8817\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6829 - val_loss: 46.7140\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6652 - val_loss: 46.7182\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6559 - val_loss: 46.8003\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6609 - val_loss: 46.7376\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6619 - val_loss: 46.7261\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6567 - val_loss: 46.7498\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6944 - val_loss: 46.8198\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7184 - val_loss: 46.7044\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6334 - val_loss: 46.7692\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 26.6797 - val_loss: 46.6596\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6588 - val_loss: 46.8455\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6682 - val_loss: 46.7624\n",
      "\n",
      "Mean Squared Error for iteration8: 46.11860498419299\n",
      "\n",
      "Iteration: 9\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.6552 - val_loss: 46.7758\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.6751 - val_loss: 46.6784\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6758 - val_loss: 46.7919\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6866 - val_loss: 46.6861\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7762 - val_loss: 46.7531\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6400 - val_loss: 46.6711\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6749 - val_loss: 46.8457\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6711 - val_loss: 46.7738\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6504 - val_loss: 46.7333\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7156 - val_loss: 46.8762\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.7269 - val_loss: 46.8155\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7245 - val_loss: 46.6883\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6746 - val_loss: 46.7376\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6620 - val_loss: 46.6718\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7132 - val_loss: 46.8959\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6212 - val_loss: 46.8078\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6529 - val_loss: 46.7671\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7085 - val_loss: 46.7202\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6348 - val_loss: 46.6997\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6443 - val_loss: 46.8265\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7020 - val_loss: 46.7416\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6909 - val_loss: 46.7879\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6407 - val_loss: 46.7738\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6929 - val_loss: 46.8252\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6849 - val_loss: 46.8060\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6741 - val_loss: 46.7098\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6821 - val_loss: 46.7465\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6446 - val_loss: 46.7350\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6351 - val_loss: 46.7666\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 26.6578 - val_loss: 46.8421\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 26.6699 - val_loss: 46.7270\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.6754 - val_loss: 46.7449\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 26.6451 - val_loss: 46.7491\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.7015 - val_loss: 46.7819\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6975 - val_loss: 46.8889\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.6678 - val_loss: 46.6961\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.6989 - val_loss: 46.6950\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.6827 - val_loss: 46.7520\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6679 - val_loss: 46.8627\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6988 - val_loss: 46.7970\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6387 - val_loss: 46.7220\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.7030 - val_loss: 46.6700\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6695 - val_loss: 46.8032\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6524 - val_loss: 46.7538\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.6598 - val_loss: 46.6925\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6348 - val_loss: 46.8623\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6403 - val_loss: 46.8453\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6245 - val_loss: 46.8189\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6729 - val_loss: 46.7965\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 244us/step - loss: 26.6819 - val_loss: 46.7760\n",
      "\n",
      "Mean Squared Error for iteration9: 46.07383641489637\n",
      "\n",
      "Iteration: 10\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 26.6485 - val_loss: 46.7917\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.6918 - val_loss: 46.7089\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.6770 - val_loss: 46.8647\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 199us/step - loss: 26.6638 - val_loss: 46.6885\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6449 - val_loss: 46.7383\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6740 - val_loss: 46.7297\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7146 - val_loss: 46.8234\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6580 - val_loss: 46.7594\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6613 - val_loss: 46.7851\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6629 - val_loss: 46.7584\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6522 - val_loss: 46.8124\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 73us/step - loss: 26.6975 - val_loss: 46.8180\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.6686 - val_loss: 46.7249\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6270 - val_loss: 46.8162\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6451 - val_loss: 46.6786\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6875 - val_loss: 46.7658\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6359 - val_loss: 46.7599\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6875 - val_loss: 46.8738\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6459 - val_loss: 46.8329\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6330 - val_loss: 46.7815\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6782 - val_loss: 46.7300\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6454 - val_loss: 46.8193\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6668 - val_loss: 46.6736\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6925 - val_loss: 46.8458\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7063 - val_loss: 46.7930\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6732 - val_loss: 46.9038\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6324 - val_loss: 46.8012\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7453 - val_loss: 46.7778\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6981 - val_loss: 46.6847\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6929 - val_loss: 46.6812\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6790 - val_loss: 46.8668\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7196 - val_loss: 46.7673\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6943 - val_loss: 46.8149\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6910 - val_loss: 46.7639\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6714 - val_loss: 46.7894\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6629 - val_loss: 46.7900\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7076 - val_loss: 46.7556\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6423 - val_loss: 46.6831\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6503 - val_loss: 46.7681\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.7348 - val_loss: 46.8590\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6523 - val_loss: 46.8143\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6973 - val_loss: 46.8618\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6217 - val_loss: 46.8178\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6422 - val_loss: 46.7421\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6470 - val_loss: 46.8234\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.7030 - val_loss: 46.7833\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6148 - val_loss: 46.7205\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6758 - val_loss: 46.8113\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6543 - val_loss: 46.7769\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6598 - val_loss: 46.7782\n",
      "\n",
      "Mean Squared Error for iteration10: 46.005018331133726\n",
      "\n",
      "Iteration: 11\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6733 - val_loss: 46.8280\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6827 - val_loss: 46.6498\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6421 - val_loss: 46.6566\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6448 - val_loss: 46.8697\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6858 - val_loss: 46.8489\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6635 - val_loss: 46.8554\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6468 - val_loss: 46.8648\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6738 - val_loss: 46.7895\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6523 - val_loss: 46.6677\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.7148 - val_loss: 46.6735\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6728 - val_loss: 46.8353\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6374 - val_loss: 46.8832\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6994 - val_loss: 46.7076\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7035 - val_loss: 46.8854\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.7184 - val_loss: 46.8075\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6672 - val_loss: 46.7705\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.7166 - val_loss: 46.8042\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6858 - val_loss: 46.7567\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6712 - val_loss: 46.7631\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6573 - val_loss: 46.7965\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6281 - val_loss: 46.7942\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7075 - val_loss: 46.8504\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6719 - val_loss: 46.8589\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6720 - val_loss: 46.7773\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7045 - val_loss: 46.7450\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6314 - val_loss: 46.7893\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6828 - val_loss: 46.8127\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6414 - val_loss: 46.8639\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6531 - val_loss: 46.8373\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6357 - val_loss: 46.7812\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6550 - val_loss: 46.7350\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6916 - val_loss: 46.9428\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6522 - val_loss: 46.6710\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6128 - val_loss: 46.7700\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6369 - val_loss: 46.8400\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6493 - val_loss: 46.8237\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6471 - val_loss: 46.8724\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6705 - val_loss: 46.8228\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6331 - val_loss: 46.7881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6620 - val_loss: 46.7631\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6383 - val_loss: 46.8087\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6419 - val_loss: 46.7538\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6661 - val_loss: 46.8353\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6650 - val_loss: 46.7372\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6861 - val_loss: 46.8237\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6275 - val_loss: 46.7489\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6849 - val_loss: 46.8155\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7275 - val_loss: 46.8686\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6727 - val_loss: 46.7909\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6502 - val_loss: 46.8354\n",
      "\n",
      "Mean Squared Error for iteration11: 46.05152524711451\n",
      "\n",
      "Iteration: 12\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6522 - val_loss: 46.8455\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6682 - val_loss: 46.7080\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.7108 - val_loss: 46.7866\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6621 - val_loss: 46.7273\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6508 - val_loss: 46.8037\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6461 - val_loss: 46.7659\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6295 - val_loss: 46.8433\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6512 - val_loss: 46.7721\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6495 - val_loss: 46.8372\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6998 - val_loss: 46.6705\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6680 - val_loss: 46.8163\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6557 - val_loss: 46.8908\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6368 - val_loss: 46.7741\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6608 - val_loss: 46.8333\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6528 - val_loss: 46.7568\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6857 - val_loss: 46.9169\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7382 - val_loss: 46.7074\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6762 - val_loss: 46.7743\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6396 - val_loss: 46.8891\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7244 - val_loss: 46.8326\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6081 - val_loss: 46.8604\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6320 - val_loss: 46.7908\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6365 - val_loss: 46.8713\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6733 - val_loss: 46.7616\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.7457 - val_loss: 46.7219\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6430 - val_loss: 46.7759\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6270 - val_loss: 46.8004\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6520 - val_loss: 46.9426\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6351 - val_loss: 46.8083\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6592 - val_loss: 46.7648\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6760 - val_loss: 46.9131\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6676 - val_loss: 46.6527\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6715 - val_loss: 46.8263\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6495 - val_loss: 46.8368\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6484 - val_loss: 46.8583\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7717 - val_loss: 46.7842\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7007 - val_loss: 46.8439\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6619 - val_loss: 46.7891\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6324 - val_loss: 46.8098\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6254 - val_loss: 46.8315\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6483 - val_loss: 46.7623\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6585 - val_loss: 46.7735\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6803 - val_loss: 46.7761\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6317 - val_loss: 46.9379\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6564 - val_loss: 46.9314\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6670 - val_loss: 46.7573\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6892 - val_loss: 46.8834\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.6815 - val_loss: 46.8535\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6288 - val_loss: 46.7596\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6438 - val_loss: 46.8124\n",
      "\n",
      "Mean Squared Error for iteration12: 46.109586989743704\n",
      "\n",
      "Iteration: 13\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6298 - val_loss: 46.8245\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6397 - val_loss: 46.8305\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6659 - val_loss: 46.8089\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6473 - val_loss: 46.8054\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6200 - val_loss: 46.7097\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6379 - val_loss: 46.7691\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6223 - val_loss: 46.7790\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6751 - val_loss: 46.8529\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6854 - val_loss: 46.8391\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6561 - val_loss: 46.8031\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7005 - val_loss: 46.8437\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6944 - val_loss: 46.9361\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6646 - val_loss: 46.8632\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6847 - val_loss: 46.8263\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6167 - val_loss: 46.8096\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 72us/step - loss: 26.6691 - val_loss: 46.8827\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6250 - val_loss: 46.8086\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6638 - val_loss: 46.8570\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6362 - val_loss: 46.7565\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6447 - val_loss: 46.7680\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6865 - val_loss: 46.8180\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6356 - val_loss: 46.8735\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6334 - val_loss: 46.8783\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6595 - val_loss: 46.7498\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6807 - val_loss: 46.7999\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.7072 - val_loss: 46.8867\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6562 - val_loss: 46.7542\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6737 - val_loss: 46.7552\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6678 - val_loss: 46.8558\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6649 - val_loss: 46.8637\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6960 - val_loss: 46.8025\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6764 - val_loss: 46.8756\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6302 - val_loss: 46.8105\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6466 - val_loss: 46.7974\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6771 - val_loss: 46.8143\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6692 - val_loss: 46.8326\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6525 - val_loss: 46.7990\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6572 - val_loss: 46.7793\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6735 - val_loss: 46.7766\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6569 - val_loss: 46.8590\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6755 - val_loss: 46.8453\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6608 - val_loss: 46.8164\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.7064 - val_loss: 46.8661\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6849 - val_loss: 46.8321\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.7237 - val_loss: 46.9925\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6239 - val_loss: 46.8701\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 26.6258 - val_loss: 46.8475\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.7157 - val_loss: 46.7536\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6646 - val_loss: 46.8805\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.7214 - val_loss: 46.9312\n",
      "\n",
      "Mean Squared Error for iteration13: 46.18645581796871\n",
      "\n",
      "Iteration: 14\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6766 - val_loss: 46.7617\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6449 - val_loss: 46.6864\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 26.6533 - val_loss: 46.7988\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 26.6486 - val_loss: 46.8865\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 129us/step - loss: 26.6265 - val_loss: 46.8327\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.6111 - val_loss: 46.8361\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - ETA: 0s - loss: 22.65 - 0s 107us/step - loss: 26.6522 - val_loss: 46.7378\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 26.6127 - val_loss: 46.8342\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 26.6621 - val_loss: 46.8793\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 118us/step - loss: 26.6815 - val_loss: 46.7856\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 141us/step - loss: 26.6593 - val_loss: 46.8371\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 26.6839 - val_loss: 46.7977\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6198 - val_loss: 46.8670\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6284 - val_loss: 46.9223\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7096 - val_loss: 46.8609\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6542 - val_loss: 46.8012\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6400 - val_loss: 46.7966\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6689 - val_loss: 46.8367\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6345 - val_loss: 46.8459\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6682 - val_loss: 46.8275\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6662 - val_loss: 46.8413\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6397 - val_loss: 46.8405\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6488 - val_loss: 46.9108\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6265 - val_loss: 46.9126\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7091 - val_loss: 46.6860\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7028 - val_loss: 46.9027\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.7888 - val_loss: 46.7783\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6678 - val_loss: 46.8820\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 136us/step - loss: 26.6962 - val_loss: 46.9288\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6510 - val_loss: 46.9036\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6202 - val_loss: 46.7786\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6200 - val_loss: 46.8299\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.7047 - val_loss: 46.8783\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6665 - val_loss: 46.7871\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6409 - val_loss: 46.8711\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6441 - val_loss: 46.8856\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6401 - val_loss: 46.7953\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6224 - val_loss: 46.8856\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6296 - val_loss: 46.7906\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6311 - val_loss: 46.8220\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6403 - val_loss: 46.9857\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6579 - val_loss: 46.8139\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 72us/step - loss: 26.6425 - val_loss: 46.8878\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6434 - val_loss: 46.8557\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6174 - val_loss: 46.7982\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6351 - val_loss: 46.9482\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6323 - val_loss: 46.8462\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6678 - val_loss: 46.9113\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.7005 - val_loss: 46.8636\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6144 - val_loss: 46.7658\n",
      "\n",
      "Mean Squared Error for iteration14: 46.08291124658764\n",
      "\n",
      "Iteration: 15\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6325 - val_loss: 46.8453\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6170 - val_loss: 46.8454\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6439 - val_loss: 46.8064\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6487 - val_loss: 46.8934\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6317 - val_loss: 46.8967\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6286 - val_loss: 46.8840\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6519 - val_loss: 46.8000\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6762 - val_loss: 46.9225\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6613 - val_loss: 46.8571\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7272 - val_loss: 46.7840\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6393 - val_loss: 46.7930\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7327 - val_loss: 46.9026\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.7002 - val_loss: 46.8150\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6210 - val_loss: 46.8175\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6358 - val_loss: 46.8942\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6689 - val_loss: 46.8811\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6357 - val_loss: 46.8891\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6863 - val_loss: 46.9914\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6853 - val_loss: 46.7968\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7025 - val_loss: 46.8410\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6290 - val_loss: 46.8161\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6330 - val_loss: 46.8840\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6386 - val_loss: 46.7935\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6169 - val_loss: 46.9539\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.7545 - val_loss: 46.8509\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7027 - val_loss: 46.9431\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6568 - val_loss: 46.8366\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6223 - val_loss: 46.9184\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6514 - val_loss: 46.8507\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6064 - val_loss: 46.8418\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6853 - val_loss: 46.9480\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6304 - val_loss: 46.8170\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6355 - val_loss: 46.8755\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6335 - val_loss: 46.8778\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6707 - val_loss: 47.0124\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6445 - val_loss: 46.8551\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6769 - val_loss: 46.7812\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6113 - val_loss: 46.8329\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6984 - val_loss: 46.8651\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6820 - val_loss: 46.9762\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6588 - val_loss: 46.8145\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6544 - val_loss: 46.8396\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6451 - val_loss: 46.8516\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6626 - val_loss: 46.8049\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6862 - val_loss: 46.9046\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6668 - val_loss: 46.8753\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6361 - val_loss: 46.8438\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6695 - val_loss: 46.7999\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6271 - val_loss: 46.9551\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6800 - val_loss: 46.9112\n",
      "\n",
      "Mean Squared Error for iteration15: 46.24719695287965\n",
      "\n",
      "Iteration: 16\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6413 - val_loss: 46.8320\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6082 - val_loss: 46.7755\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6649 - val_loss: 46.9090\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6222 - val_loss: 46.9217\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6772 - val_loss: 46.9658\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6278 - val_loss: 46.7384\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6483 - val_loss: 46.8341\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6446 - val_loss: 46.8724\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6171 - val_loss: 46.8788\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6336 - val_loss: 46.7674\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6009 - val_loss: 46.8758\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6262 - val_loss: 46.9334\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6248 - val_loss: 46.9428\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6419 - val_loss: 46.8253\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6994 - val_loss: 46.8700\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6310 - val_loss: 46.8872\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6208 - val_loss: 46.9267\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6160 - val_loss: 46.8009\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6458 - val_loss: 46.8018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6097 - val_loss: 46.8097\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6266 - val_loss: 46.8346\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6777 - val_loss: 46.8342\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6375 - val_loss: 46.9265\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6555 - val_loss: 46.7622\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6143 - val_loss: 46.8877\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6702 - val_loss: 47.0135\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6520 - val_loss: 46.7879\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6192 - val_loss: 46.8520\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6494 - val_loss: 46.9761\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6027 - val_loss: 46.9757\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6327 - val_loss: 46.9044\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6631 - val_loss: 46.9483\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6208 - val_loss: 46.8523\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6180 - val_loss: 46.7969\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6471 - val_loss: 46.8534\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6492 - val_loss: 46.8158\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6179 - val_loss: 46.9555\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.6421 - val_loss: 47.0309\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6616 - val_loss: 46.9786\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6477 - val_loss: 46.8370\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6111 - val_loss: 46.8673\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6354 - val_loss: 46.8397\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6099 - val_loss: 46.8834\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6141 - val_loss: 46.8116\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6552 - val_loss: 46.7576\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6364 - val_loss: 46.9481\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7087 - val_loss: 46.8805\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6680 - val_loss: 46.9291\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6508 - val_loss: 46.9506\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6396 - val_loss: 46.8315\n",
      "\n",
      "Mean Squared Error for iteration16: 46.02856228145513\n",
      "\n",
      "Iteration: 17\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.6507 - val_loss: 46.8969\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6326 - val_loss: 46.9093\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6474 - val_loss: 46.9982\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6670 - val_loss: 46.8021\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6862 - val_loss: 46.8465\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6776 - val_loss: 46.7623\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6185 - val_loss: 46.8396\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6162 - val_loss: 46.9080\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6274 - val_loss: 46.8105\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 26.6228 - val_loss: 46.8386\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 26.6299 - val_loss: 46.9327\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 26.6270 - val_loss: 46.9289\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6104 - val_loss: 46.8601\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6766 - val_loss: 46.9230\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6035 - val_loss: 46.8935\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6110 - val_loss: 46.9218\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6441 - val_loss: 46.8240\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6024 - val_loss: 46.8750\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6412 - val_loss: 46.9141\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6405 - val_loss: 46.8543\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6370 - val_loss: 46.8441\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6280 - val_loss: 46.9401\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6064 - val_loss: 46.8546\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 156us/step - loss: 26.6206 - val_loss: 46.8101\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7507 - val_loss: 46.9172\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7430 - val_loss: 46.9777\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6325 - val_loss: 46.7929\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 26.6163 - val_loss: 46.9322\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 141us/step - loss: 26.6270 - val_loss: 46.8585\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.6039 - val_loss: 46.9576\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 152us/step - loss: 26.6197 - val_loss: 46.9015\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5988 - val_loss: 46.8985\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.6810 - val_loss: 46.8548\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 335us/step - loss: 26.7154 - val_loss: 46.9860\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6168 - val_loss: 46.8850\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 133us/step - loss: 26.6220 - val_loss: 46.9435\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6390 - val_loss: 46.8442\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6096 - val_loss: 46.9107\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6308 - val_loss: 46.8038\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6650 - val_loss: 46.9133\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6631 - val_loss: 46.9274\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.8131 - val_loss: 46.9246\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.7089 - val_loss: 46.9045\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6183 - val_loss: 46.9121\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6393 - val_loss: 46.8050\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6816 - val_loss: 47.0043\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 104us/step - loss: 26.6241 - val_loss: 46.7983\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6168 - val_loss: 46.8977\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6703 - val_loss: 46.8667\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6573 - val_loss: 46.9766\n",
      "\n",
      "Mean Squared Error for iteration17: 46.2351326715144\n",
      "\n",
      "Iteration: 18\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6333 - val_loss: 46.8167\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6499 - val_loss: 46.8703\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6322 - val_loss: 46.8525\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6950 - val_loss: 46.9296\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6108 - val_loss: 46.8929\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6481 - val_loss: 46.9052\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7066 - val_loss: 46.9015\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6027 - val_loss: 46.8792\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6273 - val_loss: 46.9678\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.7732 - val_loss: 46.7381\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6178 - val_loss: 46.8493\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6233 - val_loss: 46.9283\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6117 - val_loss: 46.8497\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6448 - val_loss: 46.8697\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6156 - val_loss: 46.8749\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.6189 - val_loss: 46.9687\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6677 - val_loss: 46.9513\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.6715 - val_loss: 46.8632\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.7197 - val_loss: 46.9216\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6088 - val_loss: 46.8257\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6755 - val_loss: 46.8485\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6580 - val_loss: 46.9656\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6349 - val_loss: 46.9802\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6421 - val_loss: 46.8656\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6081 - val_loss: 46.9424\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6382 - val_loss: 46.9628\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6395 - val_loss: 46.8304\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6109 - val_loss: 46.8901\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6526 - val_loss: 46.9604\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6472 - val_loss: 46.8557\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6154 - val_loss: 46.8784\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6184 - val_loss: 46.8597\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6557 - val_loss: 46.9155\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6529 - val_loss: 46.9872\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6213 - val_loss: 46.9643\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6238 - val_loss: 46.9484\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6339 - val_loss: 46.8335\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6371 - val_loss: 46.9037\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6503 - val_loss: 46.9001\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6370 - val_loss: 46.9140\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6400 - val_loss: 46.9251\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6244 - val_loss: 46.8665\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6213 - val_loss: 46.9224\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6625 - val_loss: 46.8861\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6328 - val_loss: 46.8541\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5986 - val_loss: 46.8372\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6417 - val_loss: 46.9492\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6849 - val_loss: 47.0080\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6163 - val_loss: 46.9503\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6371 - val_loss: 46.8693\n",
      "\n",
      "Mean Squared Error for iteration18: 46.09442791906821\n",
      "\n",
      "Iteration: 19\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.6527 - val_loss: 46.9264\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6550 - val_loss: 46.9358\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6432 - val_loss: 46.8685\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6415 - val_loss: 46.9110\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6455 - val_loss: 46.9246\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6346 - val_loss: 46.9128\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6376 - val_loss: 46.9042\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6327 - val_loss: 46.8888\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6193 - val_loss: 46.8763\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6263 - val_loss: 46.9199\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6012 - val_loss: 46.8908\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6389 - val_loss: 46.8803\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6549 - val_loss: 46.9896\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6940 - val_loss: 47.0155\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6630 - val_loss: 46.9032\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6024 - val_loss: 46.8185\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6330 - val_loss: 46.9815\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6182 - val_loss: 46.9557\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6075 - val_loss: 46.8900\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6475 - val_loss: 46.9090\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6100 - val_loss: 46.9550\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6359 - val_loss: 46.9389\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6120 - val_loss: 46.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6497 - val_loss: 46.9390\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6457 - val_loss: 46.9174\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6019 - val_loss: 46.9207\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6372 - val_loss: 47.0245\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6275 - val_loss: 46.9167\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6661 - val_loss: 46.8197\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6206 - val_loss: 46.8535\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6197 - val_loss: 46.8521\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6912 - val_loss: 46.9302\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6440 - val_loss: 46.9609\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6451 - val_loss: 46.9306\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6554 - val_loss: 46.7748\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6482 - val_loss: 46.9436\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6556 - val_loss: 46.9173\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6176 - val_loss: 46.9574\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6409 - val_loss: 46.8045\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5969 - val_loss: 46.9162\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6551 - val_loss: 46.9430\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6971 - val_loss: 47.0487\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6558 - val_loss: 46.9686\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6240 - val_loss: 46.9305\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6530 - val_loss: 46.9109\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6090 - val_loss: 46.9909\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6513 - val_loss: 46.8598\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6005 - val_loss: 46.9378\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6376 - val_loss: 46.9557\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6317 - val_loss: 46.9349\n",
      "\n",
      "Mean Squared Error for iteration19: 46.06600739703251\n",
      "\n",
      "Iteration: 20\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6613 - val_loss: 46.8166\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6325 - val_loss: 46.9054\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6218 - val_loss: 46.9182\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5882 - val_loss: 46.9837\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6219 - val_loss: 46.8836\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6066 - val_loss: 46.8973\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6202 - val_loss: 46.9286\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5930 - val_loss: 46.9692\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6515 - val_loss: 46.8751\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5939 - val_loss: 46.9368\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.7055 - val_loss: 46.8818\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6466 - val_loss: 46.9397\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6095 - val_loss: 46.9396\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6110 - val_loss: 46.8726\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6055 - val_loss: 46.8711\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6305 - val_loss: 46.9878\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6304 - val_loss: 46.9304\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6786 - val_loss: 46.9630\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6455 - val_loss: 46.9065\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6592 - val_loss: 46.8372\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6380 - val_loss: 46.9435\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5938 - val_loss: 46.9543\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6108 - val_loss: 46.9528\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6042 - val_loss: 47.0044\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6920 - val_loss: 46.8234\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6090 - val_loss: 46.9419\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6188 - val_loss: 46.9579\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6328 - val_loss: 46.9013\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6127 - val_loss: 46.9273\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6022 - val_loss: 46.9433\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5976 - val_loss: 46.9554\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6357 - val_loss: 46.9965\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6772 - val_loss: 46.9394\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6006 - val_loss: 46.8806\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6024 - val_loss: 46.9037\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6827 - val_loss: 46.8928\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6211 - val_loss: 46.9595\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6327 - val_loss: 46.9156\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 126us/step - loss: 26.6867 - val_loss: 47.0163\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.6960 - val_loss: 46.8121\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 26.6144 - val_loss: 46.9478\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 196us/step - loss: 26.6400 - val_loss: 46.9359\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 26.5982 - val_loss: 46.9284\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 161us/step - loss: 26.6047 - val_loss: 46.9395\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 26.6218 - val_loss: 46.8783\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 191us/step - loss: 26.6422 - val_loss: 47.0181\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 242us/step - loss: 26.6407 - val_loss: 46.9549\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 130us/step - loss: 26.6197 - val_loss: 46.8938\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 226us/step - loss: 26.6251 - val_loss: 46.9696\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 248us/step - loss: 26.6140 - val_loss: 47.0171\n",
      "\n",
      "Mean Squared Error for iteration20: 46.08975923436375\n",
      "\n",
      "Iteration: 21\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 93us/step - loss: 26.6280 - val_loss: 46.9256\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6427 - val_loss: 46.9418\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6349 - val_loss: 46.9084\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.6119 - val_loss: 46.9807\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6976 - val_loss: 46.7642\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 153us/step - loss: 26.6203 - val_loss: 46.9860\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 636us/step - loss: 26.6486 - val_loss: 46.9501\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 285us/step - loss: 26.6245 - val_loss: 46.9655\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 212us/step - loss: 26.6372 - val_loss: 46.9038\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 315us/step - loss: 26.7280 - val_loss: 46.8573\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 281us/step - loss: 26.6618 - val_loss: 47.0358\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 168us/step - loss: 26.6548 - val_loss: 46.9280\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 198us/step - loss: 26.6330 - val_loss: 47.0306\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - ETA: 0s - loss: 26.65 - 0s 346us/step - loss: 26.6139 - val_loss: 46.9053\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 267us/step - loss: 26.6575 - val_loss: 46.9351\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 26.6098 - val_loss: 46.9134\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 26.6292 - val_loss: 46.9972\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 155us/step - loss: 26.6270 - val_loss: 47.0244\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 333us/step - loss: 26.6339 - val_loss: 46.8975\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 220us/step - loss: 26.6023 - val_loss: 46.9027\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6680 - val_loss: 47.0537\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.5953 - val_loss: 46.9467\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5861 - val_loss: 46.9632\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 26.6155 - val_loss: 46.9671\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 26.6673 - val_loss: 46.9308\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 140us/step - loss: 26.6122 - val_loss: 46.8801\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 174us/step - loss: 26.6246 - val_loss: 46.9649\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 156us/step - loss: 26.6478 - val_loss: 46.9491\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 26.6218 - val_loss: 46.9623\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 131us/step - loss: 26.6391 - val_loss: 46.9854\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 197us/step - loss: 26.6293 - val_loss: 47.0041\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 319us/step - loss: 26.6401 - val_loss: 47.0184\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 246us/step - loss: 26.6212 - val_loss: 46.9177\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 185us/step - loss: 26.6559 - val_loss: 46.8730\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 26.6325 - val_loss: 47.0503\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 493us/step - loss: 26.5972 - val_loss: 46.9095\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 189us/step - loss: 26.6063 - val_loss: 46.9124\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 26.6205 - val_loss: 46.9671\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 152us/step - loss: 26.6369 - val_loss: 46.8872\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 118us/step - loss: 26.6817 - val_loss: 47.0064\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 134us/step - loss: 26.5942 - val_loss: 46.9686\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 120us/step - loss: 26.6216 - val_loss: 46.9873\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 26.6179 - val_loss: 46.8515\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 152us/step - loss: 26.6348 - val_loss: 46.9979\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 496us/step - loss: 26.7127 - val_loss: 46.9577\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 269us/step - loss: 26.5630 - val_loss: 46.9585\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 129us/step - loss: 26.6845 - val_loss: 47.0548\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 127us/step - loss: 26.6290 - val_loss: 46.8817\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 221us/step - loss: 26.6434 - val_loss: 46.8508\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 188us/step - loss: 26.6434 - val_loss: 46.8876\n",
      "\n",
      "Mean Squared Error for iteration21: 45.96332485207162\n",
      "\n",
      "Iteration: 22\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 197us/step - loss: 26.6044 - val_loss: 46.9433\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6414 - val_loss: 47.0459\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 26.6084 - val_loss: 46.9362\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5961 - val_loss: 46.9027\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.7174 - val_loss: 46.9266\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 125us/step - loss: 26.5933 - val_loss: 47.0013\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 193us/step - loss: 26.5925 - val_loss: 47.0188\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 143us/step - loss: 26.6266 - val_loss: 46.9740\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 275us/step - loss: 26.6485 - val_loss: 46.9449\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 235us/step - loss: 26.6444 - val_loss: 46.9414\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 203us/step - loss: 26.6472 - val_loss: 46.8653\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 165us/step - loss: 26.5935 - val_loss: 47.0030\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 165us/step - loss: 26.6499 - val_loss: 47.0145\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 26.5922 - val_loss: 47.0178\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.6334 - val_loss: 46.9765\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 115us/step - loss: 26.6371 - val_loss: 46.9397\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 26.6205 - val_loss: 47.0297\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.6455 - val_loss: 47.0085\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 300us/step - loss: 26.5968 - val_loss: 46.9089\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 214us/step - loss: 26.6448 - val_loss: 46.9757\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 26.5990 - val_loss: 46.9780\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 496us/step - loss: 26.6620 - val_loss: 47.0318\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 148us/step - loss: 26.6048 - val_loss: 46.9039\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 167us/step - loss: 26.6231 - val_loss: 46.9210\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 202us/step - loss: 26.5875 - val_loss: 46.9164\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 204us/step - loss: 26.6842 - val_loss: 46.9043\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 167us/step - loss: 26.6318 - val_loss: 47.0761\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 153us/step - loss: 26.6022 - val_loss: 47.0270\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 26.5981 - val_loss: 46.9682\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 124us/step - loss: 26.5999 - val_loss: 46.9585\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6414 - val_loss: 46.9630\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6015 - val_loss: 46.8936\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6198 - val_loss: 47.0076\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6517 - val_loss: 46.9917\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6236 - val_loss: 47.1247\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6082 - val_loss: 47.0088\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6457 - val_loss: 46.9841\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6047 - val_loss: 46.9295\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6381 - val_loss: 46.9421\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6564 - val_loss: 46.9876\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6418 - val_loss: 46.8947\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6369 - val_loss: 47.0070\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6381 - val_loss: 46.9843\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6466 - val_loss: 46.9833\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6076 - val_loss: 47.0246\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6258 - val_loss: 47.0536\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6010 - val_loss: 46.9858\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6717 - val_loss: 46.8798\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6644 - val_loss: 47.0399\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6468 - val_loss: 46.9869\n",
      "\n",
      "Mean Squared Error for iteration22: 46.175452425378694\n",
      "\n",
      "Iteration: 23\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6332 - val_loss: 46.9605\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6222 - val_loss: 46.9533\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6558 - val_loss: 46.9811\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6147 - val_loss: 47.0368\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6209 - val_loss: 46.9754\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 175us/step - loss: 26.6557 - val_loss: 47.0496\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 26.6063 - val_loss: 46.8993\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6288 - val_loss: 46.9694\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6217 - val_loss: 46.8919\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6400 - val_loss: 47.0900\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6660 - val_loss: 47.0956\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6428 - val_loss: 46.9748\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5870 - val_loss: 46.9848\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6461 - val_loss: 46.9437\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6972 - val_loss: 46.9564\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5562 - val_loss: 46.9722\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6466 - val_loss: 47.0962\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6165 - val_loss: 46.9934\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6487 - val_loss: 47.1414\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5950 - val_loss: 46.9885\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 178us/step - loss: 26.6207 - val_loss: 47.0161\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 26.6123 - val_loss: 47.0112\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 176us/step - loss: 26.5938 - val_loss: 46.9627\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6154 - val_loss: 47.0055\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6303 - val_loss: 47.0129\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6932 - val_loss: 47.0104\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6627 - val_loss: 46.9421\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6115 - val_loss: 46.9689\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5963 - val_loss: 46.9597\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6228 - val_loss: 46.9758\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6662 - val_loss: 46.9794\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6305 - val_loss: 46.9334\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5866 - val_loss: 46.9635\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6200 - val_loss: 47.0404\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6193 - val_loss: 47.0223\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 26.5982 - val_loss: 47.1113\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 26.6200 - val_loss: 46.9997\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 26.6195 - val_loss: 46.9440\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.6530 - val_loss: 47.0064\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 139us/step - loss: 26.6016 - val_loss: 46.9590\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6511 - val_loss: 47.0112\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6280 - val_loss: 46.9991\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6287 - val_loss: 46.9808\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6199 - val_loss: 47.0147\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.5991 - val_loss: 47.0568\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6605 - val_loss: 46.9982\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5853 - val_loss: 47.0056\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 150us/step - loss: 26.7048 - val_loss: 47.1293\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 185us/step - loss: 26.5811 - val_loss: 46.9035\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 165us/step - loss: 26.6274 - val_loss: 46.8952\n",
      "\n",
      "Mean Squared Error for iteration23: 46.172156052882976\n",
      "\n",
      "Iteration: 24\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 144us/step - loss: 26.6679 - val_loss: 47.0643\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 26.6296 - val_loss: 47.0375\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 169us/step - loss: 26.6239 - val_loss: 47.0399\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 264us/step - loss: 26.5866 - val_loss: 47.0332\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6068 - val_loss: 46.9926\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6273 - val_loss: 47.0086\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5935 - val_loss: 47.0660\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6327 - val_loss: 46.9753\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 238us/step - loss: 26.6310 - val_loss: 47.0279\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.5736 - val_loss: 47.0691\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 121us/step - loss: 26.7711 - val_loss: 47.0525\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6262 - val_loss: 46.9145\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.6616 - val_loss: 47.0427\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6388 - val_loss: 47.0497\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.5996 - val_loss: 46.9740\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 26.6070 - val_loss: 47.0037\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6284 - val_loss: 46.9882\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 26.5766 - val_loss: 46.9898\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6068 - val_loss: 46.9693\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6091 - val_loss: 46.9766\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6284 - val_loss: 47.0144\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5985 - val_loss: 47.0696\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6413 - val_loss: 47.0709\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6515 - val_loss: 47.0342\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6979 - val_loss: 46.9922\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.5996 - val_loss: 47.0237\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6222 - val_loss: 46.9490\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6147 - val_loss: 47.0458\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6748 - val_loss: 47.0641\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6220 - val_loss: 47.0617\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6697 - val_loss: 47.0876\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6218 - val_loss: 47.0768\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5978 - val_loss: 46.9617\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5916 - val_loss: 46.9531\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6299 - val_loss: 46.9941\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5742 - val_loss: 47.0563\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6014 - val_loss: 46.9773\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.5863 - val_loss: 46.9872\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6218 - val_loss: 47.0479\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6039 - val_loss: 47.0902\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6009 - val_loss: 47.0892\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5960 - val_loss: 47.0370\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6217 - val_loss: 46.9779\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6713 - val_loss: 47.0385\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6186 - val_loss: 47.0540\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6023 - val_loss: 47.0937\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6189 - val_loss: 47.1188\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5604 - val_loss: 47.0018\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6378 - val_loss: 46.9473\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5976 - val_loss: 47.0164\n",
      "\n",
      "Mean Squared Error for iteration24: 46.174321139891845\n",
      "\n",
      "Iteration: 25\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6131 - val_loss: 47.0446\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6114 - val_loss: 47.0298\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6165 - val_loss: 47.0326\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6464 - val_loss: 47.1055\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5995 - val_loss: 47.0416\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6791 - val_loss: 46.9671\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6082 - val_loss: 47.0432\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6474 - val_loss: 47.1529\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6383 - val_loss: 46.9316\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6023 - val_loss: 47.0439\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7214 - val_loss: 47.0675\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5837 - val_loss: 47.1031\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6015 - val_loss: 47.0681\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6187 - val_loss: 47.1114\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5949 - val_loss: 47.0457\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6203 - val_loss: 46.9112\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6089 - val_loss: 47.0223\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.7039 - val_loss: 47.1306\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 189us/step - loss: 26.5772 - val_loss: 47.1356\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6029 - val_loss: 47.0110\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6333 - val_loss: 47.1205\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6614 - val_loss: 47.0664\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6661 - val_loss: 46.9905\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6540 - val_loss: 46.9456\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6129 - val_loss: 47.0860\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6306 - val_loss: 47.1066\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6260 - val_loss: 47.0433\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5965 - val_loss: 46.9680\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6005 - val_loss: 47.0605\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6492 - val_loss: 47.0682\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6682 - val_loss: 47.1418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6270 - val_loss: 47.0337\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6049 - val_loss: 47.1338\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6036 - val_loss: 47.0794\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5952 - val_loss: 47.0536\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5833 - val_loss: 47.0522\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5909 - val_loss: 46.9841\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6785 - val_loss: 47.0241\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5878 - val_loss: 47.0299\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5907 - val_loss: 47.0596\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5996 - val_loss: 47.1193\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5931 - val_loss: 47.0771\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5973 - val_loss: 47.0892\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5888 - val_loss: 47.0051\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6420 - val_loss: 47.1401\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6039 - val_loss: 47.1193\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 26.6589 - val_loss: 46.9572\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5747 - val_loss: 47.0370\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6110 - val_loss: 47.0353\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6478 - val_loss: 47.1505\n",
      "\n",
      "Mean Squared Error for iteration25: 46.45569206285649\n",
      "\n",
      "Iteration: 26\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6349 - val_loss: 47.0820\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5946 - val_loss: 47.0307\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5972 - val_loss: 46.9993\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6318 - val_loss: 47.1654\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6550 - val_loss: 47.0351\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6437 - val_loss: 47.1041\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6336 - val_loss: 47.0651\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5657 - val_loss: 47.1593\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6118 - val_loss: 47.1289\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6395 - val_loss: 47.0173\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6286 - val_loss: 47.0967\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6088 - val_loss: 47.1198\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6330 - val_loss: 47.0911\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6038 - val_loss: 47.1242\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6329 - val_loss: 47.0717\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5964 - val_loss: 47.0596\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5742 - val_loss: 47.1020\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6307 - val_loss: 47.1270\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6116 - val_loss: 47.1056\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6836 - val_loss: 47.0953\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6079 - val_loss: 47.1000\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6345 - val_loss: 47.1201\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6440 - val_loss: 47.0799\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6156 - val_loss: 46.9778\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6063 - val_loss: 47.0354\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6438 - val_loss: 47.1093\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6177 - val_loss: 47.1457\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6905 - val_loss: 47.0745\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6058 - val_loss: 47.1497\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5796 - val_loss: 47.0408\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6072 - val_loss: 47.0397\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6642 - val_loss: 47.2201\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6991 - val_loss: 47.1724\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6580 - val_loss: 46.9695\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6372 - val_loss: 47.1905\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5840 - val_loss: 47.0467\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5905 - val_loss: 47.0669\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6161 - val_loss: 47.1009\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6013 - val_loss: 47.0983\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6336 - val_loss: 47.1455\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5811 - val_loss: 47.1171\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5813 - val_loss: 47.0201\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5807 - val_loss: 47.0505\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6192 - val_loss: 47.0786\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6481 - val_loss: 47.0958\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6400 - val_loss: 47.1083\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6157 - val_loss: 47.0380\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6105 - val_loss: 47.0335\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6107 - val_loss: 47.1226\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6439 - val_loss: 47.1689\n",
      "\n",
      "Mean Squared Error for iteration26: 46.250601244590605\n",
      "\n",
      "Iteration: 27\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5888 - val_loss: 47.1545\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6072 - val_loss: 47.0971\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5995 - val_loss: 47.0952\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5947 - val_loss: 47.0965\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6131 - val_loss: 47.1376\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6555 - val_loss: 47.1946\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6238 - val_loss: 46.9671\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 74us/step - loss: 26.6394 - val_loss: 47.1050\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5830 - val_loss: 47.1439\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6434 - val_loss: 47.1652\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5967 - val_loss: 47.2159\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5897 - val_loss: 47.0844\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5965 - val_loss: 47.1409\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5938 - val_loss: 47.0854\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6053 - val_loss: 47.0560\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6048 - val_loss: 47.1512\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6767 - val_loss: 47.0570\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6265 - val_loss: 47.1161\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6304 - val_loss: 47.1977\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6754 - val_loss: 47.1123\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6147 - val_loss: 47.1531\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6070 - val_loss: 47.0301\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5967 - val_loss: 47.1376\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6313 - val_loss: 47.1114\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6364 - val_loss: 47.2069\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.5806 - val_loss: 47.0471\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6754 - val_loss: 47.0103\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6111 - val_loss: 47.1286\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5937 - val_loss: 47.1012\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6531 - val_loss: 47.2685\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6129 - val_loss: 47.1051\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6220 - val_loss: 47.1526\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6042 - val_loss: 47.0991\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6300 - val_loss: 47.0322\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5909 - val_loss: 47.0974\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6280 - val_loss: 47.1502\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5968 - val_loss: 47.0731\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5985 - val_loss: 47.1110\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5886 - val_loss: 47.1235\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5901 - val_loss: 47.0419\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5844 - val_loss: 47.0598\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5786 - val_loss: 47.1187\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6054 - val_loss: 47.0471\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6247 - val_loss: 47.1061\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5895 - val_loss: 47.1955\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5844 - val_loss: 47.0859\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5889 - val_loss: 47.0908\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 120us/step - loss: 26.5963 - val_loss: 47.1632\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5795 - val_loss: 47.1837\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6501 - val_loss: 47.0898\n",
      "\n",
      "Mean Squared Error for iteration27: 46.09060631800432\n",
      "\n",
      "Iteration: 28\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5862 - val_loss: 47.1699\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6432 - val_loss: 47.1261\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6803 - val_loss: 47.0742\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6693 - val_loss: 47.3192\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6108 - val_loss: 47.0949\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6016 - val_loss: 47.0656\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6378 - val_loss: 46.9645\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6519 - val_loss: 47.1490\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5917 - val_loss: 47.1010\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6053 - val_loss: 47.0245\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.5730 - val_loss: 47.1291\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6913 - val_loss: 47.1638\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6164 - val_loss: 47.1968\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5687 - val_loss: 47.1657\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5654 - val_loss: 47.1130\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6388 - val_loss: 47.1086\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6311 - val_loss: 47.0503\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6091 - val_loss: 47.1772\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6001 - val_loss: 47.1374\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.5794 - val_loss: 47.1561\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5822 - val_loss: 47.0823\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5811 - val_loss: 47.1232\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5705 - val_loss: 47.1264\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6600 - val_loss: 47.2143\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6139 - val_loss: 47.1412\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6047 - val_loss: 47.0450\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6157 - val_loss: 47.1152\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5898 - val_loss: 47.0786\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6114 - val_loss: 47.1727\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6069 - val_loss: 47.1368\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5955 - val_loss: 47.1542\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 129us/step - loss: 26.5935 - val_loss: 47.1821\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 302us/step - loss: 26.5821 - val_loss: 47.1415\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 177us/step - loss: 26.5726 - val_loss: 47.0398\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 162us/step - loss: 26.6043 - val_loss: 47.1116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 26.6435 - val_loss: 47.1377\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 141us/step - loss: 26.5764 - val_loss: 47.1111\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6047 - val_loss: 47.2499\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5963 - val_loss: 47.0637\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5941 - val_loss: 47.1655\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6301 - val_loss: 47.2315\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5946 - val_loss: 47.0580\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5866 - val_loss: 47.0975\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5959 - val_loss: 47.1194\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5737 - val_loss: 47.1435\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5985 - val_loss: 47.2034\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6112 - val_loss: 47.2010\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 176us/step - loss: 26.5841 - val_loss: 47.0994\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 156us/step - loss: 26.6143 - val_loss: 47.1246\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 173us/step - loss: 26.6232 - val_loss: 47.0918\n",
      "\n",
      "Mean Squared Error for iteration28: 46.08846684660172\n",
      "\n",
      "Iteration: 29\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5895 - val_loss: 47.1631\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6528 - val_loss: 47.0165\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6146 - val_loss: 47.1028\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5866 - val_loss: 47.1095\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6793 - val_loss: 47.2764\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6471 - val_loss: 47.2579\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6133 - val_loss: 47.0788\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6135 - val_loss: 47.0675\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6136 - val_loss: 47.1472\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6019 - val_loss: 47.1064\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5879 - val_loss: 47.1569\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6151 - val_loss: 47.2325\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6033 - val_loss: 47.2601\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5727 - val_loss: 47.1130\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5866 - val_loss: 47.1068\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6077 - val_loss: 47.1410\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6160 - val_loss: 47.1377\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5803 - val_loss: 47.1543\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6179 - val_loss: 47.2025\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5889 - val_loss: 47.0685\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6075 - val_loss: 47.1365\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6188 - val_loss: 47.1157\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.5643 - val_loss: 47.0979\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5940 - val_loss: 47.1090\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6206 - val_loss: 47.0867\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5948 - val_loss: 47.1415\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 137us/step - loss: 26.6212 - val_loss: 47.0821\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 179us/step - loss: 26.6144 - val_loss: 47.1517\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 121us/step - loss: 26.6188 - val_loss: 47.1716\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6067 - val_loss: 47.1119\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5765 - val_loss: 47.1607\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6128 - val_loss: 47.2267\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5962 - val_loss: 47.1287\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6765 - val_loss: 47.1863\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5859 - val_loss: 47.0617\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5998 - val_loss: 47.1547\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6004 - val_loss: 47.1600\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6671 - val_loss: 47.1428\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6224 - val_loss: 47.0604\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6089 - val_loss: 47.1714\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6011 - val_loss: 47.1969\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5754 - val_loss: 47.1052\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5831 - val_loss: 47.0454\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6138 - val_loss: 47.1713\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5927 - val_loss: 47.0962\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6386 - val_loss: 47.1664\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6539 - val_loss: 47.1734\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5855 - val_loss: 47.2239\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6295 - val_loss: 47.1689\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6001 - val_loss: 47.1773\n",
      "\n",
      "Mean Squared Error for iteration29: 46.12279388144785\n",
      "\n",
      "Iteration: 30\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6342 - val_loss: 47.0633\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5953 - val_loss: 47.2176\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6202 - val_loss: 47.0797\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5935 - val_loss: 47.1304\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6238 - val_loss: 47.1938\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6398 - val_loss: 47.2712\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6072 - val_loss: 47.1435\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5993 - val_loss: 47.0637\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6139 - val_loss: 47.2318\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5855 - val_loss: 47.2712\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5642 - val_loss: 47.1532\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 73us/step - loss: 26.5871 - val_loss: 47.1877\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6345 - val_loss: 47.1551\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.7074 - val_loss: 47.1032\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6394 - val_loss: 47.1186\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5994 - val_loss: 47.0624\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5979 - val_loss: 47.2267\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6386 - val_loss: 47.1561\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5880 - val_loss: 47.1634\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6275 - val_loss: 47.2453\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5991 - val_loss: 47.1640\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.5982 - val_loss: 47.1608\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5741 - val_loss: 47.1514\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5839 - val_loss: 47.1457\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5613 - val_loss: 47.1627\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6608 - val_loss: 47.1442\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5835 - val_loss: 47.1026\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6254 - val_loss: 47.1869\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6244 - val_loss: 47.2156\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6151 - val_loss: 47.0995\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6443 - val_loss: 47.1183\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5570 - val_loss: 47.0630\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5948 - val_loss: 47.2324\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5977 - val_loss: 47.1562\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6282 - val_loss: 47.1376\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5903 - val_loss: 47.1233\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6034 - val_loss: 47.0899\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5615 - val_loss: 47.2323\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5715 - val_loss: 47.1714\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6136 - val_loss: 47.1376\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5694 - val_loss: 47.1144\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6955 - val_loss: 47.2226\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6558 - val_loss: 47.2246\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5593 - val_loss: 47.1833\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6359 - val_loss: 47.0745\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6491 - val_loss: 47.1082\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6323 - val_loss: 47.2228\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5828 - val_loss: 47.2041\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5678 - val_loss: 47.1418\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5881 - val_loss: 47.0913\n",
      "\n",
      "Mean Squared Error for iteration30: 46.04800886867195\n",
      "\n",
      "Iteration: 31\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5942 - val_loss: 47.1317\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6189 - val_loss: 47.1088\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5858 - val_loss: 47.0839\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6259 - val_loss: 47.1619\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6487 - val_loss: 47.1903\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5767 - val_loss: 47.1430\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5672 - val_loss: 47.2028\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6181 - val_loss: 47.0791\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6377 - val_loss: 47.2250\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5806 - val_loss: 47.1991\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5801 - val_loss: 47.1652\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6174 - val_loss: 47.0812\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5635 - val_loss: 47.0798\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5757 - val_loss: 47.1278\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6317 - val_loss: 47.1919\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6016 - val_loss: 47.1144\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6860 - val_loss: 47.1559\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5980 - val_loss: 47.2550\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5948 - val_loss: 47.1586\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6504 - val_loss: 47.2165\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5750 - val_loss: 47.1079\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5968 - val_loss: 47.1542\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5774 - val_loss: 47.1855\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5889 - val_loss: 47.1296\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6002 - val_loss: 47.2451\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6010 - val_loss: 47.2159\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5597 - val_loss: 47.1791\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6085 - val_loss: 47.1698\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5827 - val_loss: 47.0936\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6021 - val_loss: 47.2250\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6036 - val_loss: 47.0882\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5740 - val_loss: 47.1208\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6077 - val_loss: 47.2282\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6630 - val_loss: 47.1483\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5562 - val_loss: 47.1752\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6355 - val_loss: 47.3007\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6136 - val_loss: 47.2251\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6015 - val_loss: 47.1590\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5885 - val_loss: 47.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6021 - val_loss: 47.1368\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5853 - val_loss: 47.1712\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5687 - val_loss: 47.1172\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5977 - val_loss: 47.2780\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5960 - val_loss: 47.0996\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5909 - val_loss: 47.1296\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6194 - val_loss: 47.3185\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5855 - val_loss: 47.1604\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6885 - val_loss: 47.2154\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6715 - val_loss: 47.0962\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5738 - val_loss: 47.2671\n",
      "\n",
      "Mean Squared Error for iteration31: 46.148491308848826\n",
      "\n",
      "Iteration: 32\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5872 - val_loss: 47.1550\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6012 - val_loss: 47.1666\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6440 - val_loss: 47.2594\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5932 - val_loss: 47.1811\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5754 - val_loss: 47.1233\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5696 - val_loss: 47.1607\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6158 - val_loss: 47.1249\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6232 - val_loss: 47.2272\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6185 - val_loss: 47.1796\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5724 - val_loss: 47.1155\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5900 - val_loss: 47.1946\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6293 - val_loss: 47.0842\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5612 - val_loss: 47.2281\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6088 - val_loss: 47.2901\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5765 - val_loss: 47.1186\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5883 - val_loss: 47.1553\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6383 - val_loss: 47.1941\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6476 - val_loss: 47.2135\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5604 - val_loss: 47.1499\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.6380 - val_loss: 47.2069\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.5569 - val_loss: 47.2320\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.5663 - val_loss: 47.1062\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5805 - val_loss: 47.1980\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6118 - val_loss: 47.1686\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5801 - val_loss: 47.1953\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.6135 - val_loss: 47.0891\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.5999 - val_loss: 47.2565\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6103 - val_loss: 47.1608\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 26.6382 - val_loss: 47.1571\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5640 - val_loss: 47.1512\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5864 - val_loss: 47.2637\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6635 - val_loss: 47.1515\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.7048 - val_loss: 47.1824\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.6588 - val_loss: 47.2288\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.5851 - val_loss: 47.1792\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5878 - val_loss: 47.1534\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6049 - val_loss: 47.1456\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6096 - val_loss: 47.0703\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6673 - val_loss: 47.3434\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6287 - val_loss: 47.2344\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5748 - val_loss: 47.1340\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6048 - val_loss: 47.1934\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5936 - val_loss: 47.2151\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5732 - val_loss: 47.1587\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.5700 - val_loss: 47.1375\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6109 - val_loss: 47.2748\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6004 - val_loss: 47.1538\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6408 - val_loss: 47.1770\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6378 - val_loss: 47.2406\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6568 - val_loss: 47.1318\n",
      "\n",
      "Mean Squared Error for iteration32: 46.083823841821236\n",
      "\n",
      "Iteration: 33\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6304 - val_loss: 47.2144\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6116 - val_loss: 47.1142\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5655 - val_loss: 47.0954\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6443 - val_loss: 47.1790\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6114 - val_loss: 47.2924\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6085 - val_loss: 47.1303\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5932 - val_loss: 47.2376\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5792 - val_loss: 47.0891\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6134 - val_loss: 47.1541\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5672 - val_loss: 47.2079\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5959 - val_loss: 47.2563\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5771 - val_loss: 47.1627\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5889 - val_loss: 47.1018\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6024 - val_loss: 47.2221\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5770 - val_loss: 47.1887\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 75us/step - loss: 26.5792 - val_loss: 47.2779\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 26.5973 - val_loss: 47.1889\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5472 - val_loss: 47.0936\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5647 - val_loss: 47.1874\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 138us/step - loss: 26.5606 - val_loss: 47.1687\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6403 - val_loss: 47.1613\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5708 - val_loss: 47.2206\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6001 - val_loss: 47.2039\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6281 - val_loss: 47.2016\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6220 - val_loss: 47.1878\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 158us/step - loss: 26.6030 - val_loss: 47.1793\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 26.6209 - val_loss: 47.3170\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 151us/step - loss: 26.5882 - val_loss: 47.1491\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 216us/step - loss: 26.5707 - val_loss: 47.1827\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5555 - val_loss: 47.1727\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 26.6277 - val_loss: 47.1974\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 170us/step - loss: 26.6147 - val_loss: 47.2267\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 26.5879 - val_loss: 47.1661\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 155us/step - loss: 26.6002 - val_loss: 47.1341\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.7499 - val_loss: 47.2910\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5310 - val_loss: 47.1581\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.5809 - val_loss: 47.1298\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 152us/step - loss: 26.5727 - val_loss: 47.1954\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 149us/step - loss: 26.5626 - val_loss: 47.1930\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 159us/step - loss: 26.6003 - val_loss: 47.1020\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 157us/step - loss: 26.6484 - val_loss: 47.1814\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5882 - val_loss: 47.2781\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5825 - val_loss: 47.2534\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5848 - val_loss: 47.2404\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 164us/step - loss: 26.6006 - val_loss: 47.1177\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 117us/step - loss: 26.5985 - val_loss: 47.1686\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.5600 - val_loss: 47.2363\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 138us/step - loss: 26.6257 - val_loss: 47.3196\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 360us/step - loss: 26.6087 - val_loss: 47.1448\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 412us/step - loss: 26.5633 - val_loss: 47.2199\n",
      "\n",
      "Mean Squared Error for iteration33: 46.22089821274551\n",
      "\n",
      "Iteration: 34\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 279us/step - loss: 26.5749 - val_loss: 47.2433\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5542 - val_loss: 47.2128\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 26.5639 - val_loss: 47.2277\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5982 - val_loss: 47.1484\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5788 - val_loss: 47.1194\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5570 - val_loss: 47.2127\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5859 - val_loss: 47.2412\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.5756 - val_loss: 47.1973\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 26.7279 - val_loss: 47.2582\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 26.5405 - val_loss: 47.1983\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.6038 - val_loss: 47.2700\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.6211 - val_loss: 47.1925\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5889 - val_loss: 47.1935\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6665 - val_loss: 47.1777\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6405 - val_loss: 47.1722\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5730 - val_loss: 47.1727\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5685 - val_loss: 47.2144\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5983 - val_loss: 47.1983\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6111 - val_loss: 47.1803\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 26.6142 - val_loss: 47.2838\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5931 - val_loss: 47.2453\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5982 - val_loss: 47.1728\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6311 - val_loss: 47.1909\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.5616 - val_loss: 47.1935\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6162 - val_loss: 47.2474\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6092 - val_loss: 47.1471\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5933 - val_loss: 47.1762\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6198 - val_loss: 47.2571\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5707 - val_loss: 47.2949\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5886 - val_loss: 47.1879\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.5831 - val_loss: 47.2406\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 172us/step - loss: 26.5867 - val_loss: 47.2018\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 112us/step - loss: 26.5843 - val_loss: 47.1895\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5925 - val_loss: 47.2247\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5634 - val_loss: 47.1796\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5755 - val_loss: 47.2159\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6778 - val_loss: 47.2223\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.6697 - val_loss: 47.1944\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6265 - val_loss: 47.2994\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6404 - val_loss: 47.2530\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 146us/step - loss: 26.5978 - val_loss: 47.1983\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.5788 - val_loss: 47.1313\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 100us/step - loss: 26.6315 - val_loss: 47.2094\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5458 - val_loss: 47.1544\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5769 - val_loss: 47.2399\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6097 - val_loss: 47.1589\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6131 - val_loss: 47.2861\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.6070 - val_loss: 47.1867\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5514 - val_loss: 47.1927\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.6010 - val_loss: 47.1281\n",
      "\n",
      "Mean Squared Error for iteration34: 46.04859875994265\n",
      "\n",
      "Iteration: 35\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5925 - val_loss: 47.2821\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.5513 - val_loss: 47.1935\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.7511 - val_loss: 47.3545\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5707 - val_loss: 47.1717\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.6255 - val_loss: 47.2354\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6374 - val_loss: 47.2120\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6351 - val_loss: 47.2373\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6007 - val_loss: 47.2024\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.6241 - val_loss: 47.1464\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.6042 - val_loss: 47.2626\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5809 - val_loss: 47.2959\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5641 - val_loss: 47.1706\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5960 - val_loss: 47.1979\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5703 - val_loss: 47.2561\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6071 - val_loss: 47.1622\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.6087 - val_loss: 47.2535\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5726 - val_loss: 47.2295\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.5920 - val_loss: 47.2638\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5510 - val_loss: 47.1704\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5793 - val_loss: 47.1718\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.6459 - val_loss: 47.2857\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.6397 - val_loss: 47.2325\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.6456 - val_loss: 47.1158\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5897 - val_loss: 47.2054\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5696 - val_loss: 47.1271\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.6281 - val_loss: 47.2151\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.6091 - val_loss: 47.2495\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.6343 - val_loss: 47.3448\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5728 - val_loss: 47.2231\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6212 - val_loss: 47.2387\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.5876 - val_loss: 47.2600\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.5747 - val_loss: 47.2053\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.5621 - val_loss: 47.2310\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.5726 - val_loss: 47.2017\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5764 - val_loss: 47.1390\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.5999 - val_loss: 47.2702\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5470 - val_loss: 47.2030\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5634 - val_loss: 47.2558\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6277 - val_loss: 47.2536\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5952 - val_loss: 47.2586\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5717 - val_loss: 47.1832\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5844 - val_loss: 47.2620\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6335 - val_loss: 47.1943\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5832 - val_loss: 47.2129\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5583 - val_loss: 47.2482\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5912 - val_loss: 47.2996\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 26.6269 - val_loss: 47.1504\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6514 - val_loss: 47.2192\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.5761 - val_loss: 47.2643\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5922 - val_loss: 47.2406\n",
      "\n",
      "Mean Squared Error for iteration35: 46.094467302588455\n",
      "\n",
      "Iteration: 36\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 65us/step - loss: 26.5923 - val_loss: 47.2819\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6011 - val_loss: 47.2783\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5553 - val_loss: 47.1799\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5758 - val_loss: 47.1934\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5868 - val_loss: 47.3022\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5757 - val_loss: 47.1937\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.6060 - val_loss: 47.2161\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5777 - val_loss: 47.2505\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.5602 - val_loss: 47.2650\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5766 - val_loss: 47.1989\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6065 - val_loss: 47.2002\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5759 - val_loss: 47.2039\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5858 - val_loss: 47.1873\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.6030 - val_loss: 47.2770\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.6921 - val_loss: 47.2088\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5698 - val_loss: 47.2821\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5698 - val_loss: 47.2532\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6064 - val_loss: 47.1857\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5963 - val_loss: 47.2802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.6047 - val_loss: 47.2425\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.5919 - val_loss: 47.2457\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6890 - val_loss: 47.2191\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6076 - val_loss: 47.2510\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.6682 - val_loss: 47.2141\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5933 - val_loss: 47.2192\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.5542 - val_loss: 47.2444\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5614 - val_loss: 47.2421\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.6471 - val_loss: 47.3127\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.6074 - val_loss: 47.1692\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 121us/step - loss: 26.5572 - val_loss: 47.2478\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.6027 - val_loss: 47.1880\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6076 - val_loss: 47.2283\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.5883 - val_loss: 47.1856\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.5948 - val_loss: 47.1877\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 67us/step - loss: 26.6135 - val_loss: 47.2172\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5479 - val_loss: 47.3022\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.6233 - val_loss: 47.2161\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.6042 - val_loss: 47.1867\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5975 - val_loss: 47.3410\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5806 - val_loss: 47.2965\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5852 - val_loss: 47.1378\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5518 - val_loss: 47.2767\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6086 - val_loss: 47.2950\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6012 - val_loss: 47.2827\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6397 - val_loss: 47.1437\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5520 - val_loss: 47.2417\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5960 - val_loss: 47.2145\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.5964 - val_loss: 47.2275\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5809 - val_loss: 47.2883\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5717 - val_loss: 47.1732\n",
      "\n",
      "Mean Squared Error for iteration36: 46.079890863310844\n",
      "\n",
      "Iteration: 37\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5976 - val_loss: 47.2926\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5664 - val_loss: 47.2325\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5728 - val_loss: 47.2511\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5759 - val_loss: 47.2611\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5874 - val_loss: 47.2946\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6295 - val_loss: 47.2083\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6132 - val_loss: 47.2096\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6325 - val_loss: 47.3748\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6179 - val_loss: 47.2119\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5856 - val_loss: 47.2233\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5886 - val_loss: 47.2524\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5846 - val_loss: 47.2658\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 66us/step - loss: 26.6572 - val_loss: 47.1765\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5234 - val_loss: 47.2433\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 68us/step - loss: 26.5919 - val_loss: 47.2665\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 174us/step - loss: 26.5673 - val_loss: 47.2498\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.5487 - val_loss: 47.2780\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.6585 - val_loss: 47.1863\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5874 - val_loss: 47.2334\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5902 - val_loss: 47.3284\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5918 - val_loss: 47.1534\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 142us/step - loss: 26.5644 - val_loss: 47.2045\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 26.5925 - val_loss: 47.2916\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 132us/step - loss: 26.6220 - val_loss: 47.3311\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.5651 - val_loss: 47.2119\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.6173 - val_loss: 47.2866\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6181 - val_loss: 47.2026\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.5706 - val_loss: 47.1682\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5961 - val_loss: 47.1220\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 26.5825 - val_loss: 47.2329\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 26.5696 - val_loss: 47.2247\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 128us/step - loss: 26.5946 - val_loss: 47.2828\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.5665 - val_loss: 47.2946\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5713 - val_loss: 47.1985\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5811 - val_loss: 47.2414\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5823 - val_loss: 47.2651\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5612 - val_loss: 47.2176\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6034 - val_loss: 47.2337\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.5911 - val_loss: 47.2683\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 111us/step - loss: 26.6202 - val_loss: 47.1005\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5903 - val_loss: 47.3347\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.5601 - val_loss: 47.2006\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.5711 - val_loss: 47.2640\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.5760 - val_loss: 47.2155\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5958 - val_loss: 47.2430\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5692 - val_loss: 47.2923\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 90us/step - loss: 26.5831 - val_loss: 47.1784\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.6007 - val_loss: 47.2785\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.6391 - val_loss: 47.2119\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 122us/step - loss: 26.5466 - val_loss: 47.1991\n",
      "\n",
      "Mean Squared Error for iteration37: 46.10822249465451\n",
      "\n",
      "Iteration: 38\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5639 - val_loss: 47.2114\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.5414 - val_loss: 47.2005\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5723 - val_loss: 47.2166\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5775 - val_loss: 47.2277\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.5885 - val_loss: 47.2237\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 109us/step - loss: 26.5908 - val_loss: 47.2560\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5528 - val_loss: 47.1931\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5682 - val_loss: 47.2630\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5838 - val_loss: 47.2932\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5736 - val_loss: 47.2263\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5881 - val_loss: 47.1894\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5538 - val_loss: 47.2066\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 106us/step - loss: 26.5907 - val_loss: 47.3060\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.5681 - val_loss: 47.2167\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5817 - val_loss: 47.2387\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6124 - val_loss: 47.1299\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.5501 - val_loss: 47.2512\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 108us/step - loss: 26.5610 - val_loss: 47.2697\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5695 - val_loss: 47.1864\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.5559 - val_loss: 47.2664\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 127us/step - loss: 26.5668 - val_loss: 47.3127\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.5785 - val_loss: 47.2485\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5665 - val_loss: 47.1833\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6471 - val_loss: 47.2769\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.5928 - val_loss: 47.1507\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6150 - val_loss: 47.2760\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5790 - val_loss: 47.2372\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5485 - val_loss: 47.2664\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6339 - val_loss: 47.2477\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5812 - val_loss: 47.3184\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5579 - val_loss: 47.2599\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5675 - val_loss: 47.1879\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5521 - val_loss: 47.2477\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5666 - val_loss: 47.2129\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6093 - val_loss: 47.3095\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5807 - val_loss: 47.2239\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 121us/step - loss: 26.6212 - val_loss: 47.2896\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 165us/step - loss: 26.5836 - val_loss: 47.2635\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 104us/step - loss: 26.5531 - val_loss: 47.2321\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6109 - val_loss: 47.2535\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.6261 - val_loss: 47.2224\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5757 - val_loss: 47.2236\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5926 - val_loss: 47.2198\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5631 - val_loss: 47.2446\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5895 - val_loss: 47.2328\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5467 - val_loss: 47.2551\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.7227 - val_loss: 47.1904\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6059 - val_loss: 47.3711\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6053 - val_loss: 47.2269\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5907 - val_loss: 47.2099\n",
      "\n",
      "Mean Squared Error for iteration38: 46.11607260766935\n",
      "\n",
      "Iteration: 39\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5793 - val_loss: 47.2542\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5781 - val_loss: 47.2660\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5411 - val_loss: 47.2194\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5273 - val_loss: 47.2636\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5750 - val_loss: 47.2730\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5674 - val_loss: 47.3033\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5872 - val_loss: 47.1613\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 132us/step - loss: 26.5568 - val_loss: 47.1912\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6293 - val_loss: 47.1833\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.5523 - val_loss: 47.2441\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 110us/step - loss: 26.5516 - val_loss: 47.2955\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.6054 - val_loss: 47.3045\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5764 - val_loss: 47.2080\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5602 - val_loss: 47.2450\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5533 - val_loss: 47.3366\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5432 - val_loss: 47.1931\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6215 - val_loss: 47.2497\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5539 - val_loss: 47.2567\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 26.5728 - val_loss: 47.2501\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.5594 - val_loss: 47.1616\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5957 - val_loss: 47.2990\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 26.5719 - val_loss: 47.2901\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 84us/step - loss: 26.5556 - val_loss: 47.2297\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5904 - val_loss: 47.2172\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5557 - val_loss: 47.1869\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 26.5679 - val_loss: 47.2829\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5467 - val_loss: 47.2866\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5774 - val_loss: 47.2048\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6182 - val_loss: 47.3316\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5569 - val_loss: 47.1406\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6630 - val_loss: 47.1945\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5379 - val_loss: 47.2615\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5782 - val_loss: 47.2112\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5711 - val_loss: 47.1422\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5644 - val_loss: 47.3409\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6353 - val_loss: 47.2249\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5365 - val_loss: 47.3041\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5571 - val_loss: 47.3459\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5683 - val_loss: 47.1469\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5526 - val_loss: 47.1871\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.5623 - val_loss: 47.2594\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 101us/step - loss: 26.5455 - val_loss: 47.2681\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.5803 - val_loss: 47.1639\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.6220 - val_loss: 47.3261\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 123us/step - loss: 26.6109 - val_loss: 47.2112\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 103us/step - loss: 26.5845 - val_loss: 47.2160\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5571 - val_loss: 47.2707\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5665 - val_loss: 47.2107\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5532 - val_loss: 47.2180\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5629 - val_loss: 47.2778\n",
      "\n",
      "Mean Squared Error for iteration39: 46.15785950184861\n",
      "\n",
      "Iteration: 40\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.6056 - val_loss: 47.2481\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6516 - val_loss: 47.3998\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5627 - val_loss: 47.2071\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5483 - val_loss: 47.2676\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5527 - val_loss: 47.2770\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5675 - val_loss: 47.1511\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5613 - val_loss: 47.2551\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5603 - val_loss: 47.3008\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5381 - val_loss: 47.1874\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6222 - val_loss: 47.2822\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5720 - val_loss: 47.2329\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5570 - val_loss: 47.2904\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5688 - val_loss: 47.1088\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5855 - val_loss: 47.2216\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6717 - val_loss: 47.2609\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5336 - val_loss: 47.2658\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.5770 - val_loss: 47.3185\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5757 - val_loss: 47.2494\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5918 - val_loss: 47.1576\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5344 - val_loss: 47.2137\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5516 - val_loss: 47.3525\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5324 - val_loss: 47.2326\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5901 - val_loss: 47.1956\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5544 - val_loss: 47.2005\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5718 - val_loss: 47.2136\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5897 - val_loss: 47.3679\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5589 - val_loss: 47.2307\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5939 - val_loss: 47.2605\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5755 - val_loss: 47.0965\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5424 - val_loss: 47.2587\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6449 - val_loss: 47.2564\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5746 - val_loss: 47.1883\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5892 - val_loss: 47.3512\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6558 - val_loss: 47.2035\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5392 - val_loss: 47.1841\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5949 - val_loss: 47.2837\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5450 - val_loss: 47.1839\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5947 - val_loss: 47.2180\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5668 - val_loss: 47.2067\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5573 - val_loss: 47.3115\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5881 - val_loss: 47.2677\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6276 - val_loss: 47.2618\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5505 - val_loss: 47.3047\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5616 - val_loss: 47.1956\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5591 - val_loss: 47.2601\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5756 - val_loss: 47.2821\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6005 - val_loss: 47.1879\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5919 - val_loss: 47.3393\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5865 - val_loss: 47.2293\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6187 - val_loss: 47.2382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Squared Error for iteration40: 46.30218059377951\n",
      "\n",
      "Iteration: 41\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5978 - val_loss: 47.1628\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6227 - val_loss: 47.2886\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5441 - val_loss: 47.1628\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5586 - val_loss: 47.2719\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5805 - val_loss: 47.2276\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5586 - val_loss: 47.2290\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6006 - val_loss: 47.2816\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5779 - val_loss: 47.3169\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5588 - val_loss: 47.1654\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5561 - val_loss: 47.1714\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6037 - val_loss: 47.3043\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5712 - val_loss: 47.1150\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5952 - val_loss: 47.3362\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.5949 - val_loss: 47.2777\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6053 - val_loss: 47.1927\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5693 - val_loss: 47.2212\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5580 - val_loss: 47.2800\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5947 - val_loss: 47.1422\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5745 - val_loss: 47.2647\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5809 - val_loss: 47.2517\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6102 - val_loss: 47.3218\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6114 - val_loss: 47.2330\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5745 - val_loss: 47.2593\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6098 - val_loss: 47.1168\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5680 - val_loss: 47.2573\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5978 - val_loss: 47.2913\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5389 - val_loss: 47.1997\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5662 - val_loss: 47.2578\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5723 - val_loss: 47.2311\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5709 - val_loss: 47.2421\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5835 - val_loss: 47.2648\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5872 - val_loss: 47.1265\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5175 - val_loss: 47.2694\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5438 - val_loss: 47.2308\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5636 - val_loss: 47.3440\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5864 - val_loss: 47.2189\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5712 - val_loss: 47.2251\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5409 - val_loss: 47.2485\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5899 - val_loss: 47.2713\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5705 - val_loss: 47.2706\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5462 - val_loss: 47.2829\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5899 - val_loss: 47.3044\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.6287 - val_loss: 47.1434\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.6034 - val_loss: 47.2384\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5383 - val_loss: 47.2511\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5699 - val_loss: 47.2165\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 88us/step - loss: 26.5520 - val_loss: 47.1800\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5589 - val_loss: 47.1784\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5633 - val_loss: 47.2561\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5716 - val_loss: 47.3388\n",
      "\n",
      "Mean Squared Error for iteration41: 46.44709333598763\n",
      "\n",
      "Iteration: 42\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6707 - val_loss: 47.2014\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5718 - val_loss: 47.3299\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5645 - val_loss: 47.2875\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5700 - val_loss: 47.2814\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.6536 - val_loss: 47.1867\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 119us/step - loss: 26.5560 - val_loss: 47.2840\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5791 - val_loss: 47.2123\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.7220 - val_loss: 47.4142\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6047 - val_loss: 47.1799\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5424 - val_loss: 47.2523\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5814 - val_loss: 47.2766\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5963 - val_loss: 47.2499\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6352 - val_loss: 47.3536\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5889 - val_loss: 47.1474\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5960 - val_loss: 47.1799\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6047 - val_loss: 47.2721\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5243 - val_loss: 47.2475\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5521 - val_loss: 47.1667\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5828 - val_loss: 47.2744\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6245 - val_loss: 47.2282\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5846 - val_loss: 47.3409\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6192 - val_loss: 47.3472\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5570 - val_loss: 47.2435\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5390 - val_loss: 47.2087\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5604 - val_loss: 47.2155\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5651 - val_loss: 47.1595\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 75us/step - loss: 26.5974 - val_loss: 47.3076\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.6066 - val_loss: 47.3299\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5627 - val_loss: 47.2010\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5892 - val_loss: 47.2207\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5450 - val_loss: 47.2579\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5800 - val_loss: 47.2825\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5447 - val_loss: 47.2144\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6207 - val_loss: 47.3035\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5290 - val_loss: 47.2311\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5877 - val_loss: 47.1932\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5575 - val_loss: 47.2464\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5351 - val_loss: 47.2920\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5537 - val_loss: 47.1935\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5707 - val_loss: 47.2109\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5639 - val_loss: 47.2085\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5844 - val_loss: 47.2280\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6072 - val_loss: 47.2977\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5558 - val_loss: 47.2726\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6167 - val_loss: 47.1961\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5486 - val_loss: 47.2140\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5304 - val_loss: 47.2201\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5800 - val_loss: 47.3586\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5614 - val_loss: 47.3354\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6271 - val_loss: 47.2472\n",
      "\n",
      "Mean Squared Error for iteration42: 46.22958687646505\n",
      "\n",
      "Iteration: 43\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5497 - val_loss: 47.2220\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.5623 - val_loss: 47.2562\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5536 - val_loss: 47.2551\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5455 - val_loss: 47.1763\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5283 - val_loss: 47.1802\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5439 - val_loss: 47.2466\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5747 - val_loss: 47.1356\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6175 - val_loss: 47.4817\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5818 - val_loss: 47.2552\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5160 - val_loss: 47.2679\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5907 - val_loss: 47.1355\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5950 - val_loss: 47.2889\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5353 - val_loss: 47.2850\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5714 - val_loss: 47.2241\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5500 - val_loss: 47.1877\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5519 - val_loss: 47.3044\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5612 - val_loss: 47.2155\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5621 - val_loss: 47.2235\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5775 - val_loss: 47.2648\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5902 - val_loss: 47.2924\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5568 - val_loss: 47.2203\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5845 - val_loss: 47.2454\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5703 - val_loss: 47.1540\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5823 - val_loss: 47.2355\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5594 - val_loss: 47.3860\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5590 - val_loss: 47.1806\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5758 - val_loss: 47.2933\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5665 - val_loss: 47.4029\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.6779 - val_loss: 47.2009\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5322 - val_loss: 47.2468\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5687 - val_loss: 47.3208\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5773 - val_loss: 47.2307\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5464 - val_loss: 47.2732\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5121 - val_loss: 47.2420\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5858 - val_loss: 47.2674\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5877 - val_loss: 47.1959\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5759 - val_loss: 47.1790\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5671 - val_loss: 47.2395\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5370 - val_loss: 47.2740\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5894 - val_loss: 47.3382\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5433 - val_loss: 47.1858\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6063 - val_loss: 47.2193\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.6110 - val_loss: 47.3031\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5575 - val_loss: 47.3146\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5883 - val_loss: 47.1866\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5946 - val_loss: 47.2751\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.5985 - val_loss: 47.2523\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6166 - val_loss: 47.3880\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5987 - val_loss: 47.2347\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5688 - val_loss: 47.2257\n",
      "\n",
      "Mean Squared Error for iteration43: 46.32472933442855\n",
      "\n",
      "Iteration: 44\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5477 - val_loss: 47.2914\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5627 - val_loss: 47.2833\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5605 - val_loss: 47.2594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5531 - val_loss: 47.2601\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5456 - val_loss: 47.2459\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5496 - val_loss: 47.2355\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5847 - val_loss: 47.2157\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5502 - val_loss: 47.2319\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5454 - val_loss: 47.2827\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5539 - val_loss: 47.2383\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5769 - val_loss: 47.2958\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5842 - val_loss: 47.3769\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5309 - val_loss: 47.2378\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5875 - val_loss: 47.3464\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5437 - val_loss: 47.2212\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5213 - val_loss: 47.1930\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5440 - val_loss: 47.2658\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5788 - val_loss: 47.2479\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5688 - val_loss: 47.3356\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5418 - val_loss: 47.2454\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5475 - val_loss: 47.2914\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5928 - val_loss: 47.2337\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5570 - val_loss: 47.2671\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5618 - val_loss: 47.3173\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5676 - val_loss: 47.3389\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5369 - val_loss: 47.2632\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5652 - val_loss: 47.2255\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6113 - val_loss: 47.1719\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5723 - val_loss: 47.2354\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5195 - val_loss: 47.3112\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5526 - val_loss: 47.2594\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5875 - val_loss: 47.3140\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5273 - val_loss: 47.2783\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5908 - val_loss: 47.2561\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5482 - val_loss: 47.1982\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5657 - val_loss: 47.2707\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5621 - val_loss: 47.2527\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5401 - val_loss: 47.3027\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5705 - val_loss: 47.3473\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5317 - val_loss: 47.3526\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5338 - val_loss: 47.2310\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5556 - val_loss: 47.3244\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5379 - val_loss: 47.2485\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5415 - val_loss: 47.2276\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6141 - val_loss: 47.3149\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5467 - val_loss: 47.2548\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5876 - val_loss: 47.2687\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5721 - val_loss: 47.3406\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5365 - val_loss: 47.3134\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5731 - val_loss: 47.3279\n",
      "\n",
      "Mean Squared Error for iteration44: 46.324015882420774\n",
      "\n",
      "Iteration: 45\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5633 - val_loss: 47.1931\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5590 - val_loss: 47.2505\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5220 - val_loss: 47.2279\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6269 - val_loss: 47.2820\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5519 - val_loss: 47.2974\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5257 - val_loss: 47.2169\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5617 - val_loss: 47.3379\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5996 - val_loss: 47.3028\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5829 - val_loss: 47.4115\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5641 - val_loss: 47.2223\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5851 - val_loss: 47.2489\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5483 - val_loss: 47.1900\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5932 - val_loss: 47.3064\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5608 - val_loss: 47.3000\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5504 - val_loss: 47.2515\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5510 - val_loss: 47.2093\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6229 - val_loss: 47.3078\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6133 - val_loss: 47.2788\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5585 - val_loss: 47.2476\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5768 - val_loss: 47.2179\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5574 - val_loss: 47.3113\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5380 - val_loss: 47.2940\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5814 - val_loss: 47.2723\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5790 - val_loss: 47.3869\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5380 - val_loss: 47.3102\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5739 - val_loss: 47.2771\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5401 - val_loss: 47.2617\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5471 - val_loss: 47.3022\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5227 - val_loss: 47.2247\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5486 - val_loss: 47.1831\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5487 - val_loss: 47.3307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5349 - val_loss: 47.3123\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.6474 - val_loss: 47.2612\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5977 - val_loss: 47.2602\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5445 - val_loss: 47.3148\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5741 - val_loss: 47.2651\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5491 - val_loss: 47.2564\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5367 - val_loss: 47.3383\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6068 - val_loss: 47.2571\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5441 - val_loss: 47.2740\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5351 - val_loss: 47.3422\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5180 - val_loss: 47.2970\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5378 - val_loss: 47.2260\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5119 - val_loss: 47.2569\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5354 - val_loss: 47.3154\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5753 - val_loss: 47.3452\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5367 - val_loss: 47.2282\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5491 - val_loss: 47.1905\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5988 - val_loss: 47.3302\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.6103 - val_loss: 47.2053\n",
      "\n",
      "Mean Squared Error for iteration45: 46.11557367510637\n",
      "\n",
      "Iteration: 46\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5249 - val_loss: 47.2979\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5971 - val_loss: 47.3679\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5985 - val_loss: 47.2845\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5572 - val_loss: 47.2583\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5536 - val_loss: 47.2533\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.5297 - val_loss: 47.2588\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.5342 - val_loss: 47.2030\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.5197 - val_loss: 47.2312\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.5727 - val_loss: 47.4228\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.5755 - val_loss: 47.2838\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 116us/step - loss: 26.5743 - val_loss: 47.1990\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 105us/step - loss: 26.5967 - val_loss: 47.3010\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 86us/step - loss: 26.5645 - val_loss: 47.2194\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5455 - val_loss: 47.2741\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5574 - val_loss: 47.4238\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5297 - val_loss: 47.2328\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6099 - val_loss: 47.2596\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5500 - val_loss: 47.2980\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5185 - val_loss: 47.2664\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5726 - val_loss: 47.1976\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5781 - val_loss: 47.2537\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5823 - val_loss: 47.3489\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5640 - val_loss: 47.2999\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5669 - val_loss: 47.3993\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5661 - val_loss: 47.2303\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5420 - val_loss: 47.3393\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5811 - val_loss: 47.3052\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5730 - val_loss: 47.3247\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 87us/step - loss: 26.5553 - val_loss: 47.2219\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5326 - val_loss: 47.2958\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5813 - val_loss: 47.2501\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5251 - val_loss: 47.2474\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5742 - val_loss: 47.3108\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5456 - val_loss: 47.2573\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5669 - val_loss: 47.3186\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5520 - val_loss: 47.3389\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5763 - val_loss: 47.3194\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5478 - val_loss: 47.2623\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5430 - val_loss: 47.2299\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5543 - val_loss: 47.1827\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5488 - val_loss: 47.3643\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5801 - val_loss: 47.2359\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5204 - val_loss: 47.2704\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5691 - val_loss: 47.3457\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5999 - val_loss: 47.2068\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5500 - val_loss: 47.2436\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5291 - val_loss: 47.2237\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5544 - val_loss: 47.3105\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5466 - val_loss: 47.2935\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5599 - val_loss: 47.2436\n",
      "\n",
      "Mean Squared Error for iteration46: 46.17692403748424\n",
      "\n",
      "Iteration: 47\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5531 - val_loss: 47.3193\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5594 - val_loss: 47.2878\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5227 - val_loss: 47.1953\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5875 - val_loss: 47.3675\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5553 - val_loss: 47.2666\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5411 - val_loss: 47.2009\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5751 - val_loss: 47.3412\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 78us/step - loss: 26.5432 - val_loss: 47.2520\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5517 - val_loss: 47.1364\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.6216 - val_loss: 47.3222\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5451 - val_loss: 47.2749\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5581 - val_loss: 47.2566\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5482 - val_loss: 47.2550\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5716 - val_loss: 47.3390\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5850 - val_loss: 47.2643\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5126 - val_loss: 47.2726\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5565 - val_loss: 47.2985\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5697 - val_loss: 47.3425\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5295 - val_loss: 47.3459\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5191 - val_loss: 47.2656\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5823 - val_loss: 47.1934\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5207 - val_loss: 47.1852\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5404 - val_loss: 47.2968\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.5574 - val_loss: 47.3558\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5200 - val_loss: 47.3086\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5242 - val_loss: 47.2245\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5525 - val_loss: 47.2174\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5322 - val_loss: 47.3037\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5415 - val_loss: 47.3390\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5322 - val_loss: 47.2884\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5334 - val_loss: 47.2587\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5560 - val_loss: 47.2413\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5390 - val_loss: 47.2594\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5233 - val_loss: 47.3724\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5885 - val_loss: 47.2643\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5976 - val_loss: 47.2964\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5535 - val_loss: 47.2494\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5502 - val_loss: 47.3858\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5852 - val_loss: 47.3005\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5696 - val_loss: 47.2040\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5565 - val_loss: 47.3130\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5344 - val_loss: 47.2501\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5325 - val_loss: 47.3299\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5360 - val_loss: 47.3992\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5270 - val_loss: 47.3250\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5339 - val_loss: 47.3098\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5887 - val_loss: 47.2520\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5290 - val_loss: 47.2709\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5283 - val_loss: 47.2164\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5263 - val_loss: 47.3251\n",
      "\n",
      "Mean Squared Error for iteration47: 46.22373132879856\n",
      "\n",
      "Iteration: 48\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5532 - val_loss: 47.3286\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5831 - val_loss: 47.2701\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5473 - val_loss: 47.3151\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5386 - val_loss: 47.2999\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5582 - val_loss: 47.3503\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5179 - val_loss: 47.2659\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5737 - val_loss: 47.2208\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5279 - val_loss: 47.3213\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5245 - val_loss: 47.2873\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5566 - val_loss: 47.2867\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5805 - val_loss: 47.1792\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5900 - val_loss: 47.3879\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5914 - val_loss: 47.3544\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5163 - val_loss: 47.3059\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 69us/step - loss: 26.5657 - val_loss: 47.2387\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5503 - val_loss: 47.1976\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5123 - val_loss: 47.2953\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5512 - val_loss: 47.3346\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 82us/step - loss: 26.5188 - val_loss: 47.2527\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5619 - val_loss: 47.2846\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5632 - val_loss: 47.3672\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5184 - val_loss: 47.3122\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5523 - val_loss: 47.3124\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5392 - val_loss: 47.2633\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 95us/step - loss: 26.5404 - val_loss: 47.1793\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5727 - val_loss: 47.2889\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5403 - val_loss: 47.3152\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5463 - val_loss: 47.2612\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5183 - val_loss: 47.2884\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5745 - val_loss: 47.3204\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5539 - val_loss: 47.2591\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5095 - val_loss: 47.3302\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5447 - val_loss: 47.3170\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.6024 - val_loss: 47.2618\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5628 - val_loss: 47.1911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5143 - val_loss: 47.3395\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5734 - val_loss: 47.3746\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5693 - val_loss: 47.3025\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5577 - val_loss: 47.3179\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5474 - val_loss: 47.3085\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5834 - val_loss: 47.2913\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5194 - val_loss: 47.2510\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5679 - val_loss: 47.2763\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5327 - val_loss: 47.1720\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5458 - val_loss: 47.3326\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5479 - val_loss: 47.2656\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5417 - val_loss: 47.3136\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 84us/step - loss: 26.5541 - val_loss: 47.3182\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.6449 - val_loss: 47.3303\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5368 - val_loss: 47.4180\n",
      "\n",
      "Mean Squared Error for iteration48: 46.18225265222291\n",
      "\n",
      "Iteration: 49\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5759 - val_loss: 47.2986\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5465 - val_loss: 47.3881\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5465 - val_loss: 47.2037\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5327 - val_loss: 47.3458\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5461 - val_loss: 47.4373\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5876 - val_loss: 47.2758\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5560 - val_loss: 47.2102\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5630 - val_loss: 47.1805\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5348 - val_loss: 47.3144\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5258 - val_loss: 47.4244\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5400 - val_loss: 47.3153\n",
      "Epoch 12/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5983 - val_loss: 47.4607\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5800 - val_loss: 47.2431\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5174 - val_loss: 47.2911\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 91us/step - loss: 26.5254 - val_loss: 47.2953\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5404 - val_loss: 47.3087\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5505 - val_loss: 47.3078\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5495 - val_loss: 47.3196\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5905 - val_loss: 47.3031\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.6152 - val_loss: 47.3309\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5088 - val_loss: 47.2289\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5525 - val_loss: 47.3413\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6775 - val_loss: 47.3654\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5030 - val_loss: 47.3415\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5115 - val_loss: 47.3424\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 113us/step - loss: 26.5954 - val_loss: 47.2384\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5417 - val_loss: 47.3228\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5767 - val_loss: 47.3220\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5817 - val_loss: 47.3104\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5575 - val_loss: 47.2567\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5379 - val_loss: 47.2878\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5808 - val_loss: 47.4211\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5107 - val_loss: 47.3356\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5264 - val_loss: 47.2813\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5284 - val_loss: 47.3409\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.6026 - val_loss: 47.2649\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5448 - val_loss: 47.3371\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5883 - val_loss: 47.3182\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5156 - val_loss: 47.3097\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5240 - val_loss: 47.3132\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5576 - val_loss: 47.2280\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 85us/step - loss: 26.5132 - val_loss: 47.3433\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5979 - val_loss: 47.3607\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5327 - val_loss: 47.2683\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5755 - val_loss: 47.2988\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5357 - val_loss: 47.4015\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.6065 - val_loss: 47.2487\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5362 - val_loss: 47.3171\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5322 - val_loss: 47.2722\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5510 - val_loss: 47.3363\n",
      "\n",
      "Mean Squared Error for iteration49: 46.189351786461785\n",
      "\n",
      "Iteration: 50\n",
      "Train on 576 samples, validate on 145 samples\n",
      "Epoch 1/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5467 - val_loss: 47.2052\n",
      "Epoch 2/50\n",
      "576/576 [==============================] - 0s 75us/step - loss: 26.5280 - val_loss: 47.3086\n",
      "Epoch 3/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5076 - val_loss: 47.2652\n",
      "Epoch 4/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5189 - val_loss: 47.3175\n",
      "Epoch 5/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5591 - val_loss: 47.2507\n",
      "Epoch 6/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5288 - val_loss: 47.2556\n",
      "Epoch 7/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.6057 - val_loss: 47.2825\n",
      "Epoch 8/50\n",
      "576/576 [==============================] - 0s 73us/step - loss: 26.5509 - val_loss: 47.3549\n",
      "Epoch 9/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5315 - val_loss: 47.3065\n",
      "Epoch 10/50\n",
      "576/576 [==============================] - 0s 98us/step - loss: 26.5257 - val_loss: 47.2823\n",
      "Epoch 11/50\n",
      "576/576 [==============================] - 0s 77us/step - loss: 26.5281 - val_loss: 47.2138\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 73us/step - loss: 26.6191 - val_loss: 47.3273\n",
      "Epoch 13/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5097 - val_loss: 47.3121\n",
      "Epoch 14/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.6193 - val_loss: 47.3116\n",
      "Epoch 15/50\n",
      "576/576 [==============================] - 0s 89us/step - loss: 26.5412 - val_loss: 47.2324\n",
      "Epoch 16/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5387 - val_loss: 47.3363\n",
      "Epoch 17/50\n",
      "576/576 [==============================] - 0s 71us/step - loss: 26.5291 - val_loss: 47.2571\n",
      "Epoch 18/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5571 - val_loss: 47.3054\n",
      "Epoch 19/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5074 - val_loss: 47.3059\n",
      "Epoch 20/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5808 - val_loss: 47.3900\n",
      "Epoch 21/50\n",
      "576/576 [==============================] - 0s 74us/step - loss: 26.5715 - val_loss: 47.2008\n",
      "Epoch 22/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5615 - val_loss: 47.2807\n",
      "Epoch 23/50\n",
      "576/576 [==============================] - 0s 70us/step - loss: 26.5150 - val_loss: 47.3168\n",
      "Epoch 24/50\n",
      "576/576 [==============================] - 0s 72us/step - loss: 26.5258 - val_loss: 47.2541\n",
      "Epoch 25/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5299 - val_loss: 47.3827\n",
      "Epoch 26/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5531 - val_loss: 47.3372\n",
      "Epoch 27/50\n",
      "576/576 [==============================] - 0s 93us/step - loss: 26.6106 - val_loss: 47.3510\n",
      "Epoch 28/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.5611 - val_loss: 47.3425\n",
      "Epoch 29/50\n",
      "576/576 [==============================] - 0s 90us/step - loss: 26.5610 - val_loss: 47.2984\n",
      "Epoch 30/50\n",
      "576/576 [==============================] - 0s 81us/step - loss: 26.5124 - val_loss: 47.2402\n",
      "Epoch 31/50\n",
      "576/576 [==============================] - 0s 92us/step - loss: 26.5502 - val_loss: 47.2420\n",
      "Epoch 32/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.5304 - val_loss: 47.2872\n",
      "Epoch 33/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 26.5497 - val_loss: 47.3866\n",
      "Epoch 34/50\n",
      "576/576 [==============================] - 0s 115us/step - loss: 26.5438 - val_loss: 47.3076\n",
      "Epoch 35/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.5564 - val_loss: 47.3128\n",
      "Epoch 36/50\n",
      "576/576 [==============================] - 0s 96us/step - loss: 26.5362 - val_loss: 47.3250\n",
      "Epoch 37/50\n",
      "576/576 [==============================] - 0s 99us/step - loss: 26.5050 - val_loss: 47.3568\n",
      "Epoch 38/50\n",
      "576/576 [==============================] - 0s 100us/step - loss: 26.5291 - val_loss: 47.2485\n",
      "Epoch 39/50\n",
      "576/576 [==============================] - 0s 94us/step - loss: 26.5080 - val_loss: 47.3025\n",
      "Epoch 40/50\n",
      "576/576 [==============================] - 0s 102us/step - loss: 26.4991 - val_loss: 47.3307\n",
      "Epoch 41/50\n",
      "576/576 [==============================] - 0s 97us/step - loss: 26.5214 - val_loss: 47.2641\n",
      "Epoch 42/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5213 - val_loss: 47.2950\n",
      "Epoch 43/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5562 - val_loss: 47.3360\n",
      "Epoch 44/50\n",
      "576/576 [==============================] - 0s 80us/step - loss: 26.5437 - val_loss: 47.2705\n",
      "Epoch 45/50\n",
      "576/576 [==============================] - 0s 83us/step - loss: 26.5315 - val_loss: 47.3424\n",
      "Epoch 46/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5843 - val_loss: 47.3741\n",
      "Epoch 47/50\n",
      "576/576 [==============================] - 0s 78us/step - loss: 26.5343 - val_loss: 47.2882\n",
      "Epoch 48/50\n",
      "576/576 [==============================] - 0s 76us/step - loss: 26.5458 - val_loss: 47.2344\n",
      "Epoch 49/50\n",
      "576/576 [==============================] - 0s 79us/step - loss: 26.5475 - val_loss: 47.3210\n",
      "Epoch 50/50\n",
      "576/576 [==============================] - 0s 107us/step - loss: 26.5283 - val_loss: 47.3520\n",
      "\n",
      "Mean Squared Error for iteration50: 46.210963690665984\n"
     ]
    }
   ],
   "source": [
    "mse_total = []\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    print('\\nIteration: ', i+1)\n",
    "    model.fit(X_train_norm, y_train, validation_split=0.2, epochs=50)\n",
    "    predict_yhat = model.predict(X_test_norm)\n",
    "    mse = mean_squared_error(y_test, predict_yhat)\n",
    "    print('\\n''Mean Squared Error for iteration{}: {}'.format(i+1, mse))\n",
    "    mse_total.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_total)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Part A - Mean of MSE and Std. Dev.\n",
    "\n",
    "The mean MSE value is 50.59490996401415 and standard deviation for MSE is 1.0276902495212634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean MSE value is 46.145059421030176 and standard deviation for MSE is 0.10127510875528388\n"
     ]
    }
   ],
   "source": [
    "#Calculating mean and standard deviation of MSE - Part B\n",
    "mean = np.mean(mse_total)\n",
    "std_dev=np.std(mse_total)\n",
    "\n",
    "print('The mean MSE value is {} and standard deviation for MSE is {}'.format(mean, std_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
